# Time-why it also matters {#Time}

The chapter contains the theory required for handling time series data. From this chapter, the reader will have gained an understanding of the following topics:

- That a temporal process consists of both low and high frequency components, the former playing a key role in determining long-term trends while the latter may be associated with shorter-term changes.
- Techniques for the exploratory analysis of the data generated by the temporal process, including the ACF (correlogram) and PACF (periodogram).
- Models for irregular (high frequency) components after the regular components (trend) have been removed.
- Methods for forecasting, including exponential smoothing and ARIMA modelling.
- The state space modelling approach, which sits naturally within a Bayesian setting and which provides a general framework for most of the classical time series models and many more besides.
- Implementing time series processes within a Bayesian hierarchical framework.


## Example 11.1 Ground level ozone concentrations {-}


Load the daily and hourly data for one site.

```{r Ex 11.1 load data, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(ggplot2)

# Load data for one site
site_daily <- read.csv("data/LA_ozone_daily.csv", header = TRUE)

# change the format of the date column
site_daily$date <- as.Date(site_daily$date, "%m/%d/%Y")

# load hourly data from that same site
site_hourly <- read.csv("data/LA_ozone_hourly.csv", header = TRUE)

# Add a theme to clear axes and background in ggplot (optional)
theme_clear <- function(){
  theme(
    panel.grid.major = element_blank(), # remove background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), # remove grey background
    axis.line = element_line(colour = "black") # keep axis line
  )
}
  
```


Plot the daily and hourly time series. 

```{r Ex 11.1 plot time series}
# Plot daily data
ggplot(data = site_daily) +
  geom_line(aes(x = date, y = max.ozone, group = 1)) +
  # draw a line at the first data
  geom_vline(xintercept = as.Date("2013-01-01"), color = "grey") +
  # 8 hour regulatory standard of 0.075 (ppm)
  geom_hline(yintercept = 0.075, color = "grey") +
  xlab("Day in 2013 at Los Angeles Site 060379033") + 
  ylab("Max Daily 8hr Ozone Level (ppm)") + theme_clear()
  

# Plot hourly data
ggplot(data = site_hourly,) +
  geom_line(aes(x = time, y = ozone, group = 1)) +
  geom_vline(xintercept = 1, color = "grey") +
   # 8 hour regulatory standard of 0.075 (ppm).
  geom_hline(yintercept = 0.075, color = "grey") +
  xlab("Hour in 2013's ozone season") + 
  ylab("Hourly Ozone Concentration (ppm)") +  theme_clear()

```

## Example 11.2 Low-pass filtering of carbon monoxide levels using the moving average {-}

```{r Ex 11.2 clean, include = FALSE}
rm(list=ls())
```

For this example we will use the TTR package (Technical Trading Rules). This allow us to manipulate objects like time series for forecasting.


```{r Ex 11.2 load data, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(TTR)
# Load daily data
site_daily <- read.csv("data/LA_ozone_daily.csv", header = TRUE)
# add an identifier column for each day in the sample
site_daily$day <- 1:nrow(site_daily)
# add a theme to clear axes and background in ggplot
theme_clear <- function(){
  theme(
    panel.grid.major = element_blank(), # remove background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), # remove grey background
    axis.line = element_line(colour = "black"), # keep axis line
  )
}

```


```{r Ex 11.2 moving averages plot, warning=FALSE}

# Add loess smooth
# Single day
ozone.loess <- loess(max.ozone ~ day, span = 0.75, data = site_daily[,c("max.ozone", "day")])
ozone.predict <- predict(ozone.loess, data.frame(day = 1:nrow(site_daily)))
ozone.predict_df <- data.frame(day = 1:nrow(site_daily), 
                               ozone.prediction = ozone.predict)

ggplot(data = site_daily) +
  geom_line(aes(x = day, y = max.ozone, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at Los Angeles Site 060379033") + 
  ylab("Max Daily 8hr Ozone Level (ppm)") +
  ggtitle("Single day") + 
  theme_clear()

# Three days
ozone_SMA3 <- data.frame(sma = SMA(site_daily$max.ozone, n = 3),
                         day = 1:nrow(site_daily))

ggplot(data = ozone_SMA3) +
  geom_line(aes(x = day, y = sma, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at Los Angeles Site 060379033") + 
  ylab("Max Daily 8hr Ozone Level (ppm)") +  
  ggtitle("Three days") + 
  theme_clear()


# Six days
ozone_SMA6 <- data.frame(sma = SMA(site_daily$max.ozone, n = 6),
                         day = 1:nrow(site_daily))

ggplot(data = ozone_SMA6) +
  geom_line(aes(x = day, y = sma, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at Los Angeles Site 060379033") + 
  ylab("Max Daily 8hr Ozone Level (ppm)") +  
  ggtitle("Six days") + 
  theme_clear()


# Twelve days
ozone_SMA12 <- data.frame(sma = SMA(site_daily$max.ozone, n = 12),
                         day = 1:nrow(site_daily))

ggplot(data = ozone_SMA12) +
  geom_line(aes(x = day, y = sma, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at Los Angeles Site 060379033") + 
  ylab("Max Daily 8hr Ozone Level (ppm)") +
  ggtitle("Twelve days") + 
  theme_clear()

```

## Example 11.13 Forecasting ozone levels {-}

```{r Ex 11.12 clean, include = FALSE}
rm(list = ls())
```

```{r Ex 11.13 load, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(TTR)
library(forecast)
# Load hourly data for site 060379033
site_hourly <- read.csv("data/LA_ozone_hourly.csv", header = TRUE)
# one night hour per day missing for instrument calibration - imputed for simplicity
imputeNA <- mean(site_hourly$ozone, na.rm = TRUE)
site_hourly$ozone[is.na(site_hourly$ozone)] <- imputeNA

```

```{r Ex 11.13 data munge}

# Select the first seven days in july
# days_pattern contains the dates for the first seven days
days_pattern <- paste0("^2013070", 1:7, collapse="|") 

# select all the rows that follow that pattern using grepl
july_seven_days <- site_hourly[grepl(days_pattern, site_hourly$datetime),] 
july_seven_days$hours <- 1:nrow(july_seven_days)

# Holt-Winters model fitting
# Turn this into a time series object to use Holt-Winters forecast
level_ts <- ts(july_seven_days$ozone,
               frequency = 24,
               start = c(1))
ozone_forecast <- HoltWinters(level_ts) 

# Plot using the default function
plot(
  ozone_forecast,
  xlab = "Hours - First Week -July 2013",
  ylab = "O3 (ppm)",
  col.predicted = 1,
  col = "black",
  bty = "n",
  lty = 2
)

# Holt- Winters 24 ahead forast on Day 8 
# no need to specify Holt-Winters forecast as the object is already HoltWinters class
ozoneforecast_day8 <- forecast(ozone_forecast, h=24)

# Plot using default function
plot(ozoneforecast_day8, bty = "n")

```

## Example 11.14 Forecasting volcanic ash {-}


```{r Ex 11.14 clean, include = FALSE}
rm(list = ls())
```

The data in this example consists of atmospheric levels of volcanic ash from 1500AD to 2000AD. 

```{r Ex 11.14 load, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(ggplot2)
library(forecast)
library(TTR)

# Load volcano dust data 
## REVIEW: Data source: Hyn�d�man, R.J.  Time Series Data Library, http://data.is/TSDLdemo
# Data cover the period from 1500AD to 2000AD
volcano_dust <-
  scan("http://robjhyndman.com/tsdldata/annual/dvi.dat", skip = 1)

# Add a theme to clear axes and background in ggplot
theme_clear <- function(){
  theme(
    panel.grid.major = element_blank(), # remove background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), # remove grey background
    axis.line = element_line(colour = "black"), # keep axis line
  )
}


```

The following figure shows the plot of the original time series.

```{r Ex 11.14 plot time series ACF and PACF}

# Turn data into data frame to plot it in ggplot
volcano_dust_df <- data.frame(year = 1500:(1500+length(volcano_dust)-1),
                              dust = volcano_dust)

ggplot(data = volcano_dust_df) +
  geom_line(aes(x = year, y = dust, group = 1)) +
  xlab("Year") + 
  ylab("Atmospheric levels of volcanic ash") + theme_clear()
  
```


We can also plot the autocorrelogram (ACF) and partial autocorrelogram (PACF) to identify any autocorrelation in the time series.

```{r Ex 11.14 acf and pacf}

# convert data into a time series object
volcano_dust_series <- ts(volcano_dust, start = c(1500))
# Compute autocorrelogram with max lag 20
acf(
  volcano_dust_series,
  lag.max = 20,
  bty = "n",
  main = "Autocorrelogram volcano dust"
)

# Compute the partial autocorrelogram with max lag 20
pacf(
  volcano_dust_series,
  lag.max = 20,
  bty = "n",
  main = "Partial autocorrelogram volcano dust"
)

```

```{r Ex 11.14 arima model}

# Finding an ARIMA model
auto.arima(volcano_dust_series, ic = "aic")

# fitting the ARIMA(2,0,0) model
volcano_dust_arima <- arima(volcano_dust_series, order = c(2, 0, 0))

# forecast 31 years with the ARIMA(2,0,0) model
volcano_dust_forecast <- forecast(volcano_dust_arima, h = 31)
plot(volcano_dust_forecast, bty = "n")


```

## Example 11.16 implementation of a dynamic linear model {-}

### Nimble 

```{r Ex 11.16 clean, include = FALSE}
rm(list = ls())
```

```{r  Ex 11.16 load, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(coda)
library(nimble)
library(tidybayes)
library(tidyverse)

# Load sampler functions
source("functions/Ex11_16_FFBS_sampler.R")

# Load data for one site
site_daily <- read.csv("data/LA_ozone_daily.csv", header = TRUE)

# change the format of the date column
site_daily$date <- as.Date(site_daily$date, "%m/%d/%Y")

# load hourly data from that same site
site_hourly <- read.csv("data/LA_ozone_hourly.csv", header = TRUE)

# Select the first seven days in July as in Example 11.13
days_pattern <- paste0("^2013070", 1:7, collapse="|") 

# select all the rows that follow that pattern using grepl

# I know I don't need to impute it but it was taking forever to compile
imputeNA <- mean(site_hourly$ozone, na.rm = TRUE)
site_hourly$ozone[is.na(site_hourly$ozone)] <- imputeNA

july_seven_days <- site_hourly[grepl(days_pattern, site_hourly$datetime),] 
july_seven_days$hours <- 1:nrow(july_seven_days)

# Add a theme to clear axes and background in ggplot (optional)
theme_clear <- function(){
  theme(
    panel.grid.major = element_blank(), # remove background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), # remove grey background
    axis.line = element_line(colour = "black") # keep axis line
  )
}
```

#### Hourly data seasonal component

We first analyze the hourly data for the first seven days in July.

```{r Ex 11.16 nimble model multivariate}

# The following nimble code was originally written by Paritosh Kumar Roy

Example11_16Hourly <- nimbleCode({
  tau ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  Vt <- tau ^ 2
  
  
  
  for (j in 1:p) {
    sqrt_Wt_diag[j] ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  }
  
  Wt[1:p, 1:p] <- diag(sqrt_Wt_diag[1:p] ^ 2)
  yt[1:Tt] ~ ddlm_uoms(
    Ft = Ft[1:p, 1:Tt],
    Vt = Vt,
    Gt = Gt[1:p, 1:p],
    Wt = Wt[1:p, 1:p],
    m0 = m0[1:p],
    C0 = C0[1:p, 1:p]
  )
 

  theta[1:p, 1:(Tt + 1)] <-
    nim_ffbs_uoms(
      yt = yt[1:Tt],
      Ft = Ft[1:p, 1:Tt],
      Vt = Vt,
      Gt = Gt[1:p, 1:p],
      Wt = Wt[1:p, 1:p],
      m0 = m0[1:p],
      C0 = C0[1:p, 1:p]
    )
   yt.fitted[1:Tt] <- nim_postfit_uoms(yt[1:Tt], Ft[1:p, 1:Tt], Vt,
                 Gt[1:p,1:p], Wt[1:p,1:p], m0[1:p], C0[1:p,1:p])
  
})

```



```{r Ex 11.16 nimble hourly data, results='hide', warning=FALSE, message= FALSE}

# fit a linear growth model for the daily data
yt <- july_seven_days$ozone
Tt <- length(yt)
p <- 3

Ft <- array(0, dim = c(p, Tt))
Ft[1, ] <- 1
Ft[2, ] <- 1
Ft[3, ] <- 0

# Intercept and seasonal component with period of 24hrs
Gt <- rbind(c(1, 0, 0),
           c(0, cos(2 * pi / 12), sin(2 * pi / 12)),
           c(0, -sin(2 * pi / 12), cos(2 * pi / 12)))

# initials
m0 <- c(mean(yt, na.rm = TRUE), 0, 0)
C0 <- diag(x = 1, nrow = p, ncol = p)

const_list <- list(Tt = Tt,
                   p = p,
                   m0 = m0,
                   C0 = C0)
dat_list <- list(yt = yt, Ft = Ft, Gt = Gt)
init_list <- list(
  tau = 0.01,
  sqrt_Wt_diag = sqrt(rep(0.1, p)),
  theta = array(0, dim = c(p, Tt + 1))
)

params <- c("tau", "sqrt_Wt_diag", "theta", "yt.fitted")
# Run model in nimble
mcmc.out <- nimbleMCMC(
  code = Example11_16Hourly,
  constants = const_list,
  data = dat_list,
  inits = init_list,
  monitors = params,
  niter = 40000,
  nburnin = 20000,
  thin = 80,
  WAIC = TRUE,
  nchains = 2,
  summary = TRUE,
  samplesAsCodaMCMC = TRUE
)

```

```{r Ex 11.16 hourly posterior summary}
post_summary <- mcmc.out$summary$all.chains 
post_summary[c('tau',
               'sqrt_Wt_diag[1]',
               'sqrt_Wt_diag[2]',
               'sqrt_Wt_diag[3]'), ]

tidy_post_samples <- mcmc.out$samples |> tidy_draws()

tidy_post_samples |>
  select(
    .chain,
    .iteration,
    .draw,
    'tau',
    'sqrt_Wt_diag[1]',
    'sqrt_Wt_diag[2]',
    'sqrt_Wt_diag[3]'
  ) |>
  gather(vars, value, -.chain, -.iteration, -.draw) |>
  ggplot(aes(x = .iteration, y = value)) +
  geom_path(aes(color = factor(.chain)), size = 0.25,
            show.legend = FALSE) +
  facet_wrap( ~ vars, scales = "free_y", nrow = 3) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())

post_sum_theta <-
  as.data.frame(post_summary) |>  rownames_to_column() |>
  filter(str_detect(rowname, "theta")) |>
  select(rowname, `95%CI_low`, Mean, `95%CI_upp`)|>
  separate(rowname, into = c("x1", "x2"), sep = ",") |>
  mutate(component = as.numeric(gsub(".*?([0-9]+).*", "\\1", x1))) |>
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", x2))) |>
  select(component, time, `95%CI_low`, Mean, `95%CI_upp`)

ggplot(data = post_sum_theta, aes(x = time)) +
  #geom_path(aes(y = theta), color = "red", size = 0.4) +
  geom_ribbon(aes(ymin = `95%CI_low`, ymax = `95%CI_upp`), fill = "lightgray", alpha = 0.7) +
  geom_path(aes(y = Mean), col = "blue", size = 0.4) +
  facet_wrap(
    ~ component,
    nrow = 2,
    scales = "free",
    labeller = label_bquote(theta[.(component)])
  ) +
  ylab("") +
  xlab("Time") +
  theme(panel.grid = element_blank(),
        strip.background = element_blank()) + theme_clear()

```

Define the constants, data and initials lists for the `nimble` model.

```{r Ex 11.16 rhat and ess hourly}
n <- ncol(mcmc.out$samples$chain1)

Rhat_all <-  sapply(1:n, function(x) {
  rstan::Rhat(cbind(mcmc.out$samples$chain1[, x],
                    mcmc.out$samples$chain2[, x]))
})

ess_all <- sapply(1:n, function(x) {
  rstan::ess_bulk(cbind(mcmc.out$samples$chain1[, x],
                        mcmc.out$samples$chain2[, x]))
})

ess_all_tail <- sapply(1:n, function(x) {
  rstan::ess_tail(cbind(mcmc.out$samples$chain1[, x],
                        mcmc.out$samples$chain2[, x]))
})

max(Rhat_all, na.rm = T)
min(ess_all, na.rm = T)
min(ess_all_tail, na.rm = T)
```


#### Daily data time varying mean

```{r}


# nim_bsample <- nimbleFunction(
#   run = function(mt = double(1), Ct = double(1), at = double(1),
#                  Gt = double(0), Rt = double(1)) {
#     
#     returnType(double(1))  # return type declaration
#     
#     # identifying the dimension of the observation equation and evolution equation
#     Tt <- nimDim(at)[1] # total time points
#     theta <-  nimNumeric(length = Tt + 1) # including theta0 at the 1st column
#     # forward j = 1:(Tt+1) index transformed to t = (Tt+1):1 index as t = (Tt+2) - j
#     theta[Tt+1]  <-  rnorm(n = 1, mean = mt[Tt+1], sd = sqrt(Ct[Tt+1]))
#     # for t = J:1 (backward) use j = 1:J and transformed to t = J:1 as t = (J+1)-j
#     for(j in 1:Tt){
#       t <- (Tt+1)-j
#       Bt <- Ct[t] * Gt / Rt[t]
#       ht <- mt[t] + Bt * (theta[t+1] - at[t])
#       Ht <- Ct[t] - Bt * Gt * Ct[t]
#       theta[t] <- rnorm(n = 1, mean = ht, sd = sqrt(Ht))
#     }
#      
#      return(theta)
#   }, check = FALSE
# )

nim_bsample <- nimbleFunction(
  run = function(mt = double(2), Ct = double(3), at = double(2),
                 Gt = double(2), Rt = double(3)) {
    
    returnType(double(2))  # return type declaration
    
    # identifying the dimension of the observation equation and evolution equation
    p <- nimDim(at)[1] # dimension of the evolution equation
    Tt <- nimDim(at)[2] # total time points
    
    theta <- nimArray(0, dim = c(p,Tt+1)) # including theta0 at the 1st column
    
    
    # forward j = 1:(Tt+1) index transformed to t = (Tt+1):1 index as t = (Tt+2) - j
    j <- 1
    t <- (Tt+2)-j
    theta[1:p,t] <- rmnorm_chol(n = 1, mean = mt[1:p,t], cholesky = chol(Ct[1:p,1:p,t]), prec_param = FALSE)
    for(j in 2:(Tt+1)){
      t <- (Tt+2)-j
      Bt <- Ct[1:p,1:p,t] %*% t(Gt) %*% inverse(Rt[1:p,1:p,t])
      ht <- (mt[1:p,t] + Bt %*% (theta[1:p,t+1] - at[1:p,t]))[,1]
      Ht <- Ct[1:p,1:p,t] - Bt %*% Gt %*% Ct[1:p,1:p,t]
      theta[1:p,t] <- rmnorm_chol(n = 1, mean = ht, cholesky = chol(Ht), prec_param = FALSE)
    }
    
    return(theta)
  }, check = FALSE
)


```

```{r Ex 11.16 nimble RW code}

Example11_16Daily <- nimbleCode({
  
  tau ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  
    Vt <- tau^2

  
  sqrt_Wt_diag[1] ~ T(dt(mu = 0, sigma = 0.01, df = 1), 0, Inf)
  sqrt_Wt_diag[2] ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)

  
  Wt[1:p,1:p] <- nim_diag(x = sqrt_Wt_diag[1:p]^2)
  
  mt[1:p,1] <- m0[1:p]
  Ct[1:p,1:p,1] <- C0[1:p,1:p]
  
  for (t in 1:Tt) {
    at[1:p,t] <- (Gt[1:p,1:p] %*% mt[1:p,t])[1:p, 1]
    Rt[1:p,1:p,t] <- Gt[1:p,1:p] %*% Ct[1:p,1:p,t] %*% t(Gt[1:p,1:p]) + Wt[1:p,1:p]
    ft[t] <- (t(Ft[1:p, t]) %*% at[1:p,t])[1, 1]
    Qt[t] <- (t(Ft[1:p, t]) %*% Rt[1:p,1:p,t] %*% Ft[1:p, t] + Vt)[1,1]
    yt[t] ~ dnorm(mean = ft[t], var = Qt[t])
    At[1:p,t] <- (Rt[1:p,1:p,t] %*% Ft[1:p, t])[1:p, 1]/Qt[t]
    mt[1:p,t+1] <- at[1:p,t] + (At[1:p,t] * (yt[t] - ft[t]))
    Ct[1:p,1:p,t+1] <- Rt[1:p,1:p,t] - (At[1:p,t] %*% t(At[1:p,t])) * Qt[t]
  }
  
  yt.fitted[1:Tt] <- nim_postfit_uoms(yt[1:Tt], Ft[1:p, 1:Tt], Vt,
                 Gt[1:p,1:p], Wt[1:p,1:p], m0[1:p], C0[1:p,1:p])
  theta[1:p,1:(Tt+1)] <- nim_bsample(mt = mt[1:p,1:(Tt+1)], Ct = Ct[1:p,1:p,1:(Tt+1)], at = at[1:p,1:Tt], Gt = Gt[1:p,1:p], Rt = Rt[1:p,1:p,1:Tt])
  
  
})
```



```{r Ex 11.16 daily data rw model, results='hide', warning=FALSE, message= FALSE}
# fit a linear growth model for the daily data
yt <- site_daily$max.ozone
Tt <- length(yt)
p <- 2
Ft <- matrix(c(1, 0), nrow = p, ncol = Tt)
Gt <- matrix(c(1,0,1,1),ncol = 2, nrow = 2)
# initial values
m0 <- rep(mean(yt, na.rm = TRUE),2)
C0 <- diag(x = 1, nrow = p, ncol = p)

const_list <- list(Tt = Tt,
                   m0 = m0,
                   C0 = C0,
                   p = p)
dat_list <- list(yt = yt, Ft = Ft, Gt = Gt)
init_list <- list(
  tau = 0.01,
  sqrt_Wt = sqrt(0.1))
params <- c("tau",  "theta", "Vt", "Wt", "yt.fitted")
# Run model in nimble
mcmc.out <- nimbleMCMC(
  code = Example11_16Daily,
  constants = const_list,
  data = dat_list,
  inits = init_list,
  monitors = params,
  niter = 40000,
  nburnin = 20000,
  thin = 20,
  WAIC = TRUE,
  nchains = 2,
  summary = TRUE,
  samplesAsCodaMCMC = TRUE
)


```

```{r Ex 11.16 daily rw posterior summary}

post_summary <- mcmc.out$summary$all.chains 


post_sum_theta <-
  as.data.frame(post_summary) |>  rownames_to_column() |>
  filter(str_detect(rowname, "theta")) |>
  select(rowname, `95%CI_low`, Mean, `95%CI_upp`)|>
  separate(rowname, into = c("x1", "x2"), sep = ",") |>
  mutate(component = as.numeric(gsub(".*?([0-9]+).*", "\\1", x1))) |>
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", x2))) |>
  select(component, time, `95%CI_low`, Mean, `95%CI_upp`)

ggplot(data = post_sum_theta, aes(x = time)) +
  #geom_path(aes(y = theta), color = "red", size = 0.4) +
  geom_ribbon(aes(ymin = `95%CI_low`, ymax = `95%CI_upp`), fill = "lightgray", alpha = 0.7) +
  geom_path(aes(y = Mean), col = "blue", size = 0.4) +
  facet_wrap(
    ~ component,
    nrow = 2,
    scales = "free",
    labeller = label_bquote(theta[.(component)])
  ) +
  ylab("") +
  xlab("Time") +
  theme(panel.grid = element_blank(),
        strip.background = element_blank()) + theme_clear()

```

```{r  Ex 11.16 daily residuals}

post_sum_theta <-
  as.data.frame(post_summary) |>  rownames_to_column() |>
  filter(str_detect(rowname, "yt.fitted")) |>
  select(rowname, `95%CI_low`, Mean, `95%CI_upp`) |>
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", rowname))) |>
  select(time, `95%CI_low`, Mean, `95%CI_upp`)

ggplot(data = post_sum_theta, aes(x = time)) +
  #geom_path(aes(y = theta), color = "red", size = 0.4) +
  geom_ribbon(aes(ymin = `95%CI_low`, ymax = `95%CI_upp`), fill = "lightgray", alpha = 0.7) +
  geom_path(aes(y = Mean), col = "blue", size = 0.4) +
  ylab("") +
  xlab("Time") +
  theme_clear() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())
```

```{r}
 for (t in 1:Tt) {
    at[t] <- (Gt * mt[t])
    Rt[t] <- Gt * Ct[t] * Gt + Wt
    ft[t] <- Ft[t] * at[t]
    Qt[t] <- Ft[t] * Rt[t] * Ft[t] + Vt
    yt[t] <-  rnorm(1, mean = ft[t], sd = sqrt(Qt[t]))
    At[t] <- (Rt[t] * Ft[t])/Qt[t]
    mt[t+1] <- at[t] + (At[t] * (yt[t] - ft[t]))
    Ct[t+1] <- Rt[t] - (At[t] * At[t]) * Qt[t]
  }
  
```


