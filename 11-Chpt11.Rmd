# Time-why it also matters {#Time}

The chapter contains the theory required for handling time series data. From this chapter, the reader will have gained an understanding of the following topics:

- That a temporal process consists of both low and high frequency components, the former playing a key role in determining long-term trends while the latter may be associated with shorter-term changes.
- Techniques for the exploratory analysis of the data generated by the temporal process, including the ACF (correlogram) and PACF (periodogram).
- Models for irregular (high frequency) components after the regular components (trend) have been removed.
- Methods for forecasting, including exponential smoothing and ARIMA modelling.
- The state space modelling approach, which sits naturally within a Bayesian setting and which provides a general framework for most of the classical time series models and many more besides.
- Implementing time series processes within a Bayesian hierarchical framework.


## Example 11.1 Ground level ozone concentrations {-}


Load the daily and hourly data for one site.

```{r Ex 11.1 load data, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(ggplot2)

# Load data for one site
site_daily <- read.csv("data/LA_ozone_daily.csv", header = TRUE)

# change the format of the date column
site_daily$date <- as.Date(site_daily$date, "%m/%d/%Y")

# load hourly data from that same site
site_hourly <- read.csv("data/LA_ozone_hourly.csv", header = TRUE)

```


Plot the daily and hourly time series.

```{r Ex 11.1 plot time series}
# Plot daily data
ggplot(data = site_daily) +
  geom_line(aes(x = date, y = max.ozone, group = 1)) +
  # draw a line at the first data
  geom_vline(xintercept = as.Date("2013-01-01"), color = "grey") +
  # 8 hour regulatory standard of 0.075 (ppm)
  geom_hline(yintercept = 0.075, color = "grey") +
  xlab("Day in 2013 at Los Angeles Site 060379033") +
  ylab("Max Daily 8hr Ozone Level (ppm)") + theme_classic()


# Plot hourly data
ggplot(data = site_hourly,) +
  geom_line(aes(x = time, y = ozone, group = 1)) +
  geom_vline(xintercept = 1, color = "grey") +
   # 8 hour regulatory standard of 0.075 (ppm).
  geom_hline(yintercept = 0.075, color = "grey") +
  xlab("Hour in 2013's ozone season") +
  ylab("Hourly Ozone Concentration (ppm)") +  theme_classic()

```

## Example 11.2 Low-pass filtering of carbon monoxide levels using the moving average {-}

```{r Ex 11.2 clean, include = FALSE}
rm(list=ls())
```

For this example we will use the TTR package (Technical Trading Rules). This allow us to manipulate objects like time series for forecasting.


```{r Ex 11.2 load data, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(TTR)
# Load daily data
site_daily <- read.csv("data/LA_ozone_daily.csv", header = TRUE)
# add an identifier column for each day in the sample
site_daily$day <- 1:nrow(site_daily)

```


```{r Ex 11.2 moving averages plot, warning=FALSE}

# Add loess smooth
# Single day
ozone.loess <- loess(max.ozone ~ day, span = 0.75, data = site_daily[,c("max.ozone", "day")])
ozone.predict <- predict(ozone.loess, data.frame(day = 1:nrow(site_daily)))
ozone.predict_df <- data.frame(day = 1:nrow(site_daily),
                               ozone.prediction = ozone.predict)

plot_SMA1 <- ggplot(data = site_daily) +
  geom_line(aes(x = day, y = max.ozone, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at LA Site 060379033") +
  ylab("Ozone Level (ppm)") +
  ggtitle("Single day") +
 theme_classic()
# Three days
ozone_SMA3 <- data.frame(sma = SMA(site_daily$max.ozone, n = 3),
                         day = 1:nrow(site_daily))

plot_SMA3 <- ggplot(data = ozone_SMA3) +
  geom_line(aes(x = day, y = sma, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at LA Site 060379033") +
  ylab("Ozone Level (ppm)") +
  ggtitle("Three days") +
  theme_classic()


# Six days
ozone_SMA6 <- data.frame(sma = SMA(site_daily$max.ozone, n = 6),
                         day = 1:nrow(site_daily))

plot_SMA6 <- ggplot(data = ozone_SMA6) +
  geom_line(aes(x = day, y = sma, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at LA Site 060379033") +
  ylab("Ozone Level (ppm)") +
  ggtitle("Six days") +
  theme_classic()


# Twelve days
ozone_SMA12 <- data.frame(sma = SMA(site_daily$max.ozone, n = 12),
                         day = 1:nrow(site_daily))

plot_SMA12 <- ggplot(data = ozone_SMA12) +
  geom_line(aes(x = day, y = sma, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at LA Site 060379033") +
  ylab("Ozone Level (ppm)") +
  ggtitle("Twelve days") +
  theme_classic()

cowplot::plot_grid(plot_SMA1, plot_SMA3, plot_SMA6, plot_SMA12, labels = "auto")



```

## Example 11.13 Forecasting ozone levels {-}

```{r Ex 11.12 clean, include = FALSE}
rm(list = ls())
```

```{r Ex 11.13 load, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(TTR)
library(forecast)
# Load hourly data for site 060379033
site_hourly <- read.csv("data/LA_ozone_hourly.csv", header = TRUE)
# one night hour per day missing for instrument calibration - imputed for simplicity
imputeNA <- mean(site_hourly$ozone, na.rm = TRUE)
site_hourly$ozone[is.na(site_hourly$ozone)] <- imputeNA

```

```{r Ex 11.13 data munge}

# Select the first seven days in july
# days_pattern contains the dates for the first seven days
days_pattern <- paste0("^2013070", 1:7, collapse="|")

# select all the rows that follow that pattern using grepl
july_seven_days <- site_hourly[grepl(days_pattern, site_hourly$datetime),]
july_seven_days$hours <- 1:nrow(july_seven_days)

# Holt-Winters model fitting
# Turn this into a time series object to use Holt-Winters forecast
level_ts <- ts(july_seven_days$ozone,
               frequency = 24,
               start = c(1))
ozone_forecast <- HoltWinters(level_ts)

# Plot using the default function
plot(
  ozone_forecast,
  xlab = "Hours - First Week -July 2013",
  ylab = "O3 (ppm)",
  col.predicted = 1,
  col = "black",
  bty = "n",
  lty = 2
)

# Holt- Winters 24 ahead forast on Day 8
# no need to specify Holt-Winters forecast as the object is already HoltWinters class
ozoneforecast_day8 <- forecast(ozone_forecast, h=24)

# Plot using default function
plot(ozoneforecast_day8, bty = "n")

```

## Example 11.14 Forecasting volcanic ash {-}


```{r Ex 11.14 clean, include = FALSE}
rm(list = ls())
```

The data in this example consists of atmospheric levels of volcanic ash from 1500AD to 2000AD.

```{r Ex 11.14 load, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(ggplot2)
library(forecast)
library(TTR)

# Load volcano dust data
## REVIEW: Data source: Hyn�d�man, R.J.  Time Series Data Library, http://data.is/TSDLdemo
# Data cover the period from 1500AD to 2000AD
volcano_dust <-
  scan("https://robjhyndman.com/tsdldata/annual/dvi.dat", skip = 1)


```

The following figure shows the plot of the original time series.

```{r Ex 11.14 plot time series ACF and PACF}

# Turn data into data frame to plot it in ggplot
volcano_dust_df <- data.frame(year = 1500:(1500+length(volcano_dust)-1),
                              dust = volcano_dust)

ggplot(data = volcano_dust_df) +
  geom_line(aes(x = year, y = dust, group = 1)) +
  xlab("Year") +
  ylab("Atmospheric levels of volcanic ash") + theme_classic()

```


We can also plot the autocorrelogram (ACF) and partial autocorrelogram (PACF) to identify any autocorrelation in the time series.

```{r Ex 11.14 acf and pacf}

# convert data into a time series object
volcano_dust_series <- ts(volcano_dust, start = c(1500))
# Compute autocorrelogram with max lag 20
acf(
  volcano_dust_series,
  lag.max = 20,
  bty = "n",
  main = "Autocorrelogram volcano dust"
)

# Compute the partial autocorrelogram with max lag 20
pacf(
  volcano_dust_series,
  lag.max = 20,
  bty = "n",
  main = "Partial autocorrelogram volcano dust"
)

```

```{r Ex 11.14 arima model}

# Finding an ARIMA model
auto.arima(volcano_dust_series, ic = "aic")

# fitting the ARIMA(2,0,0) model
volcano_dust_arima <- arima(volcano_dust_series, order = c(2, 0, 0))

# forecast 31 years with the ARIMA(2,0,0) model
volcano_dust_forecast <- forecast(volcano_dust_arima, h = 31)
plot(volcano_dust_forecast, bty = "n")


```

## Example 11.16 Fitting a random walk model to PM10 concentrations in London {-}

:::: {.blackbox data-latex=""}
::: {.center data-latex=""}
**NOTE**
:::

The code for the implementation of DLMs in Stan and Nimble was developed by Paritosh Kumar Roy. This code and other more complex DLM structures are available through his [github](https://github.com/paritoshkroy). 

::::

### Nimble {-}

```{r Ex 11.16 pm10 clean nimble, include = FALSE}
rm(list = ls())
```

```{r  Ex 11.16 pm10 load nimble, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}
library(coda)
library(ggplot2)
library(nimble)
library(tidybayes)
library(tidyverse)
source("functions/FFBS_functions_nimble.R") # load necessary functions for ffbs
# Load data 
pm10 <- source("data/11_13_data.txt")[["value"]][["y"]] |> unlist()

# Choose 250 days for example
pm10_250 <- pm10[385:634]

```

```{r Ex 11.16 pm10 nimble model, warning = FALSE}

Example11_16_PM10_Nimble <- nimbleCode({
  
  tau ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  Vt <- tau^2
  sqrt_Wt_diag ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  Wt <- sqrt_Wt_diag^2
  
  theta_mean[1] <- m0
  theta[1] ~ dnorm(theta_mean[1], var = C0)
  
  for(t in 1:J) {
    theta_mean[t+1] <- Gt * theta[t]
    theta[t+1] ~ dnorm(theta_mean[t+1], var = Wt)
    yt_mean[t] <- Ft[t] * theta[t+1]
    yt[t] ~ dnorm(yt_mean[t], var = Vt)
  }
  
})
```

```{r Ex 11.16 run pm10 nimble model, warning = FALSE, error = FALSE, message = FALSE, results='hide', cache = TRUE}
# Model specification
J <- length(pm10_250)
yt <-pm10_250
Ft <- rep(1, J)
Gt <- 1
m0 <- mean(yt, na.rm = TRUE)
C0 <- 10
  
const_list <- list(J = J)
dat_list <- list(
  yt = yt,
  Ft = Ft,
  Gt = Gt,
  m0 = m0,
  C0 = C0
)
init_list <-
  list(tau = 0.01,
       sqrt_Wt_diag = 0.1,
       theta = rep(0, J + 1))
Rmodel <-
  nimbleModel(
    Example11_16_PM10_Nimble,
    constants = const_list,
    data = dat_list,
    inits = init_list
  )
Rmodel$initializeInfo()
Cmodel <- compileNimble(Rmodel, showCompilerOutput = FALSE)
conf <-
  configureMCMC(Rmodel, monitors = c("tau", "sqrt_Wt_diag", "theta", "yt"))
conf$removeSampler(target = "theta[]")
conf$addSampler(
  target = "theta",
  type = "ffbs_uous",
  control = list(
    ytName = "yt",
    FtName = "Ft",
    VtName = "Vt",
    GtName = "Gt",
    WtName = "Wt",
    m0Name = "m0",
    C0Name = "C0"
  )
)
conf$printSamplers(byType = TRUE)
conf$removeSampler(target = "sqrt_Wt_diag")
conf$addSampler(target = "sqrt_Wt_diag",
                type = "RW",
                control = list(log = TRUE))
conf$removeSampler(target = "tau")
conf$addSampler(target = "tau",
                type = "RW",
                control = list(log = TRUE))
conf$printSamplers(byType = TRUE)
conf$printSamplers(executionOrder = TRUE)
Rmcmc <- buildMCMC(conf)
Cmcmc <-
  compileNimble(
    Rmcmc,
    project = Cmodel,
    resetFunctions = TRUE,
    showCompilerOutput = TRUE
  )
niter <- 60000
nburnin <- 0.5 * niter
nchain <- 2
nthin <- 14
post_samples <- runMCMC(
  Cmcmc,
  niter = niter,
  nburnin = nburnin,
  thin = nthin,
  nchains = nchain,
  samplesAsCodaMCMC = TRUE
)
```

```{r Ex 11.16 pm10 nimble extract posterior summary}
post_summary <- nimSummary(post_samples)
tidy_post_samples <- post_samples |> tidy_draws()
# Traceplots
tidy_post_samples |>
  select(.chain, .iteration, .draw, 'tau') |>
  gather(vars, value, -.chain, -.iteration, -.draw) |>
  ggplot(aes(x = .iteration, y = value)) +
  geom_path(aes(color = factor(.chain)), linewidth = 0.25,
            show.legend = FALSE) +
  facet_wrap( ~ vars, scales = "free_y", nrow = 1) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())
tidy_post_samples |>
  select(.chain, .iteration, .draw, 'sqrt_Wt_diag') |>
  gather(vars, value, -.chain, -.iteration, -.draw) |>
  ggplot(aes(x = .iteration, y = value)) +
  geom_path(aes(color = factor(.chain)), linewidth = 0.25,
            show.legend = FALSE) +
  facet_wrap( ~ vars, scales = "free_y", nrow = 1) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())
tidy_post_samples |>
  select(.chain, .iteration, .draw, paste0('theta[', sample.int(J, size = 4, replace = FALSE),"]")) |>
  gather(vars, value, -.chain, -.iteration, -.draw) |>
  ggplot(aes(x = .iteration, y = value)) +
  geom_path(aes(color = factor(.chain)), linewidth = 0.25,
            show.legend = FALSE) +
  facet_wrap( ~ vars, scales = "free_y", nrow = 2) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())
```

```{r 11.16 pm10 nimble posterior summary}
head(post_summary)
post_sum_theta <-
  as.data.frame(post_summary) |>  rownames_to_column() |>
  filter(str_detect(rowname, "theta")) |>
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", rowname))) |>
  select(time, post.mean, post.sd, q2.5, q50, q97.5)
ggplot(data = post_sum_theta, aes(x = time)) +
  geom_ribbon(aes(ymin = q2.5, ymax = q97.5),
              fill = "lightgray",
              alpha = 0.7) +
  geom_path(aes(y = q50), col = "blue", linewidth = 0.6) +
  ylab("") + xlab("Time (days)") + 
  ggtitle(expression(paste("Trend ", PM[10], " London site"))) +
  theme_classic()

```

```{r Ex 11.16 pm10 nimble fitted values, cache = TRUE }

npsample <- floor((niter - nburnin)/nthin)

Cnim_postfit_uous <-
  compileNimble(nim_postfit_uous, showCompilerOutput = FALSE)
post_tau <- tidy_post_samples$tau
post_sqrt_Wt_diag <- tidy_post_samples$sqrt_Wt_diag
# post_yt <- tidy_post_samples$yt

post_ft_list <- lapply(1:(nchain * npsample), function(i) {
  post_Vt <- post_tau[i] ^ 2
  post_Wt <- post_sqrt_Wt_diag[i] ^ 2
  post_ft <- Cnim_postfit_uous(
    yt = dat_list$yt,
    Ft = dat_list$Ft,
    Vt = post_Vt,
    Gt = dat_list$Gt,
    Wt = post_Wt,
    m0 = dat_list$m0,
    C0 = dat_list$C0
  )
  post_ft <-
    data.frame(ft = post_ft) |> mutate(time = row_number())
  return(post_ft)
})
tidy_post_ft <- do.call("rbind", post_ft_list)
## posterior summaries of ft
post_sum_ft <- tidy_post_ft |> group_by(time) |>
  summarise(
    post.mean = mean(ft),
    post.sd = sd(ft),
    q2.5 = quantile(ft, prob = 0.025),
    q50 = quantile(ft, prob = 0.50),
    q97.5 = quantile(ft, prob = 0.975)) |>
  ungroup()

ggplot(data = post_sum_ft, aes(x = time)) +
  geom_ribbon(aes(ymin = q2.5, ymax = q97.5), fill = "lightgray") +
  geom_path(aes(y = post.mean), linewidth = 0.25) +
  geom_point(aes(y = yt), size = 0.25) +
  ylab(bquote("PM"[10]~"Concentration")) +
  xlab("Time (days)") + 
  ggtitle(expression(paste("Fitted values ", PM[10], " London site"))) +
  theme_classic()

```


### Stan {-}

```{r Ex 11.16 pm10 stan clean, include = FALSE}
rm(list = ls())
```

```{r Ex 11.16 pm10 load data, echo = TRUE, warning=FALSE, message= FALSE}

library(coda)
library(ggplot2)
library(rstan)
library(tidyverse)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)


# TODO: change the name of this dataset cause it is used here and in the exercises
pm10 <- source("data/11_13_data.txt")[["value"]][["y"]] |> unlist()
pm10_250 <- pm10[385:634]


```



```{r Ex 11.16 pm10 prepare data stan}
J <- length(pm10_250)
y <- pm10_250
Ft <- rep(1, J)
Gt <- 1
m0 <- mean(y)
C0 <- 10
  
stan_data <- list(
  Tt = J,
  y = y,
  Ft = Ft,
  G = Gt,
  m0 = m0,
  C0 = C0
)
```


```{r engine='bash', comment='', echo = FALSE}
cat functions/Example11_16_PM10.stan
``` 


```{r Ex 11.16 pm10 run stan, cache = TRUE}

Example11_16_PM10_Stan  <- stan(
  file = "functions/Example11_16_PM10.stan",
  data = stan_data,
  warmup = 5000,
  iter = 10000,
  chains = 3,
  include = TRUE
)
rstan::traceplot(Example11_16_PM10_Stan, pars = c("tau","sqrt_W"))
rstan::traceplot(Example11_16_PM10_Stan, pars = paste0("theta[", sample.int(J, size = 4, replace = FALSE), "]"))

stanfit_summary <- summary(Example11_16_PM10_Stan, pars = c("tau","sqrt_W","theta", "yfit"))
head(stanfit_summary$summary)

stan_fit_df <- data.frame(stanfit_summary$summary) |>
  rownames_to_column() |>
  filter(str_detect(rowname, "theta")) |>
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", rowname)))

ggplot(data = stan_fit_df, aes(x = time)) +
  geom_path(aes(y = mean), col = "blue", size = 0.6) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "gray99") +
  xlab("Time (days)") + ylab(" ") + 
  ggtitle(expression(paste("Trend ", PM[10], " London site"))) +
  theme_classic()

yfit_summary_dt <- data.frame(stanfit_summary$summary) |>
  rownames_to_column() |>
  filter(str_detect(rowname, "yfit")) |>
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", rowname)))

ggplot(yfit_summary_dt, aes(x = time)) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "gray99") +
  geom_point(aes(y = y)) +
  geom_path(aes(y = mean), linewidth = 0.1, size = 1) + 
  xlab("Time (days)") + ylab(" ") +
  ggtitle(expression(paste("Fitted values ", PM[10], " London site"))) +
  theme_classic()
 
```



## Example 11.16 EXTRA Implementation of a dynamic linear model: UK ozone data {-}


### Nimble {-}

```{r Ex 11.16 o3 clean nimble, include = FALSE}
rm(list = ls())
```

```{r Ex 11.16 o3 nimble load, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(coda)
library(dplyr)
#library(sf)
library(ggplot2)
library(nimble, warn.conflicts = FALSE)
library(nleqslv)
library(tidybayes)
library(tidyverse)

source("functions/FFBS_functions_nimble.R")

UK_ozone <- read.csv("data/uk_ozone_one_site.csv")
```


```{r o3 nimble model}

Example11_16_O3_Nimble <- nimbleCode({
  tau ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  for (t in 1:Tt) {
    Vt[t] <- tau ^ 2
  }
  
   for (j in 1:p) {
    sqrt_Wt_diag[j] ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  }
  
  Wt[1:p, 1:p] <- nim_diag(x = sqrt_Wt_diag[1:p] ^ 2)
  
  mt[1:p, 1] <- m0[1:p]
  Ct[1:p, 1:p, 1] <- C0[1:p, 1:p]
  
  for (t in 1:Tt) {
    at[1:p, t] <- (Gt[1:p, 1:p] %*% mt[1:p, t])[1:p, 1]
    Rt[1:p, 1:p, t] <-
      Gt[1:p, 1:p] %*% Ct[1:p, 1:p, t] %*% t(Gt[1:p, 1:p]) + Wt[1:p, 1:p]
    ft[t] <- (t(Ft[1:p, t]) %*% at[1:p, t])[1, 1]
    Qt[t] <-
      (t(Ft[1:p, t]) %*% Rt[1:p, 1:p, t] %*% Ft[1:p, t] + Vt[t])[1, 1]
    yt[t] ~ dnorm(mean = ft[t], var = Qt[t])
    At[1:p, t] <- (Rt[1:p, 1:p, t] %*% Ft[1:p, t])[1:p, 1] / Qt[t]
    mt[1:p, t + 1] <- at[1:p, t] + (At[1:p, t] * (yt[t] - ft[t]))
    Ct[1:p, 1:p, t + 1] <-
      Rt[1:p, 1:p, t] - (At[1:p, t] %*% t(At[1:p, t])) * Qt[t]
  }
  
  theta[1:p, 1:(Tt + 1)] <-
    nim_bsample(
      mt = mt[1:p, 1:(Tt + 1)],
      Ct = Ct[1:p, 1:p, 1:(Tt + 1)],
      at = at[1:p, 1:Tt],
      Gt = Gt[1:p, 1:p],
      Rt = Rt[1:p, 1:p, 1:Tt]
    )
  
})

```

#### Time-varying level model {-}

```{r run o3 nimble model, warning = FALSE, error = FALSE, message = FALSE, results='hide', cache=TRUE}

# Model specification
yt <- sqrt(UK_ozone$ozone)
temp <- UK_ozone$temp
wind <- UK_ozone$wind

Tt <- length(yt)
p <- 3 # (intercept, wind, temp)

Ft <- array(0, dim = c( p, Tt))
Ft[ 1,] <- 1
Ft[ 2,] <- (wind[1:Tt] - mean(wind[1:Tt])) / sd(wind[1:Tt])
Ft[ 3,] <- (temp[1:Tt] - mean(temp[1:Tt])) / sd(temp[1:Tt])

Gt <- diag(x = 1, nrow = p, ncol = p)
m0 <- c(mean(yt), 0, 0)
C0 <- diag(x = 1, nrow = p, ncol = p)


const_list <- list(Tt = Tt,
                   p = p)
dat_list <- list(
  yt = yt,
  Ft = Ft,
  Gt = Gt,
  m0 = m0,
  C0 = C0
)
init_list <- list(tau = 0.01, sqrt_Wt_diag = sqrt(rep(0.1, p)))

Rmodel <-
  nimbleModel(
    Example11_16_O3_Nimble,
    constants = const_list,
    data = dat_list,
    inits = init_list
  )
Rmodel$initializeInfo()
Rmodel$calculate()
Cmodel <- compileNimble(Rmodel, showCompilerOutput = FALSE)
conf <-
  configureMCMC(Rmodel, monitors = c("tau", "sqrt_Wt_diag", "theta", "ft"))

Rmcmc <- buildMCMC(conf)
Cmcmc <-
  compileNimble(
    Rmcmc,
    project = Cmodel,
    resetFunctions = TRUE,
    showCompilerOutput = FALSE
  )
niter <- 10000
nburnin <- 0.5 * niter
nthin <- 1
nchains <- 2
start_time <- Sys.time()
post_samples <-
  runMCMC(
    Cmcmc,
    niter = niter,
    nburnin = nburnin,
    thin = nthin,
    nchains = nchains,
    samplesAsCodaMCMC = TRUE
  )
end_time <- Sys.time()
run_time <- end_time - start_time
run_time


```

```{r Ex 11.16 o3 nimble traceplots}

post_summary <- nimSummary(post_samples)
tidy_post_samples <- post_samples |> tidy_draws()
 
tidy_post_samples |>
   dplyr::select(
    .chain,
    .iteration,
    .draw,
    'tau',
    'sqrt_Wt_diag[1]',
    'sqrt_Wt_diag[2]',
    'sqrt_Wt_diag[3]'
  ) |>
  gather(vars, value, -.chain, -.iteration, -.draw) |>
  ggplot(aes(x = .iteration, y = value)) +
  geom_path(aes(color = factor(.chain)), linewidth = 0.25,
            show.legend = FALSE) +
  facet_wrap( ~ vars, scales = "free", nrow = 2) +
  theme_classic() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())



```

```{r Ex 11.16 o3 nimble posterior summary}

post_summary[c('tau',
               'sqrt_Wt_diag[1]',
               'sqrt_Wt_diag[2]',
               'sqrt_Wt_diag[3]'), ]

post_sum_theta <-
  as.data.frame(post_summary) |>  rownames_to_column() |>
  filter(str_detect(rowname, "theta")) |>
  dplyr::select(rowname, q2.5, q50, q97.5) |>
  separate(rowname, into = c("x1", "x2"), sep = ",") |>
  mutate(component = as.numeric(gsub(".*?([0-9]+).*", "\\1", x1))) |>
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", x2))) |>
  dplyr::select(component, time, q2.5, q50, q97.5)

ggplot(data = post_sum_theta, aes(x = time)) +
  geom_ribbon(aes(ymin = q2.5, ymax = q97.5),
              fill = "lightgray",
              alpha = 0.7) +
  geom_path(aes(y = q50), col = "blue", linewidth = 0.4) +
  facet_wrap(
    ~ component,
    nrow = 2,
    scales = "free",
    labeller = label_bquote(theta[.(component)])
  ) +
  ylab("") + xlab("Time") +
  theme_classic() 


```



```{r Ex 11.16 o3  nimble fitted values}

npsample <- floor((niter - nburnin)/nthin)
str(tidy_post_samples)

Cnim_postfit_uoms <- compileNimble(nim_postfit_uoms, showCompilerOutput = FALSE)

post_tau <- tidy_post_samples$tau
post_sqrt_Wt_diag <-
  tidy_post_samples  |>  select(starts_with("sqrt_Wt_diag")) |> 
  as.matrix()|>  unname()

post_ft_list <- lapply(1:(nchains*npsample), function(i) {
  post_Vt <- post_tau[i]^2
  post_Wt <- nim_diag(post_sqrt_Wt_diag[i,]^2)
  post_ft <- Cnim_postfit_uoms(yt = dat_list$yt, 
                               Ft = dat_list$Ft, 
                               Vt = post_Vt,
                               Gt = dat_list$Gt, 
                               Wt = post_Wt,
                               m0 = dat_list$m0, 
                               C0 = dat_list$C0)
  post_ft <- data.frame(ft = post_ft) |> mutate(time = row_number())
  return(post_ft)
})

tidy_post_ft <- do.call("rbind", post_ft_list)
str(tidy_post_ft)
head(tidy_post_ft)

## posterior summaries of ft
head(tidy_post_ft)
post_sum_ft <- tidy_post_ft |> group_by(time) |> 
  summarise(post.mean = mean(ft),
            post.sd = sd(ft),
            q2.5 = quantile(ft, prob = 0.025),
            q50 = quantile(ft, prob = 0.50),
            q97.5 = quantile(ft, prob = 0.975)) |>
  ungroup()
str(post_sum_ft)
post_sum_ft |> head()

ggplot(data = post_sum_ft, aes(x = time)) + 
  geom_ribbon(aes(ymin = q2.5,ymax = q97.5), fill = "lightgray") +
  geom_path(aes(y = post.mean),  size = 0.25) +
  geom_point(aes(y=yt), size = 0.25) +
  ylab("Ozone Level (ppm)") +
  xlab("Time") + ggtitle("Fitted values Ozone level UK") +
  theme_classic() 
```

#### Trend model {-}

```{r run o3 nimble trend model, warning = FALSE, error = FALSE, message = FALSE, results='hide', cache = TRUE}

# Model specification
yt <- sqrt(UK_ozone$ozone)
temp <- UK_ozone$temp
wind <- UK_ozone$wind

Tt <- length(yt)
p <- 4 # (intercept, trend, wind, temp)

Ft <- array(0, dim = c( p, Tt))
Ft[1,] <- 1
Ft[2,] <- 0
Ft[3,] <- (wind[1:Tt] - mean(wind[1:Tt])) / sd(wind[1:Tt])
Ft[4,] <- (temp[1:Tt] - mean(temp[1:Tt])) / sd(temp[1:Tt])


Gt <- diag(x = 1, nrow = p, ncol = p)
Gt[1, 2] <- 1 

m0 <- c(mean(yt), 0, 0, 0)
C0 <- diag(x = 1, nrow = p, ncol = p)

const_list <- list(Tt = Tt,
                   p = p)
dat_list <- list(
  yt = yt,
  Ft = Ft,
  Gt = Gt,
  m0 = m0,
  C0 = C0
)
init_list <- list(tau = 0.01, sqrt_Wt_diag = sqrt(rep(0.1, p)))

Rmodel <-
  nimbleModel(
    Example11_16_O3_Nimble,
    constants = const_list,
    data = dat_list,
    inits = init_list
  )
Rmodel$initializeInfo()
Rmodel$calculate()
Cmodel <- compileNimble(Rmodel, showCompilerOutput = FALSE)
conf <-
  configureMCMC(Rmodel, monitors = c("tau", "sqrt_Wt_diag", "theta", "ft"))

Rmcmc <- buildMCMC(conf)
Cmcmc <-
  compileNimble(
    Rmcmc,
    project = Cmodel,
    resetFunctions = TRUE,
    showCompilerOutput = FALSE
  )
niter <- 10000
nburnin <- 0.5 * niter
nthin <- 1
nchains <- 2
start_time <- Sys.time()
post_samples <-
  runMCMC(
    Cmcmc,
    niter = niter,
    nburnin = nburnin,
    thin = nthin,
    nchains = nchains,
    samplesAsCodaMCMC = TRUE
  )
end_time <- Sys.time()
run_time <- end_time - start_time
run_time


```

```{r Ex 11.16 o3 nimble trend traceplots}

post_summary <- nimSummary(post_samples)
tidy_post_samples <- post_samples |> tidy_draws()

tidy_post_samples |>
   dplyr::select(
    .chain,
    .iteration,
    .draw,
    'tau',
    'sqrt_Wt_diag[1]',
    'sqrt_Wt_diag[2]',
    'sqrt_Wt_diag[3]',
    'sqrt_Wt_diag[4]'

  ) |>
  gather(vars, value, -.chain, -.iteration, -.draw) |>
  ggplot(aes(x = .iteration, y = value)) +
  geom_path(aes(color = factor(.chain)), linewidth = 0.25,
            show.legend = FALSE) +
  facet_wrap( ~ vars, scales = "free", nrow = 2) +
  theme_classic() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())



```

```{r Ex 11.16 o3 nimble trend posterior summary}

post_summary[c('tau',
               'sqrt_Wt_diag[1]',
               'sqrt_Wt_diag[2]',
               'sqrt_Wt_diag[3]',
               'sqrt_Wt_diag[4]'), ]

post_sum_theta <-
  as.data.frame(post_summary) |>  rownames_to_column() |>
  filter(str_detect(rowname, "theta")) |>
  dplyr::select(rowname, q2.5, q50, q97.5) |>
  separate(rowname, into = c("x1", "x2"), sep = ",") |>
  mutate(component = as.numeric(gsub(".*?([0-9]+).*", "\\1", x1))) |>
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", x2))) |>
  dplyr::select(component, time, q2.5, q50, q97.5)

ggplot(data = post_sum_theta, aes(x = time)) +
  geom_ribbon(aes(ymin = q2.5, ymax = q97.5),
              fill = "lightgray",
              alpha = 0.7) +
  geom_path(aes(y = q50), col = "blue", linewidth = 0.4) +
  facet_wrap(
    ~ component,
    nrow = 2,
    scales = "free",
    labeller = label_bquote(theta[.(component)])
  ) +
  ylab("") +
  xlab("Time") +
  theme_classic() 

```

```{r  Ex 11.16 nimble trend fitted values, cache=TRUE, messages = FALSE}

npsample <- floor((niter - nburnin)/nthin)

Cnim_postfit_uoms <- compileNimble(nim_postfit_uoms, showCompilerOutput = FALSE)

post_tau <- tidy_post_samples$tau
post_sqrt_Wt_diag <-
  tidy_post_samples  |>  select(starts_with("sqrt_Wt_diag")) |> 
  as.matrix()|>  unname()

post_ft_list <- lapply(1:(nchains*npsample), function(i) {
  post_Vt <- post_tau[i]^2
  post_Wt <- nim_diag(post_sqrt_Wt_diag[i,]^2)
  post_ft <- Cnim_postfit_uoms(yt = dat_list$yt, 
                               Ft = dat_list$Ft, 
                               Vt = post_Vt,
                               Gt = dat_list$Gt, 
                               Wt = post_Wt,
                               m0 = dat_list$m0, 
                               C0 = dat_list$C0)
  post_ft <- data.frame(ft = post_ft) |> mutate(time = row_number())
  return(post_ft)
})

tidy_post_ft <- do.call("rbind", post_ft_list)

## posterior summaries of ft
post_sum_ft <- tidy_post_ft |> group_by(time) |>  
  summarise(post.mean = mean(ft),
            post.sd = sd(ft),
            q2.5 = quantile(ft, prob = 0.025),
            q50 = quantile(ft, prob = 0.50),
            q97.5 = quantile(ft, prob = 0.975)) |> 
  ungroup()


ggplot(data = post_sum_ft, aes(x = time)) + 
  geom_ribbon(aes(ymin = q2.5,ymax = q97.5), fill = "lightgray") +
  geom_path(aes(y = post.mean),  size = 0.25) +
  geom_point(aes(y=yt), size = 0.25) +
  ylab("Ozone Level (ppm)") +
  xlab("Time") + ggtitle("Fitted values Ozone level UK") +
  theme_classic() 
```

### Stan {-}

```{r Ex 11.16 ozone clean stan, include = FALSE}
rm(list = ls())
```


```{r  Ex 11.16 ozone stan load, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}
library(coda)
library(ggplot2)
library(gridExtra)
library(rstan)
library(tidyverse)

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

# Load data for RW case
UK_ozone <- read.csv("data/uk_ozone_one_site.csv")

```

#### Time-varying level model {-}

```{r  Ex 11.16 o3 prepare data stan}
y <- sqrt(UK_ozone$ozone)
temp <- UK_ozone$temp
wind <- UK_ozone$wind

Tt <- length(y)
p <- 3 # (intercept, wind, temp)

Ft <- array(0, dim = c(Tt, p))
Ft[, 1] <- 1
Ft[, 2] <- (wind[1:Tt] - mean(wind[1:Tt])) / sd(wind[1:Tt])
Ft[, 3] <- (temp[1:Tt] - mean(temp[1:Tt])) / sd(temp[1:Tt])

Gt <- diag(x = 1, nrow = p, ncol = p)
m0 <- c(mean(y), 0, 0)
C0 <- diag(x = 1, nrow = p, ncol = p)

stan_data <- list(T = Tt, p = p, y = y, F = Ft, G = Gt, m0= m0, C0 = C0)

```

```{r engine='bash', comment='', echo = FALSE}
cat functions/Example11_16_UK.stan
``` 

```{r Ex 11.16 o3 run stan, cache = TRUE}
Example11_16_UK_Stan  <- stan(
  file = "functions/Example11_16_UK.stan",
  data = stan_data,
  warmup = 5000,
  iter = 10000,
  chains = 3,
  include = TRUE
)

```


```{r Ex 11.16 o3 post summaries stan}

rstan::traceplot(Example11_16_UK_Stan,
                 pars = c("tau", "sqrt_W_diag", "theta[1,1]"))
rstan::traceplot(Example11_16_UK_Stan, 
                 pars = paste0("theta[", sample.int(Tt, size = 4, replace = FALSE), ",1]"))
rstan::traceplot(Example11_16_UK_Stan, 
                 pars = paste0("theta[", sample.int(Tt, size = 4, replace = FALSE), ",2]"))
rstan::traceplot(Example11_16_UK_Stan, 
                 pars = paste0("theta[", sample.int(Tt, size = 4, replace = FALSE), ",3]"))


fixedpars_summary <-
  summary(Example11_16_UK_Stan, pars = c("tau", "sqrt_W_diag"))$summary
fixedpars_summary

theta_summary <-
  summary(Example11_16_UK_Stan, pars = c("theta"))$summary

yfit_summary <-
  summary(Example11_16_UK_Stan, pars = c("yfit"))$summary

p1 <- data.frame(theta_summary) |>
  rownames_to_column() |>
  filter(rowname %in% paste0("theta[", 1:Tt, ",1]")) |>
  mutate(date = as.Date(UK_ozone$date[1:Tt])) |>
  ggplot(aes(x = date, group = 1)) +
  geom_path(aes(y = mean), color = "blue", linewidth = 0.6) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "lightgray") +
  ggtitle("Intercept") + theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))

p2 <- data.frame(theta_summary) |>
  rownames_to_column() |>
  filter(rowname %in% paste0("theta[", 1:Tt, ",2]")) |>
  mutate(date = as.Date(UK_ozone$date[1:Tt])) |>
  ggplot(aes(x = date)) +
  geom_path(aes(y = mean), color = "blue", linewidth = 0.6) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "lightgray") +
  ggtitle("Wind") +  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))


p3 <- data.frame(theta_summary) |>
  rownames_to_column() |>
  filter(rowname %in% paste0("theta[", 1:Tt, ",3]")) |>
  mutate(date = as.Date(UK_ozone$date[1:Tt])) |>
  ggplot(aes(x = date)) +
  geom_path(aes(y = mean), color = "blue", linewidth = 0.6) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "lightgray") +
  ggtitle("Temperature") +  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(p1,p2,p3, ncol = 2)

# Fitted values
yfit_summary_dt <- data.frame(yfit_summary) |>
  rownames_to_column() |>
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", rowname)))

ggplot(yfit_summary_dt, aes(x = time)) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "gray99") +
  geom_point(aes(y = y)) +
  geom_path(aes(y = mean), linewidth = 0.1, size = 1) + 
 ylab("Ozone Level (ppm)") +
  xlab("Time") + ggtitle("Fitted values Ozone level UK") +
  theme_classic()
```


#### Trend model {-}

```{r  Ex 11.16 o3 trend data stan, cache = TRUE}
y <- sqrt(UK_ozone$ozone)
temp <- UK_ozone$temp
wind <- UK_ozone$wind

Tt <- length(y)
p <- 4 # (intercept, trend, wind, temp)

Ft <- array(0, dim = c(Tt, p))
Ft[, 1] <- 1
Ft[, 2] <- 0
Ft[, 3] <- (wind[1:Tt] - mean(wind[1:Tt])) / sd(wind[1:Tt])
Ft[, 4] <- (temp[1:Tt] - mean(temp[1:Tt])) / sd(temp[1:Tt])

Gt <- diag(x = 1, nrow = p, ncol = p)
Gt[1, 2] <- 1 


m0 <- c(mean(y), 0, 0, 0)
C0 <- diag(x = 1, nrow = p, ncol = p)

stan_data_trend <- list(
  T = Tt,
  p = p,
  y = y,
  F = Ft,
  G = Gt,
  m0 = m0,
  C0 = C0
)

Example11_16_UK_trend_Stan  <- stan(
  file = "functions/Example11_16_UK.stan",
  data = stan_data_trend,
  warmup = 5000,
  iter = 10000,
  chains = 3,
  include = TRUE
)

```

```{r  Ex 11.16 o3 traceplots trend stan}
rstan::traceplot(Example11_16_UK_trend_Stan,
                 pars = c("tau", "sqrt_W_diag", "theta[1,1]"))
rstan::traceplot(Example11_16_UK_trend_Stan, 
                 pars = paste0("theta[", sample.int(Tt, size = 4, replace = FALSE), ",1]"))
rstan::traceplot(Example11_16_UK_trend_Stan, 
                 pars = paste0("theta[", sample.int(Tt, size = 4, replace = FALSE), ",2]"))
rstan::traceplot(Example11_16_UK_trend_Stan, 
                 pars = paste0("theta[", sample.int(Tt, size = 4, replace = FALSE), ",3]"))
rstan::traceplot(Example11_16_UK_trend_Stan, 
                 pars = paste0("theta[", sample.int(Tt, size = 4, replace = FALSE), ",4]"))

```


```{r Ex 11.16 o3 post summaries trend stan}

fixedpars_summary <-
  summary(Example11_16_UK_trend_Stan, pars = c("tau", "sqrt_W_diag"))$summary
fixedpars_summary

theta_summary <-
  summary(Example11_16_UK_trend_Stan, pars = c("theta"))$summary

yfit_summary <-
  summary(Example11_16_UK_trend_Stan, pars = c("yfit"))$summary


p1 <- data.frame(theta_summary) |>
  rownames_to_column() |>
  filter(rowname %in% paste0("theta[", 1:Tt, ",1]")) |>
  mutate(date = as.Date(UK_ozone$date[1:Tt])) |>
  ggplot(aes(x = date, group = 1)) +
  geom_path(aes(y = mean), color = "blue", linewidth = 0.6) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "lightgray") +
  ggtitle("Intercept") + theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))

p2 <- data.frame(theta_summary) |>
  rownames_to_column() |>
  filter(rowname %in% paste0("theta[", 1:Tt, ",4]")) |>
  mutate(date = as.Date(UK_ozone$date[1:Tt])) |>
  ggplot(aes(x = date)) +
  geom_path(aes(y = mean), color = "blue", linewidth = 0.6) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "lightgray") +
  ggtitle("Trend") +  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))

p3 <- data.frame(theta_summary) |>
  rownames_to_column() |>
  filter(rowname %in% paste0("theta[", 1:Tt, ",2]")) |>
  mutate(date = as.Date(UK_ozone$date[1:Tt])) |>
  ggplot(aes(x = date)) +
  geom_path(aes(y = mean), color = "blue", linewidth = 0.6) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "lightgray") +
  ggtitle("Wind") +  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))


p4 <- data.frame(theta_summary) |>
  rownames_to_column() |>
  filter(rowname %in% paste0("theta[", 1:Tt, ",3]")) |>
  mutate(date = as.Date(UK_ozone$date[1:Tt])) |>
  ggplot(aes(x = date)) +
  geom_path(aes(y = mean), color = "blue", linewidth = 0.6) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "lightgray") +
  ggtitle("Temperature") +  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))



grid.arrange(p1,p2,p3, p4, ncol = 2)

# Fitted values
yfit_summary_dt <- data.frame(yfit_summary) |>
  rownames_to_column() |>
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", rowname)))

ggplot(yfit_summary_dt, aes(x = time)) +
  geom_ribbon(aes(ymin = X2.5., ymax = X97.5.),
              alpha = 0.25,
              col = "gray99") +
  geom_point(aes(y = y)) +
  geom_path(aes(y = mean), linewidth = 0.1, size = 1) + 
 ylab("Ozone Level (ppm)") +
  xlab("Time") + ggtitle("Fitted values Ozone level UK") +
  theme_classic()

```



## Solutions to Selected Exercises {-}

## Exercise 11.11 {-}

The joint distribution of $\mathbf{\gamma} = \{\gamma_1, \gamma_2, \dots, \gamma_{N_T}\}$ can be written as:
$$
p(\mathbf{\gamma}) = p(\gamma_1) \prod_{t=1}^{N_T-1}p(\gamma_{t+1}\mid\gamma)\\
= p(\gamma_1)(2\pi\sigma_w^2)^{-(N_T-1)/2}\exp\{- \frac{1}{2\sigma_w^2} \sum_{t=1}^{N_T-1} (\gamma_{t+1} - \gamma)^2) \}\\
\propto p(\gamma_1) \exp\{-\frac{1}{2\sigma_w^2}\mathbf{\gamma}^\top M \mathbf{\gamma}\},
$$
where the entries of $M$ are:
$$
M_{ij} = \begin{cases}
1, & i = j = 1, N_T\\
2, & i = j = 2, 3, \dots, N_T - 1 \\
-1 & i = (j-1), \text{where } j = 2, 3, \dots, N_T\\
-1 & i = (j+1), \text{where } j = 1, 2, \dots, N_T - 1 \\
0 & \text{else}
\end{cases}.
$$
Now, if we assume that $p(\gamma_1) \propto 1$, i.e., an uninformative, improper prior, we have that 
$$
p(\mathbf{\gamma}) \propto \exp\{-\frac{1}{2\sigma_w^2}\mathbf{\gamma}^\top M \mathbf{\gamma}\},
$$
which implies that, for any $t$, by Bayes rule,

$$
p(\gamma_t|\mathbf{\gamma}_{-t}) = \frac{p(\mathbf{\gamma})}{p(\mathbf{\gamma}_{-t})} \propto p(\mathbf{\gamma}).
$$

Eliminating terms in the joint distribution $P(\gamma)$ not related to $\gamma_t$, we obtain

$$
p(\gamma_t|\mathbf{\gamma}_{-t}) \propto 
\begin{cases}
\exp\{-\frac{1}{2\sigma_w^2}(\gamma_t^2 - 2\gamma_t\gamma_{t+1})\}, & t = 1\\
\exp\{-\frac{1}{2\sigma_w^2}(2\gamma_t^2 - 2\gamma_t\gamma_{t+1} - 2\gamma_{t-1}\gamma_t)\}, & t = 2, 3, \dots, N_T-1 \\
\exp\{-\frac{1}{2\sigma_w^2}(\gamma_t^2 - 2\gamma_{t-1}\gamma_{t})\}, & t = N_T
\end{cases}.
$$

The proportional form implies that these are Normal densities. By completing the square, we can obtain 

$$
p(\gamma|\gamma_{-t}) \propto \begin{cases}
N(\gamma_{t+1}, \sigma_w^2), & t = 1 \\
N(\frac{\gamma_{t-1}+\gamma_{t+1}}{2}, \sigma^2_w/2), & t = 2, 3 \dots, N_T-1 \\
N(\gamma_{t-1}, \sigma_w^2), & t = N_T
\end{cases},
$$
as required. A necessary assumption for this conclusion was that $p(\gamma_1) \propto 1$. 
## Exercise 11.12 {-}

The joint density of $\gamma_t$ and $\tau_w$, given $\gamma_{t-1}$ is given by
$$
p(\gamma_t, \tau_w \mid \gamma_{t-1}) = \frac{\tau_w^{1/2}}{\sqrt{2\pi}}\exp \left(-\frac{\tau(\gamma_t - \gamma_{t-1})^2}{2} \right) \frac{b^a}{\Gamma(a)}\tau_w^{a-1}\exp(-b\tau_w).
$$
Marginalizing $\tau_w$ gives
$$
p(\gamma_t \mid \gamma_{t-1}) = \int_{0}^{\infty} \frac{\tau_2^{1/2}}{\sqrt{2\pi}}\exp \left(-\frac{\tau(\gamma_t - \gamma_{t-1})^2}{2} \right) \frac{b^a}{\Gamma(a)}\tau_w^{a-1}\exp(-b\tau_w) d\tau_w \\
= \frac{b^2}{\Gamma(a)\sqrt{2\pi}} \int_{0}^\infty \tau_w^{a-0.5} \exp \left(-\tau_w \left[ \frac{(\gamma_t - \gamma_{t-1})^2}{2} + b\right] \right) d\tau_w \\
= \frac{b^a \Gamma(a+0.5)}{\gamma(a)\sqrt{2\pi} ((\gamma_t - \gamma_{t-1})^2/2+b)^{a+0.5}} \int_{0}^\infty \frac{(\gamma_t - \gamma_{t-1})^2/2+b)^{a+0.5}}{\Gamma(a+0.5)} \tau_w^{(a +0.5) - 1} \exp\left( -\tau_w \left[ \frac{(\gamma_t - \gamma_{t-1})^2}{2} + b\right]\right)\\ 
= \frac{b^a \Gamma(a+0.5)}{\gamma(a)\sqrt{2\pi} ((\gamma_t - \gamma_{t-1})^2/2+b)^{a+0.5}},
$$
where the last equality follows because the integrand was the density of a Gamma distribution. Now, by Bayes rule, we have the following expression for the posterior:
$$
p(\tau_{w}|\gamma_t, \gamma_{t-1}) = \frac{p(\gamma_t, \tau_w \mid \gamma_{t-1})}{p(\gamma_t \mid \gamma_{t-1}) } = \frac{((\gamma_t - \gamma_{t-1})^2/2+b)^{a+0.5}}{\Gamma(a + 0.5)}\tau^{(a+0.5)-1} \exp \left(-\tau_w \left[\frac{(\gamma_t - \gamma_{t-1})^2}{2} + b \right] \right),
$$
which is the density function of the $Ga(a + 0.5, (\gamma_t - \gamma_{t-1})^2/2 + b)$ distribution. The shape parameter of the posterior is the prior shape parameter shifted by $0.5$, and the rate parameter is the prior rate parameter shifted by the term $(\gamma_t - \gamma_{t-1})^2/2$. 

