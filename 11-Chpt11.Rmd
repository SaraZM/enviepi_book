# Time-why it also matters {#Time}

The chapter contains the theory required for handling time series data. From this chapter, the reader will have gained an understanding of the following topics:

- That a temporal process consists of both low and high frequency components, the former playing a key role in determining long-term trends while the latter may be associated with shorter-term changes.
- Techniques for the exploratory analysis of the data generated by the temporal process, including the ACF (correlogram) and PACF (periodogram).
- Models for irregular (high frequency) components after the regular components (trend) have been removed.
- Methods for forecasting, including exponential smoothing and ARIMA modelling.
- The state space modelling approach, which sits naturally within a Bayesian setting and which provides a general framework for most of the classical time series models and many more besides.
- Implementing time series processes within a Bayesian hierarchical framework.


## Example 11.1 Ground level ozone concentrations {-}


Load the daily and hourly data for one site.

```{r Ex 11.1 load data, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(ggplot2)

# Load data for one site
site_daily <- read.csv("data/LA_ozone_daily.csv", header = TRUE)

# change the format of the date column
site_daily$date <- as.Date(site_daily$date, "%m/%d/%Y")

# load hourly data from that same site
site_hourly <- read.csv("data/LA_ozone_hourly.csv", header = TRUE)

# Add a theme to clear axes and background in ggplot (optional)
theme_clear <- function(){
  theme(
    panel.grid.major = element_blank(), # remove background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), # remove grey background
    axis.line = element_line(colour = "black") # keep axis line
  )
}
  
```


Plot the daily and hourly time series. 

```{r Ex 11.1 plot time series}
# Plot daily data
ggplot(data = site_daily) +
  geom_line(aes(x = date, y = max.ozone, group = 1)) +
  # draw a line at the first data
  geom_vline(xintercept = as.Date("2013-01-01"), color = "grey") +
  # 8 hour regulatory standard of 0.075 (ppm)
  geom_hline(yintercept = 0.075, color = "grey") +
  xlab("Day in 2013 at Los Angeles Site 060379033") + 
  ylab("Max Daily 8hr Ozone Level (ppm)") + theme_clear()
  

# Plot hourly data
ggplot(data = site_hourly,) +
  geom_line(aes(x = time, y = ozone, group = 1)) +
  geom_vline(xintercept = 1, color = "grey") +
   # 8 hour regulatory standard of 0.075 (ppm).
  geom_hline(yintercept = 0.075, color = "grey") +
  xlab("Hour in 2013's ozone season") + 
  ylab("Hourly Ozone Concentration (ppm)") +  theme_clear()

```

## Example 11.2 Low-pass filtering of carbon monoxide levels using the moving average {-}

```{r Ex 11.2 clean, include = FALSE}
rm(list=ls())
```

For this example we will use the TTR package (Technical Trading Rules). This allow us to manipulate objects like time series for forecasting.


```{r Ex 11.2 load data, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(TTR)
# Load daily data
site_daily <- read.csv("data/LA_ozone_daily.csv", header = TRUE)
# add an identifier column for each day in the sample
site_daily$day <- 1:nrow(site_daily)
# add a theme to clear axes and background in ggplot
theme_clear <- function(){
  theme(
    panel.grid.major = element_blank(), # remove background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), # remove grey background
    axis.line = element_line(colour = "black"), # keep axis line
  )
}

```


```{r Ex 11.2 moving averages plot, warning=FALSE}

# Add loess smooth
# Single day
ozone.loess <- loess(max.ozone ~ day, span = 0.75, data = site_daily[,c("max.ozone", "day")])
ozone.predict <- predict(ozone.loess, data.frame(day = 1:nrow(site_daily)))
ozone.predict_df <- data.frame(day = 1:nrow(site_daily), 
                               ozone.prediction = ozone.predict)

ggplot(data = site_daily) +
  geom_line(aes(x = day, y = max.ozone, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at Los Angeles Site 060379033") + 
  ylab("Max Daily 8hr Ozone Level (ppm)") +
  ggtitle("Single day") + 
  theme_clear()

# Three days
ozone_SMA3 <- data.frame(sma = SMA(site_daily$max.ozone, n = 3),
                         day = 1:nrow(site_daily))

ggplot(data = ozone_SMA3) +
  geom_line(aes(x = day, y = sma, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at Los Angeles Site 060379033") + 
  ylab("Max Daily 8hr Ozone Level (ppm)") +  
  ggtitle("Three days") + 
  theme_clear()


# Six days
ozone_SMA6 <- data.frame(sma = SMA(site_daily$max.ozone, n = 6),
                         day = 1:nrow(site_daily))

ggplot(data = ozone_SMA6) +
  geom_line(aes(x = day, y = sma, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at Los Angeles Site 060379033") + 
  ylab("Max Daily 8hr Ozone Level (ppm)") +  
  ggtitle("Six days") + 
  theme_clear()


# Twelve days
ozone_SMA12 <- data.frame(sma = SMA(site_daily$max.ozone, n = 12),
                         day = 1:nrow(site_daily))

ggplot(data = ozone_SMA12) +
  geom_line(aes(x = day, y = sma, group = 1)) +
  geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) +
  xlab("Day in 2013 at Los Angeles Site 060379033") + 
  ylab("Max Daily 8hr Ozone Level (ppm)") +
  ggtitle("Twelve days") + 
  theme_clear()

```

## Example 11.13 Forecasting ozone levels {-}

```{r Ex 11.12 clean, include = FALSE}
rm(list = ls())
```

```{r Ex 11.13 load, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(TTR)
library(forecast)

# Load hourly data for site 060379033
site_hourly <- read.csv("data/LA_ozone_hourly.csv", header = TRUE)
# add a theme to clear axes and background in ggplot
theme_clear <- function(){
  theme(
    panel.grid.major = element_blank(), # remove background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), # remove grey background
    axis.line = element_line(colour = "black"), # keep axis line
  )
}

```

```{r Ex 11.13 data munge}

# one night hour per day missing for instrument calibration - imputed for simplicity
imputeNA <- mean(site_hourly$ozone, na.rm = TRUE)
site_hourly$ozone[is.na(site_hourly$ozone)] <- imputeNA

# Select the first seven days in july
# days_pattern contains the dates for the first seven days
days_pattern <- paste0("^2013070", 1:7, collapse="|") 

# select all the rows that follow that pattern using grepl
july_seven_days <- site_hourly[grepl(days_pattern, site_hourly$datetime),] 
july_seven_days$hours <- 1:nrow(july_seven_days)

# Turn this into a time series object to use Holt-Winters forecast
level_ts <- ts(july_seven_days$ozone,
               frequency = 24,
               start = c(1))

ozone_forecast <- HoltWinters(level_ts) 
ozone_forecast_fitted <- as.data.frame(ozone_forecast$fitted)
ozone_forecast_fitted$hours <- 1:nrow(ozone_forecast_fitted) + 24 

# Plot Holt-Winters model fitting
## REVIEW: I know you might not like it but the plot from the forecast package seems more straightforwardthan using ggplot, I'll leave the two for now

# Plot using ggplot
ggplot(july_seven_days) + # Plot the original data for the first seven days
  geom_line(aes(x = hours, y = ozone)) +
  # Plot the fitted values
  geom_line(data = ozone_forecast_fitted, aes(x = hours, y = xhat), linetype = "dashed") +
  ggtitle("Holt-Winters filtering") +
  xlab("Hours - First Week -July 2013") +
  theme_clear()

# Plot using the default function
plot(
  ozone_forecast,
  xlab = "Hours - First Week -July 2013",
  ylab = "O3 (ppm)",
  col.predicted = 1,
  col = "black",
  lty = 2
)

# Holt- Winters 24 ahead forast on Day 8 
# no need to specify Holt-Winters forecast as the object is already HoltWinters class
ozoneforecast_day8 <- forecast(ozone_forecast, h=24)
ozoneforecast_day8_df <- data.frame(mean =  as.vector(ozoneforecast_day8$mean),
                            lwr = as.vector(ozoneforecast_day8$lower[,"95%"]),
                            uppr =  as.vector(ozoneforecast_day8$upper[,"95%"]),
                            hours = (nrow(july_seven_days)+1):(nrow(july_seven_days) + 24))

# Plot using ggplot
ggplot(july_seven_days) +
  geom_line(aes(x = hours, y = ozone))  +
  geom_line(data = ozoneforecast_day8_df, aes(x = hours, y = mean), color = "blue") +
  geom_ribbon(data = ozoneforecast_day8_df,
              aes(ymin = lwr, ymax = uppr, x = hours),
              alpha = 0.3) +
  ggtitle("Forecasts from Holt Winters") + theme_clear()

# Plot using default function
plot(ozoneforecast_day8)

```

## Example 11.14 Forecasting volcanic ash {-}


```{r Ex 11.14 clean, include = FALSE}
rm(list = ls())
```

The data in this example consists of atmospheric levels of volcanic ash from 1500AD to 2000AD. 

```{r Ex 11.14 load, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(ggplot2)
library(forecast)
library(TTR)

# Load volcano dust data 
## REVIEW: Data source: Hyn�d�man, R.J.  Time Series Data Library, http://data.is/TSDLdemo
# Data cover the period from 1500AD to 2000AD
volcano_dust <-
  scan("http://robjhyndman.com/tsdldata/annual/dvi.dat", skip = 1)

# Add a theme to clear axes and background in ggplot
theme_clear <- function(){
  theme(
    panel.grid.major = element_blank(), # remove background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), # remove grey background
    axis.line = element_line(colour = "black"), # keep axis line
  )
}


```

The following figure shows the plot of the original time series.

```{r Ex 11.14 plot time series ACF and PACF}

# Turn data into data frame to plot it in ggplot
volcano_dust_df <- data.frame(year = 1500:(1500+length(volcano_dust)-1),
                              dust = volcano_dust)

ggplot(data = volcano_dust_df) +
  geom_line(aes(x = year, y = dust, group = 1)) +
  xlab("Year") + 
  ylab("Atmospheric levels of volcanic ash") + theme_clear()
  
```


We can also plot the autocorrelogram (ACF) and partial autocorrelogram (PACF) to identify any autocorrelation in the time series.

```{r Ex 11.14 acf and pacf}

# convert data into a time series object
volcano_dust_series <- ts(volcano_dust, start = c(1500))

# Compute the autocorrelogram with max lag 20
volcano_acf <- acf(volcano_dust_series, lag.max = 20, plot = FALSE) 
# create a data frame with the output of acf
volcano_acf_df <- with(volcano_acf, data.frame(lag, acf))
# Compute 95% CI
conf.level <- 0.95
ciline <- qnorm((1 - conf.level)/2)/sqrt(length(volcano_dust_series))
# plot using ggplot
ggplot(data = volcano_acf_df, mapping = aes(x = lag, y = acf)) +
  geom_hline(aes(yintercept = 0)) +
  # plot acf as lines 
  geom_segment(mapping = aes(xend = lag, yend = 0)) +
  # show the 95%CI 
  geom_hline(aes(yintercept = ciline), linetype = 2, color = 'blue') + 
  geom_hline(aes(yintercept = -ciline), linetype = 2, color = 'blue') + 
  ggtitle("Autocorrelogram volcano dust") +
  theme_clear()

# Or plot using the acf function directly
acf(volcano_dust_series, lag.max = 20) 
# Compute the partial autocorrelogram with max lag 20 
volcano_pacf <- pacf(volcano_dust_series, lag.max = 20, plot = FALSE) 
# create a data frame with the output of pacf
volcano_pacf_df <- with(volcano_acf, data.frame(lag, acf))
# plot using ggplot
ggplot(data = volcano_pacf_df, mapping = aes(x = lag, y = acf)) +
  geom_hline(aes(yintercept = 0)) +
  # plot acf as lines
  geom_segment(mapping = aes(xend = lag, yend = 0)) +
  # plot 95%CI
  geom_hline(aes(yintercept = ciline), linetype = 2, color = 'blue') + 
  geom_hline(aes(yintercept = -ciline), linetype = 2, color = 'blue') + 
  ggtitle("Partial autocorrelogram volcano dust") +
  theme_clear()

# Or plot using pacf function directly
pacf(volcano_dust_series, lag.max = 20)

```

```{r Ex 11.14 arima model}

# Finding an ARIMA model
auto.arima(volcano_dust_series, ic = "aic")

# fitting the ARIMA(2,0,0) model
volcano_dust_arima <- arima(volcano_dust_series, order = c(2, 0, 0))

# forecast 31 years with the ARIMA(2,0,0) model
volcano_dust_forecast <- forecast(volcano_dust_arima, h = 31)
plot(volcano_dust_forecast)

# Make a data frame with the forecast information for ggplot
volcano_dust_forecast_df <- data.frame(
  mean =  as.vector(volcano_dust_forecast$mean),
  lwr = as.vector(volcano_dust_forecast$lower[, "95%"]),
  uppr =  as.vector(volcano_dust_forecast$upper[, "95%"]),
  year = 1970:2000
)

# Same plot using ggplot
ggplot(volcano_dust_df) +
  geom_line(aes(x = year, y = dust))  +
  geom_line(data = volcano_dust_forecast_df, aes(x = year, y = mean), color = "blue") +
  geom_ribbon(data = volcano_dust_forecast_df,
              aes(ymin = lwr, ymax = uppr, x = year),
              alpha = 0.3) +
  ggtitle("Forecasts from ARIMA (2, 0, 0)") + theme_clear()

```

## Example 11.16 implementation of a random walk {-}

### Nimble

```{r Ex 11.16 clean, include = FALSE}
rm(list = ls())
```

```{r  Ex 11.16 load, message=FALSE, echo = TRUE, warning=FALSE, message= FALSE}

library(nimble)

# Load data for one site
site_daily <- read.csv("data/LA_ozone_daily.csv", header = TRUE)

# change the format of the date column
site_daily$date <- as.Date(site_daily$date, "%m/%d/%Y")

# load hourly data from that same site
site_hourly <- read.csv("data/LA_ozone_hourly.csv", header = TRUE)

# Select the first seven days in July as in Example 11.13
days_pattern <- paste0("^2013070", 1:7, collapse="|") 

# select all the rows that follow that pattern using grepl

# I know I don't need to impute it but it was taking forever to compile
imputeNA <- mean(site_hourly$ozone, na.rm = TRUE)
site_hourly$ozone[is.na(site_hourly$ozone)] <- imputeNA

july_seven_days <- site_hourly[grepl(days_pattern, site_hourly$datetime),] 
july_seven_days$hours <- 1:nrow(july_seven_days)

# Add a theme to clear axes and background in ggplot (optional)
theme_clear <- function(){
  theme(
    panel.grid.major = element_blank(), # remove background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank(), # remove grey background
    axis.line = element_line(colour = "black") # keep axis line
  )
}
```


```{r Ex 11.16 nimble model, results='hide', warning=FALSE, message= FALSE}

# The following nimble code was originally written by Paritosh Kumar Roy
Example11_16Code <- nimbleCode({
  tau ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  for (t in 1:Tt) {
    Vt[t] <- tau ^ 2
  }
  
  
  for (j in 1:p) {
    sqrt_Wt_diag[j] ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  }
  
  Wt[1:p, 1:p] <- diag(sqrt_Wt_diag[1:p] ^ 2)
  
  mt[1:p, 1] <- m0[1:p]
  Ct[1:p, 1:p, 1] <- C0[1:p, 1:p]
  
  for (t in 1:Tt) {
    at[1:p, t] <- (Gt[1:p, 1:p] %*% mt[1:p, t])[1:p, 1]
    Rt[1:p, 1:p, t] <-
      Gt[1:p, 1:p] %*% Ct[1:p, 1:p, t] %*% t(Gt[1:p, 1:p]) + Wt[1:p, 1:p]
    ft[t] <- (t(Ft[1:p, t]) %*% at[1:p, t])[1, 1]
    Qt[t] <-
      (t(Ft[1:p, t]) %*% Rt[1:p, 1:p, t] %*% Ft[1:p, t] + Vt[t])[1, 1]
    yt[t] ~ dnorm(mean = ft[t], var = Qt[t])
    At[1:p, t] <- (Rt[1:p, 1:p, t] %*% Ft[1:p, t])[1:p, 1] / Qt[t]
    mt[1:p, t + 1] <- at[1:p, t] + (At[1:p, t] * (yt[t] - ft[t]))
    Ct[1:p, 1:p, t + 1] <-
      Rt[1:p, 1:p, t] - (At[1:p, t] %*% t(At[1:p, t])) * Qt[t]
  }
  
  theta[1:p, 1:(Tt + 1)] <-
    nim_bsample(
      mt = mt[1:p, 1:(Tt + 1)],
      Ct = Ct[1:p, 1:p, 1:(Tt + 1)],
      at = at[1:p, 1:Tt],
      Gt = Gt[1:p, 1:p],
      Rt = Rt[1:p, 1:p, 1:Tt]
    )
  
  
})

```

```{r Ex 11.16 nimble sampler}

nim_bsample <- nimbleFunction(
  run = function(mt = double(2),
                 Ct = double(3),
                 at = double(2),
                 Gt = double(2),
                 Rt = double(3)) {
    returnType(double(2))  # return type declaration
    # identifying the dimension of the observation equation and evolution equation
    p <- nimDim(at)[1] # dimension of the evolution equation
    Tt <- nimDim(at)[2] # total time points
    
    theta <-
      nimArray(0, dim = c(p, Tt + 1)) # including theta0 at the 1st column
    # forward j = 1:(Tt+1) index transformed to t = (Tt+1):1 index as t = (Tt+2) - j
    j <- 1
    t <- (Tt + 2) - j
    theta[1:p, t] <-
      rmnorm_chol(
        n = 1,
        mean = mt[1:p, t],
        cholesky = chol(Ct[1:p, 1:p, t]),
        prec_param = FALSE
      )
    for (j in 2:(Tt + 1)) {
      t <- (Tt + 2) - j
      Bt <- Ct[1:p, 1:p, t] %*% t(Gt) %*% inverse(Rt[1:p, 1:p, t])
      ht <- (mt[1:p, t] + Bt %*% (theta[1:p, t + 1] - at[1:p, t]))[, 1]
      Ht <- Ct[1:p, 1:p, t] - Bt %*% Gt %*% Ct[1:p, 1:p, t]
      theta[1:p, t] <-
        rmnorm_chol(
          n = 1,
          mean = ht,
          cholesky = chol(Ht),
          prec_param = FALSE
        )
    }
    
    return(theta)
  },
  check = FALSE
)
```

## Hourly data using seasonal component

```{r Ex 11.16 nimble hourly data}

#linearGrowth <- readRDS("data/linearGrowth.rds")
# fit a linear growth model for the daily data
yt <- july_seven_days$ozone
Tt <- length(yt)
p <- 3

Ft <- array(0, dim = c(p, Tt))
Ft[1, ] <- 1
Ft[2, ] <- 1
Ft[3, ] <- 0

# Intercept and seasonal component with period of 24hrs
Gt <- rbind(c(1, 0, 0),
           c(0, cos(2 * pi / 24), sin(2 * pi / 24)),
           c(0, -sin(2 * pi / 24), cos(2 * pi / 24)))

#Gt <- rbind(c(1, 1), c(0, 1))

# initials
m0 <- c(mean(yt, na.rm = TRUE), 0, 0)
C0 <- diag(x = 1, nrow = p, ncol = p)

const_list <- list(Tt = Tt,
                   p = p,
                   m0 = m0,
                   C0 = C0)
dat_list <- list(yt = yt, Ft = Ft, Gt = Gt)
init_list <- list(
  tau = 0.01,
  sqrt_Wt_diag = sqrt(rep(0.1, p)),
  theta = array(0, dim = c(p, Tt + 1))
)

Rmodel <-
  nimbleModel(Example11_16Code,
              constants = const_list,
              data = dat_list,
              inits = init_list)
Rmodel$initializeInfo()
Rmodel$calculate()
Cmodel <- compileNimble(Rmodel, showCompilerOutput = FALSE)
conf <-
  configureMCMC(Rmodel, monitors = c("tau", "sqrt_Wt_diag", "theta"))

Rmcmc <- buildMCMC(conf)
Cmcmc <-
  compileNimble(
    Rmcmc,
    project = Cmodel,
    resetFunctions = TRUE,
    showCompilerOutput = FALSE
  )

niter <- 20000
nburnin <- 0.5 * niter
nthin <- 1
start_time <- Sys.time()
post_samples <-
  runMCMC(
    Cmcmc,
    niter = niter,
    nburnin = nburnin,
    thin = nthin,
    nchains = 2,
    summary = TRUE,
    samplesAsCodaMCMC = TRUE
  )
end_time <- Sys.time()
run_time <- end_time - start_time
run_time

```

```{r}
library(coda)
post_summary <- post_samples$summary$all.chains 
post_summary[c('tau',
               'sqrt_Wt_diag[1]',
               'sqrt_Wt_diag[2]',
               'sqrt_Wt_diag[3]'), ]



library(tidybayes)
tidy_post_samples <- post_samples$samples %>% tidy_draws()

tidy_post_samples %>%
  select(
    .chain,
    .iteration,
    .draw,
    'tau',
    'sqrt_Wt_diag[1]',
    'sqrt_Wt_diag[2]',
    'sqrt_Wt_diag[3]'
  ) %>%
  gather(vars, value, -.chain, -.iteration, -.draw) %>%
  ggplot(aes(x = .iteration, y = value)) +
  geom_path(aes(color = factor(.chain)), size = 0.25,
            show.legend = FALSE) +
  facet_wrap( ~ vars, scales = "free_y", nrow = 3) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())

post_sum_theta <-
  as.data.frame(post_summary) %>%  rownames_to_column() %>%
  filter(str_detect(rowname, "theta")) %>%
  select(rowname, `95%CI_low`, Mean, `95%CI_upp`) %>%
  separate(rowname, into = c("x1", "x2"), sep = ",") %>%
  mutate(component = as.numeric(gsub(".*?([0-9]+).*", "\\1", x1))) %>%
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", x2))) %>%
  select(component, time, `95%CI_low`, Mean, `95%CI_upp`)
str(post_sum_theta)

theta_true_df <- data.frame(t(theta)) %>%
  rownames_to_column() %>%
  mutate(time = as.numeric(rowname)) %>%
  select(-rowname) %>%
  gather(key, theta,-time) %>%
  mutate(component = as.numeric(gsub(".*?([0-9]+).*", "\\1", key))) %>%
  select(component, time, theta)
str(theta_true_df)

theta_df <-
  inner_join(theta_true_df, post_sum_theta, by = c("component", "time"))

ggplot(data = post_sum_theta, aes(x = time)) +
  #geom_path(aes(y = theta), color = "red", size = 0.4) +
  geom_ribbon(aes(ymin = `95%CI_low`, ymax = `95%CI_upp`), fill = "lightgray", alpha = 0.7) +
  geom_path(aes(y = Mean), col = "blue", size = 0.4) +
  facet_wrap(
    ~ component,
    nrow = 2,
    scales = "free",
    labeller = label_bquote(theta[.(component)])
  ) +
  ylab("") +
  xlab("Time") +
  theme_bw() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())

```

Define the constants, data and initials lists for the `nimble` model.



```{r}
n <- ncol(post_samples$samples$chain1)

Rhat_all <-  sapply(1:n, function(x) {
  rstan::Rhat(cbind(post_samples$samples$chain1[, x],
                    post_samples$samples$chain2[, x]))
})

ess_all <- sapply(1:n, function(x) {
  rstan::ess_bulk(cbind(post_samples$samples$chain1[, x],
                        post_samples$samples$chain2[, x]))
})

ess_all_tail <- sapply(1:n, function(x) {
  rstan::ess_tail(cbind(post_samples$samples$chain1[, x],
                        post_samples$samples$chain2[, x]))
})

max(Rhat_all, na.rm = T)
min(ess_all, na.rm = T)
min(ess_all_tail, na.rm = T)
```







## Daily data linear growth model -----

```{r}
integratedcodeUni <- nimbleCode({
  tau ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  for (t in 1:Tt) {
    Vt[t] <- tau ^ 2
  }
  
  sqrt_Wt ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf)
  
  Wt <-  sqrt_Wt ^ 2
  
  mt[1] <- m0
  Ct[1] <- C0
  
  for (t in 1:Tt) {
    at[t] <- Gt * mt[t]
    Rt[t] <- Gt * Ct[t] * Gt + Wt
    ft[t] <- (Ft[t] * at[t])
    Qt[t] <- (Ft[t] * Rt[t] * Ft[t] + Vt[t])
    yt[t] ~ dnorm(mean = ft[t], var = Qt[t])
    At[t] <- (Rt[t] * Ft[t]) / Qt[t]
    mt[t + 1] <- at[t] + (At[t] * (yt[t] - ft[t]))
    Ct[t + 1] <- Rt[t] - (At[t] * At[t]) * Qt[t]
  }
  
  theta[1:(Tt + 1)] <- nim_bsample_uni(
    mt = mt[1:(Tt + 1)],
    Ct = Ct[1:(Tt + 1)],
    at = at[1:Tt],
    Gt = Gt,
    Rt = Rt[1:Tt]
  )
  
})
```

```{r}

nim_bsample_uni <- nimbleFunction(
  run = function(mt = double(1),
                 Ct = double(1),
                 at = double(1),
                 Gt = double(1),
                 Rt = double(1)) {
    returnType(double(1))  # return type declaration
    # identifying the dimension of the observation equation and evolution equation
    Tt <- nimDim(at)[1] # total time points
    
    theta <-
      nimArray(0, dim = c(1, Tt + 1)) # including theta0 at the 1st column
    # forward j = 1:(Tt+1) index transformed to t = (Tt+1):1 index as t = (Tt+2) - j
    j <- 1
    t <- (Tt + 2) - j
    theta[t] <-
      rnorm(
        n = 1,
        mean = mt[t],
        sd = sqrt(Ct[t])
      )
    for (j in 2:(Tt + 1)) {
      t <- (Tt + 2) - j
      Bt <- Ct[t] * t(Gt) * inverse(Rt[t])
      ht <- (mt[ t] + Bt * (theta[t + 1] - at[ t]))
      Ht <- Ct[t] - Bt * Gt * Ct[ t]
      theta[t] <-
        rnorm(
          n = 1,
          mean = ht,
          sd = sqrt(Ht)
        )
    }
    
    return(theta)
  },
  check = FALSE
)
```

```{r Ex 11.16 daily data linear growth model}

#linearGrowth <- readRDS("data/linearGrowth.rds")
# fit a linear growth model for the daily data
yt <- site_daily$max.ozone
Tt <- length(yt)

Ft <- rep(1, Tt)

# Intercept and seasonal component with period of 24hrs

Gt <- 1

# initials
m0 <- mean(yt, na.rm = TRUE)
C0 <- 1

const_list <- list(Tt = Tt,
                   m0 = as.matrix(m0),
                   C0 = as.matrix(C0),
                   p = 1)
dat_list <- list(yt = yt, Ft = Ft, Gt = Gt)
init_list <- list(
  tau = 0.01,
  sqrt_Wt = sqrt(0.1),
  theta = rep(0, Tt+1)
)

Rmodel <-
  nimbleModel(integratedcodeUni,
              constants = const_list,
              data = dat_list,
              inits = init_list)
Rmodel$initializeInfo()
Rmodel$calculate()
Cmodel <- compileNimble(Rmodel, showCompilerOutput = FALSE)
conf <-
  configureMCMC(Rmodel, monitors = c("tau", "sqrt_Wt", "theta"))

Rmcmc <- buildMCMC(conf)
Cmcmc <-
  compileNimble(
    Rmcmc,
    project = Cmodel,
    resetFunctions = TRUE,
    showCompilerOutput = FALSE
  )

niter <- 20000
nburnin <- 0.5 * niter
nthin <- 1
start_time <- Sys.time()
post_samples <-
  runMCMC(
    Cmcmc,
    niter = niter,
    nburnin = nburnin,
    thin = nthin,
    nchains = 2,
    summary = TRUE,
    samplesAsCodaMCMC = TRUE
  )
end_time <- Sys.time()
run_time <- end_time - start_time
run_time
```

```{r}
library(coda)
post_summary <- post_samples$summary$all.chains 
post_summary[c('tau',
               'sqrt_Wt_diag[1]',
               'sqrt_Wt_diag[2]'), ]



library(tidybayes)
tidy_post_samples <- post_samples$samples %>% tidy_draws()

tidy_post_samples %>%
  select(
    .chain,
    .iteration,
    .draw,
    'tau',
    'sqrt_Wt_diag[1]',
    'sqrt_Wt_diag[2]'
  ) %>%
  gather(vars, value, -.chain, -.iteration, -.draw) %>%
  ggplot(aes(x = .iteration, y = value)) +
  geom_path(aes(color = factor(.chain)), size = 0.25,
            show.legend = FALSE) +
  facet_wrap( ~ vars, scales = "free_y", nrow = 3) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())

post_sum_theta <-
  as.data.frame(post_summary) %>%  rownames_to_column() %>%
  filter(str_detect(rowname, "theta")) %>%
  select(rowname, `95%CI_low`, Mean, `95%CI_upp`) %>%
  separate(rowname, into = c("x1", "x2"), sep = ",") %>%
  mutate(component = as.numeric(gsub(".*?([0-9]+).*", "\\1", x1))) %>%
  mutate(time = as.numeric(gsub(".*?([0-9]+).*", "\\1", x2))) %>%
  select(component, time, `95%CI_low`, Mean, `95%CI_upp`)
str(post_sum_theta)

theta_true_df <- data.frame(t(theta)) %>%
  rownames_to_column() %>%
  mutate(time = as.numeric(rowname)) %>%
  select(-rowname) %>%
  gather(key, theta,-time) %>%
  mutate(component = as.numeric(gsub(".*?([0-9]+).*", "\\1", key))) %>%
  select(component, time, theta)
str(theta_true_df)

theta_df <-
  inner_join(theta_true_df, post_sum_theta, by = c("component", "time"))

ggplot(data = post_sum_theta, aes(x = time)) +
  #geom_path(aes(y = theta), color = "red", size = 0.4) +
  geom_ribbon(aes(ymin = `95%CI_low`, ymax = `95%CI_upp`), fill = "lightgray", alpha = 0.7) +
  geom_path(aes(y = Mean), col = "blue", size = 0.4) +
  facet_wrap(
    ~ component,
    nrow = 2,
    scales = "free",
    labeller = label_bquote(theta[.(component)])
  ) +
  ylab("") +
  xlab("Time") +
  theme_bw() +
  theme(panel.grid = element_blank(),
        strip.background = element_blank())

```



