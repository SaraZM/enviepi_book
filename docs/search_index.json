[["hazards.html", "Chapter 10 Environmental hazards-spatial models Example 10.1 Spatial patterns of benzene concentrations in Montreal, QC, Canada Example 10.2: Examining the log concentrations of benzene in Montreal Example 10.3: Mapping the locations of ozone monitoring sites in New York State Example 10.5: Variogram Example 10.6 Basic spatial modelling and prediction of benzene in Montreal Example 10.9 Spatial modelling of Benzene in Montreal Example 10.11: INLA, creating a mesh Example 10.12: Fitting an SPDE model using Râ€“INLA: benzene concentration in Montreal Example 10.13: Directional variograms Example 10.14: Spatial modeling of malaria in Gambia", " Chapter 10 Environmental hazards-spatial models This chapter contains the basic theory for spatial processes and a number of approaches to modelling point-referenced spatial data. From this chapter, the reader will have gained an understanding of the following topics: Visualization techniques needed for both exploring and analyzing spatial data and communicating its features through the use of maps. Exploring the underlying structure of spatial data and methods for characterizing dependence over space. Second-order theory for spatial processes including the covariance. The variogram for measuring spatial associations. Stationarity and isotropy. Methods for spatial prediction, using both classical methods (kriging) as well as modern methods (Bayesian kriging). Non-stationarity fields. Example 10.1 Spatial patterns of benzene concentrations in Montreal, QC, Canada Map the locations of the monitoring stations in Montreal. library(cowplot) library(geoR) library(ggmap) library(spdep) # Load data on benzene concentration in Montreal benzene &lt;- read.csv(&quot;data/montreal_benzene_apr.csv&quot;) # TODO: Add description of the data, this is the April campaign # create a new variable in &quot;sp&quot; format and define coordinates benzene_geo &lt;- benzene coordinates(benzene_geo) &lt;- ~ lon + lat proj4string(benzene_geo) &lt;- CRS(&quot;+proj=longlat +datum=WGS84&quot;) # specify the bounding box latLongBox = bbox(benzene_geo) location = c(latLongBox[1, 1] - 0.05, latLongBox[2, 1] - 0.05, latLongBox[1, 2] + 0.1, latLongBox[2, 2] + 0.05) # create map with location dots marked on it in MontrelBenzeneMap &lt;- get_stamenmap(bbox = location, zoom = 10) ggmap(MontrelBenzeneMap) + geom_point(data = benzene, aes(x = lon, y = lat, size = Benzene), col = &quot;#011f4b&quot;, alpha = 0.45) + theme_void() Using the geoR package we can also plot the following: the locations of the sampling sites the concentrations of ozone in relation to the x and y coordinates and a histogram of the concentrations indicating the distribution of concentrations together with an estimate of the density. # convert data to utm coordinates benzene_utm &lt;- spTransform(benzene_geo, CRS(&quot;+proj=utm +zone=18 +ellps=WGS72&quot;)) # Save the utm as a data frame benzene_utm_df &lt;- as.data.frame(benzene_utm) colnames(benzene_utm_df) &lt;- c(&quot;Benzene&quot;, &quot;X&quot;, &quot;Y&quot;) # Save as geodata to generate the geodata plot benzene_geodata &lt;- as.geodata(benzene_utm_df, coords.col = 2:3, data.col = 1) plot(benzene_geodata) Example 10.2: Examining the log concentrations of benzene in Montreal # Histogram for the log of the benzene concentration par(mfrow=c(1,2)) log_histogram &lt;- hist(log(benzene$Benzene), main = &quot;&quot;, xlab = &quot;log(Benzene)&quot;) qqnorm(log(benzene$Benzene), bty = &quot;n&quot;) qqline(log(benzene$Benzene)) Example 10.3: Mapping the locations of ozone monitoring sites in New York State # Load the metadata giving the site coordinates ny_data &lt;- read.csv(&quot;data/NY_metadata.txt&quot;, sep=&quot;&quot;) # Now copy ny_data into ny_data_sp and convert data to &quot;sp&quot; format ny_data_sp &lt;- ny_data coordinates(ny_data_sp) &lt;- ~Longitude+Latitude # assign a reference system to ny_data_sp proj4string(ny_data_sp) &lt;- CRS(&quot;+proj=longlat +ellps=WGS84&quot;) # We next specify a bounding box - a 2 x 2 matrix of corners of the geographic # area. Then specify the range of locations within the box. # Note: location must bounding box format be in left -bottom -right -top latLongBox &lt;- bbox(ny_data_sp) location &lt;- c(latLongBox [1, 1] - 0.2 , latLongBox [2, 1] - 0.2, latLongBox [1, 2] + 0.2 , latLongBox [2, 2] + 0.2) # Now create the map with location dots NYmap &lt;- get_stamenmap( bbox = location, zoom = 8 ) ggmap(NYmap) + geom_point( data = ny_data, aes(x = Longitude , y = Latitude), size = 4, color = &quot;darkred&quot; ) + theme_void() Example 10.5: Variogram library(gstat) benzene_utm_geo &lt;- benzene_utm_df # get the coordinates in kms and turn into a Spatial object benzene_utm_geo[,c(&quot;X&quot;, &quot;Y&quot;)] &lt;- benzene_utm_geo[,c(&quot;X&quot;, &quot;Y&quot;)]/1000 coordinates(benzene_utm_geo) &lt;- ~ X + Y # Estimate variogram intercept only benzene_inter_vgm &lt;- variogram(log(Benzene)~ 1, data = benzene_utm_geo, cutoff = 20, # cutoff distance width = 20/10 # bins width ) benzene_inter_vgm_fit &lt;- fit.variogram(benzene_inter_vgm, model = vgm(0.1, &quot;Exp&quot;, 15, 0.02)) benzene_inter_vgm_fit ## model psill range ## 1 Nug 0.01616521 0.00000 ## 2 Exp 0.17301314 23.97153 # Estimate variogram using coordinates benzene_vgm &lt;- variogram(log(Benzene)~ X + Y, data = benzene_utm_geo, cutoff = 20, # cutoff distance width = 20/10 # bins width ) benzene_vgm_fit &lt;- fit.variogram(benzene_vgm, model = vgm(0.1, &quot;Exp&quot;, 3, 0.02)) benzene_vgm_fit ## model psill range ## 1 Nug 0.01638881 0.000000 ## 2 Exp 0.05598753 7.365469 plot_inter_variog &lt;- plot(benzene_inter_vgm, benzene_inter_vgm_fit, bty = &quot;n&quot;) plot_coord_variog &lt;- plot(benzene_vgm, benzene_vgm_fit, bty = &quot;n&quot;) plot_grid(plot_inter_variog, plot_coord_variog, labels = &quot;auto&quot;) Example 10.6 Basic spatial modelling and prediction of benzene in Montreal # Generate grid MtlPred &lt;- expand.grid(seq (580, 615 , 0.5), seq (5020, 5060 , 0.5) ) # change names grid names(MtlPred)[ names(MtlPred)==&quot;Var1&quot;] &lt;- &quot;X&quot; names(MtlPred)[ names(MtlPred)==&quot;Var2&quot;] &lt;- &quot;Y&quot; # make the grid a Spatial object coordinates (MtlPred) = ~ X + Y gridded(MtlPred) = TRUE # define the model based on the variogram fit from the previous example mod &lt;- vgm (0.053 , &quot;Exp&quot;, 5.54, 0.0122) # use ordinary kriging to predict values in the grid x &lt;- krige(log(Benzene) ~ X + Y, benzene_utm_geo , MtlPred , model = mod ) ## [using universal kriging] # Plot the ordinary kriging predictions and their variance monitor_loc &lt;- list(&#39;sp.points&#39;, benzene_utm_geo, pch=19, cex=.8, col=&#39;midnightblue&#39;) krig_pred &lt;- spplot ( x[&quot;var1.pred&quot;], main = &quot;Ordinary kriging predictions &quot;, col.regions = viridis::plasma(20), sp.layout = list(monitor_loc) ) krig_var &lt;- spplot ( x[&quot;var1.var&quot;], main = &quot;Ordinary kriging variance &quot;, col.regions = viridis::plasma(20), sp.layout = list(monitor_loc) ) plot_grid(krig_pred, krig_var, labels = &quot;auto&quot;) Example 10.9 Spatial modelling of Benzene in Montreal Nimble library(coda) library(geoR) library(magrittr) library(nimble) library(spdep) library(tidyverse) library(tidybayes) source(&quot;functions/utilityfunctions.R&quot;) # Load data on benzene concentration in Montreal benzene &lt;- read.csv(&quot;data/montreal_benzene_apr.csv&quot;) # create a new variable in &quot;sp&quot; format and define coordinates benzene_geo &lt;- benzene coordinates(benzene_geo) &lt;- ~ lon + lat proj4string(benzene_geo) &lt;- CRS(&quot;+proj=longlat +datum=WGS84&quot;) benzene_utm &lt;- spTransform(benzene_geo, CRS(&quot;+proj=utm +zone=18 +ellps=WGS72&quot;)) # Save the utm as a data frame benzene_utm_df &lt;- as.data.frame(benzene_utm) # Change coordinates to kilometers and observations to the log scale Mtl_benzene_sample &lt;- data.frame( y = log(benzene_utm_df$Benzene), easting = benzene_utm_df$lon / 1000, northing = benzene_utm_df$lat / 1000 ) # Compute the distance matrix obsCoords &lt;- unname(as.matrix(Mtl_benzene_sample[,c(&quot;easting&quot;, &quot;northing&quot;)])) obsDist &lt;- fields::rdist(obsCoords) Example10_9Code &lt;- nimbleCode ({ # Covariance matrix spatial effect Sigma[1:n, 1:n] &lt;- (sigma ^ 2) * exp(-distMatrix[1:n, 1:n] / phi) + (tau ^ 2) * identityMatrix(d = n) for (site in 1:n) { mean.site[site] &lt;- beta0 + beta1 * easting[site] + beta2 * northing[site] } y[1:n] ~ dmnorm(mean.site[1:n], cov = Sigma[1:n, 1:n]) # Set up the priors for the spatial model sigma ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf) sigma_sq &lt;- sigma^2 tau ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf) tau_sq &lt;- tau^2 phi_inv ~ dgamma(shape = 2, scale = 2) phi &lt;- 1 / phi_inv # prior for the coefficients beta0 ~ dnorm (0, sd = 10) beta1 ~ dnorm (0, sd = 10) beta2 ~ dnorm (0, sd = 10) }) Define the constants, data and initials lists for the nimble model. # Define the constants, data, parameters and initial values easting_scaled &lt;- as.vector(scale(Mtl_benzene_sample$easting)) northing_scaled &lt;- as.vector(scale(Mtl_benzene_sample$northing)) constants &lt;- list(n = nrow(Mtl_benzene_sample)) ex.data &lt;- list(y = Mtl_benzene_sample$y, easting = easting_scaled, northing = northing_scaled, distMatrix = obsDist) params &lt;- c( &quot;beta0&quot;, &quot;beta1&quot;,&quot;beta2&quot;, &quot;sigma_sq&quot;, &quot;phi&quot;, &quot;tau_sq&quot;) inits &lt;- list( sigma = 0.1, phi_inv = 6/max(obsDist), tau = 0.1) # Run model in nimble start_time &lt;- Sys.time() mcmc.out &lt;- nimbleMCMC( code = Example10_9Code, constants = constants, data = ex.data, inits = inits, monitors = params, niter = 30000, nburnin = 15000, thin = 14, WAIC = TRUE, nchains = 2, summary = TRUE, samplesAsCodaMCMC = TRUE ) end_time &lt;- Sys.time() run_time &lt;- end_time - start_time run_time mcmc.out$WAIC ## nimbleList object of type waicList ## Field &quot;WAIC&quot;: ## [1] -31.38491 ## Field &quot;lppd&quot;: ## [1] 19.00464 ## Field &quot;pWAIC&quot;: ## [1] 3.312188 min(coda::effectiveSize(mcmc.out$samples)) ## [1] 100.121 plot(mcmc.out$samples[, c(&quot;beta0&quot;)], bty = &quot;n&quot;, main = &quot;beta0&quot;) plot(mcmc.out$samples[, c(&quot;beta1&quot;)], bty = &quot;n&quot;, main = &quot;beta1&quot;) plot(mcmc.out$samples[, c(&quot;beta2&quot;)], bty = &quot;n&quot;, main = &quot;beta2&quot;) plot(mcmc.out$samples[, c(&quot;sigma_sq&quot;)], bty = &quot;n&quot;, main = &quot;sigma&quot;) plot(mcmc.out$samples[, c(&quot;tau_sq&quot;)], bty = &quot;n&quot;, main = &quot;tau&quot;) plot(mcmc.out$samples[, c(&quot;phi&quot;)], bty = &quot;n&quot;, main = &quot;phi&quot;) mcmc.out$summary$all.chains ## Mean Median St.Dev. 95%CI_low 95%CI_upp ## beta0 0.08043343 0.11906839 0.246369749 -0.5657046509 0.44026928 ## beta1 0.06796635 0.06641440 0.094024785 -0.1116415180 0.27415371 ## beta2 0.04025232 0.05089251 0.102375749 -0.1944293620 0.21364688 ## phi 13.96807504 7.28653025 20.439210251 1.8587221408 69.11809501 ## sigma_sq 0.12722089 0.07401729 0.155009174 0.0309302814 0.59989080 ## tau_sq 0.01285013 0.01276744 0.006849039 0.0003551619 0.02653876 # Load centroids for spatial prediction Mtl_centroids &lt;- read.csv(&quot;data/montreal_shp/centroids_mtl.csv&quot;) coordinates(Mtl_centroids) &lt;- ~ X + Y proj4string(Mtl_centroids) &lt;- CRS(&quot;+proj=longlat +datum=WGS84&quot;) Mtl_centroids_utm &lt;- spTransform(Mtl_centroids, CRS(&quot;+proj=utm +zone=18 +ellps=WGS72&quot;)) # Save the utm as a data frame Mtl_centroids_df &lt;- as.data.frame(Mtl_centroids_utm) predCoords &lt;- unname(as.matrix(Mtl_centroids_df))/1000 Following the posterior predictive distribution we have to define a model for the predictions. library(coda) tidy_post_samples &lt;- mcmc.out$samples %&gt;% tidy_draws() tidy_post_samples ## # A tibble: 2,142 Ã— 9 ## .chain .iteration .draw beta0 beta1 beta2 phi sigma_sq tau_sq ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 1 0.0980 0.110 -0.0488 3.59 0.0746 0.000619 ## 2 1 2 2 0.158 0.0777 0.0383 4.17 0.0869 0.000210 ## 3 1 3 3 0.00777 0.0466 0.104 7.47 0.0961 0.00990 ## 4 1 4 4 0.174 -0.0112 0.134 4.55 0.0350 0.0149 ## 5 1 5 5 0.0609 -0.0300 0.113 3.95 0.0548 0.0139 ## 6 1 6 6 0.213 0.143 0.0596 2.50 0.0787 0.00578 ## 7 1 7 7 0.192 0.0411 0.155 2.97 0.0447 0.00701 ## 8 1 8 8 0.168 0.0707 0.132 4.26 0.106 0.00935 ## 9 1 9 9 0.243 -0.000570 0.0980 6.01 0.0854 0.00263 ## 10 1 10 10 0.157 0.0887 0.0646 3.11 0.0465 0.00635 ## # â€¦ with 2,132 more rows # Extract posterior samples for each of the parameters of itnerest post_beta0 &lt;- tidy_post_samples$beta0 post_beta1 &lt;- tidy_post_samples$beta1 post_beta2 &lt;- tidy_post_samples$beta2 post_sigmasq &lt;- tidy_post_samples$sigma_sq post_phi &lt;- tidy_post_samples$phi post_tausq &lt;- tidy_post_samples$tau_sq # Define coordinates for predictive locations predCoords &lt;- Mtl_centroids_df / 1000 predCoords[,1] &lt;- (predCoords[,1] - mean(Mtl_benzene_sample$easting)) / sd(Mtl_benzene_sample$easting) predCoords[,2] &lt;- (predCoords[,2] - mean(Mtl_benzene_sample$northing)) / sd(Mtl_benzene_sample$northing) n0 &lt;- nrow(predCoords) L &lt;- length(post_tausq) obsMu &lt;- cbind(1, easting_scaled, northing_scaled) %*% t(cbind(post_beta0, post_beta1, post_beta2)) predMu &lt;- cbind(1, as.matrix(predCoords)) %*% t(cbind(post_beta0, post_beta1, post_beta2)) pred2obsDist &lt;- fields::rdist(predCoords, obsCoords) Rcpp::sourceCpp(&quot;functions/prediction_marginal_gp12.cpp&quot;) args(prediction_marginal_gp12) ## function (y, obsMu, predMu, obsDistMat, pred2ObsDistMat, sigmasq, ## phi, tausq, iterprint) ## NULL system.time(pred_samples &lt;- prediction_marginal_gp12(y = Mtl_benzene_sample$y, obsMu = obsMu, predMu = predMu, obsDistMat = obsDist, pred2ObsDistMat = pred2obsDist, sigmasq = post_sigmasq, phi = post_phi, tausq = post_tausq, iterprint = 1000)) ## Prediction upto the 0th MCMC sample is completed ## Prediction upto the 1000th MCMC sample is completed ## Prediction upto the 2000th MCMC sample is completed ## user system elapsed ## 8.99 0.00 25.19 ## user system elapsed ## 227.320 0.290 30.199 str(pred_samples) ## num [1:597, 1:2142] -0.18418 -0.30023 -0.16395 -0.00605 -0.12666 ... predict_res_dt &lt;- data.frame( xcoord = predCoords[,1], ycoord = predCoords[,2], post.mean = apply(pred_samples, 1, mean), post.sd = apply(pred_samples, 1, sd), q2.5 = apply(pred_samples, 1, function(x) quantile(x, prob = 0.025)), q50 = apply(pred_samples, 1, function(x) quantile(x, prob = 0.5)), q97.5 = apply(pred_samples, 1, function(x) quantile(x, prob = 0.975))) Mtl_shape &lt;- st_read(&quot;data/montreal_shp/temp1.shp&quot;, quiet = TRUE) %&gt;% st_as_sf() Mtl_shape$mean_benzene &lt;- predict_res_dt$post.mean Mtl_shape$sd &lt;- predict_res_dt$post.sd benzene_post_mean &lt;- ggplot() + geom_sf(data = Mtl_shape, aes(fill = mean_benzene), color = NA) + geom_point(data = benzene, aes(x = lon, y = lat), color = &quot;midnightblue&quot;) + theme_void() + labs(fill = &quot;Posterior mean&quot;) benzene_post_sd &lt;- ggplot() + geom_sf(data = Mtl_shape, aes(fill = sd), color = NA) + geom_point(data = benzene, aes(x = lon, y = lat), color = &quot;midnightblue&quot;) + theme_void() + labs(fill = &quot;Posterior sd&quot;) plot_grid(benzene_post_mean, benzene_post_sd, labels = &quot;auto&quot;) Stan benzene_data &lt;- read.csv(&quot;data/montreal_benzene_apr.csv&quot;) # create a new variable in &quot;sp&quot; format and define coordinates benzene_data_geo &lt;- benzene_data coordinates(benzene_data_geo) &lt;- ~ lon + lat proj4string(benzene_data_geo) &lt;- CRS(&quot;+proj=longlat +datum=WGS84&quot;) benzene_data_utm &lt;- spTransform(benzene_data_geo, CRS(&quot;+proj=utm +zone=18 +ellps=WGS72&quot;)) # Save the utm as a data frame benzene_utm_df &lt;- as.data.frame(benzene_data_utm) # change the observed values to the log scale and the coordinates to km&#39;s Mtl_benzene_sample &lt;- data.frame( y = log(benzene_utm_df$Benzene), easting = benzene_utm_df$lon / 1000, northing = benzene_utm_df$lat / 1000 ) # Compute the distance matrix Dist &lt;- as.matrix(dist(Mtl_benzene_sample[,c(&quot;easting&quot;, &quot;northing&quot;)])) data { int&lt;lower=1&gt; N; int&lt;lower=0&gt; p; vector[N] y; matrix[N,N] dist_matrix; matrix[N,p] X; } parameters { real&lt;lower=0&gt; phi; real&lt;lower=0&gt; tau; real&lt;lower=0&gt; sigma; vector[p] beta; real beta0; } model { vector[N] mu; matrix[N, N] L; matrix[N, N] Sigma; real sigma_sq = square(sigma); real tau_sq = square(tau); for(i in 1:(N-1)){ for(j in (i+1):N){ Sigma[i,j] = sigma_sq*exp(-dist_matrix[i,j]/phi); Sigma[j,i] = Sigma[i,j]; } } // diagonal elements for(i in 1:N) { Sigma[i,i] = sigma_sq + tau_sq; mu[i] = beta0 + X[i,]*beta; } L = cholesky_decompose(Sigma); beta0 ~ normal(0,10); beta ~ normal(0,10); phi ~ inv_gamma(5, 5); tau ~ cauchy(0,1); sigma ~ cauchy(0,1); y ~ multi_normal_cholesky(mu, L); } N &lt;- nrow(benzene_utm_df) # Change coordinates to kilometers X &lt;- data.frame(easting = as.vector(scale(Mtl_benzene_sample$easting/1000)), northing = as.vector(scale(Mtl_benzene_sample$northing/1000))) ex.data &lt;- list( N = N, p = 2, y = log(benzene_utm_df$Benzene), dist_matrix = Dist, X = as.matrix(X) ) Example10_9Stan &lt;- stan( file = &quot;functions/Example10_9.stan&quot;, data = ex.data, warmup = 10000, iter = 20000, chains = 2, thin = 10, pars = c(&quot;beta0&quot;, &quot;beta&quot;,&quot;sigma&quot;, &quot;tau&quot;, &quot;phi&quot;), include = TRUE ) traceplot(Example10_9Stan, pars = c(&quot;beta0&quot;,&quot;beta&quot;,&quot;sigma&quot;, &quot;tau&quot;, &quot;phi&quot;)) summary_exp_stan &lt;- summary( Example10_9Stan, pars = c(&quot;beta0&quot;,&quot;beta&quot;, &quot;phi&quot;, &quot;sigma&quot;, &quot;tau&quot;), probs = c(0.025, 0.975) ) summary_exp_stan$summary ## mean se_mean sd 2.5% 97.5% n_eff ## beta0 0.15248292 0.0018867485 0.08324219 -0.040680057 0.2996809 1946.520 ## beta[1] 0.05076669 0.0015246951 0.06309862 -0.061347465 0.1852491 1712.670 ## beta[2] 0.07961114 0.0016110728 0.06971081 -0.076474942 0.2030695 1872.276 ## phi 3.65709252 0.0526405158 2.16670101 1.509704371 8.6373547 1694.173 ## sigma 0.23259289 0.0009729169 0.04092984 0.166889872 0.3249775 1769.818 ## tau 0.08696572 0.0009198663 0.04009834 0.006566465 0.1528727 1900.217 ## Rhat ## beta0 1.0022855 ## beta[1] 0.9992031 ## beta[2] 0.9999323 ## phi 1.0004915 ## sigma 1.0001710 ## tau 0.9994904 Example 10.11: INLA, creating a mesh library(geoR) library(INLA) library(spdep) benzene_data &lt;- read.csv(&quot;data/montreal_benzene_apr.csv&quot;) # create a new variable in &quot;sp&quot; format and define coordinates benzene_data_loc &lt;- benzene_data coordinates(benzene_data_loc) &lt;- ~ lon + lat proj4string(benzene_data_loc) &lt;- CRS(&quot;+proj=longlat +datum=WGS84&quot;) benzene_data_utm &lt;- spTransform(benzene_data_loc, CRS(&quot;+proj=utm +zone=18 +ellps=WGS72&quot;)) # Save the utm as a data frame locations_df &lt;- as.data.frame(benzene_data_utm@coords) benzene_utm_df &lt;- data.frame( ID = 1:nrow(benzene_data), X = benzene_data_utm@coords[,1]/1000, Y = benzene_data_utm@coords[,2]/1000, logbenzene = log(benzene_data_utm$Benzene)) # change the observed values to the log scale and the coordinates to km&#39;s mesh = inla.mesh.create(locations_df, cutoff = 0.01, refine =(list(min.angle =20))) plot(mesh , col=&quot;gray&quot;, main=&quot;&quot;) # ukmap &lt;- readShapeLines(&quot;uk_BNG.shp&quot;) plot(mesh , col=&quot;gray&quot;, main=&quot;&quot;) # lines(ukmap) # points(locations , col=&quot;red&quot;, pch=20,bg=&quot;red&quot;) Example 10.12: Fitting an SPDE model using Râ€“INLA: benzene concentration in Montreal # Field std . dev . for theta =0 sigma0 = 1 # find the range of the location data size = min(c(diff(range(mesh$loc[, 1])), diff (range(mesh$loc[, 2])))) # A fifth of the approximate domain width . range0 = size/5 kappa0 = sqrt(8)/range0 tau0 = 1/(sqrt (4*pi)*kappa0*sigma0) spde = inla.spde2.matern ( mesh, B.tau = cbind(log (tau0), -1, +1), B.kappa = cbind(log (kappa0), 0, -1), theta.prior.mean = c(0 , 0), constr = TRUE ) formula = logbenzene ~ 1 + X + Y + f(ID , model = spde) model = inla( formula, family = &quot;gaussian&quot;, data = benzene_utm_df , control.predictor = list(compute = TRUE), control.compute = list(dic = TRUE , config = TRUE) ) model$summary.fixed ## mean sd 0.025quant 0.5quant 0.975quant ## (Intercept) 8.263107109 118.01744834 -189.26686123 -5.4724133487 298.73720629 ## X 0.014532810 0.02130267 -0.02563718 0.0132910509 0.06340354 ## Y -0.003363563 0.02371941 -0.06108419 -0.0006481981 0.03642514 ## mode kld ## (Intercept) -20.057620990 5.350437e-05 ## X 0.011915185 7.755183e-05 ## Y 0.002407428 3.418641e-05 Example 10.13: Directional variograms ### Compute and plot the directional variogram CA.geo &lt;- as.geodata( benzene_utm_df , coords.col = 2:3 , data.col=1) CA.vario4 &lt;- variog4(CA.geo ) plot(CA.vario4) Example 10.14: Spatial modeling of malaria in Gambia library(dplyr) # to manipulate the data library(geoR) # to get the dataset library(ggmap) # to plot the map library(nimble) # for modeling library(raster) # to get the environmental data library(rgdal) # for adding and transforming coordinates library(sf) # manipulate spatial data library(sp) # for manipulating spatial data library(stringr) # to analyze posterior library(viridis) # for a more cheerful color palette data(gambia) # gambia dataset from geoR package theme_clear &lt;- function(){ theme( panel.grid.major = element_blank(), # remove background grid panel.grid.minor = element_blank(), panel.background = element_blank(), # remove grey background axis.line = element_line(colour = &quot;black&quot;), # keep axis line text=element_text(size=12) ) } Since the data is given at the individual level, we want to aggregate the malaria tests by village. If we explore the data frame we see that there are 2035 individuals at 65 villages. head(gambia) dim(gambia) dim(unique(gambia[, c(&quot;x&quot;, &quot;y&quot;)])) We create a new data frame aggregated by village containing the coordinates, the number of malaria tests, the prevalence and the altitude. malaria_village &lt;- group_by(gambia, x, y) |&gt; summarize(total = n(), positive = sum(pos), prev = positive / total) |&gt; as.data.frame() head(malaria_village) # create a new variable in &quot;sp&quot; format and define coordinates malaria_utm &lt;- malaria_village coordinates(malaria_utm) &lt;- ~ x + y proj4string(malaria_utm) &lt;- CRS(&quot;+proj=utm +zone=28&quot;) # convert to long lat malaria_geo &lt;- spTransform(malaria_utm, CRS(&quot;+proj=longlat +datum=WGS84&quot;)) # add long lat coordinates to malaria dataframe malaria_village[, c(&quot;long&quot;, &quot;lat&quot;)] &lt;- coordinates(malaria_geo) # specify the bounding box latLongBox = bbox(malaria_geo) location = c(latLongBox[1, 1] - 0.05, latLongBox[2, 1] - 0.05, latLongBox[1, 2] + 0.05, latLongBox[2, 2] + 0.05) # create map with location dots marked on it in GambiaMap &lt;- get_stamenmap(bbox = location, zoom = 11, type = terrain-background) ggmap(GambiaMap) + geom_point(data = malaria_village, aes(x = long, y = lat, col = prev), size = 2) + scale_color_viridis() + theme_void() altitude_gambia &lt;- getData(name = &quot;alt&quot;, country = &quot;GMB&quot;, mask = TRUE) %&gt;% projectRaster(crs = CRS(&quot;+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs&quot;)) # Convert raster to polygons to plot using ggmap altitude_pol &lt;- rasterToPolygons(altitude_gambia) ggmap(GambiaMap) + inset_raster( as.raster(altitude_gambia), xmin = altitude_gambia@extent[1], xmax = altitude_gambia@extent[2], ymin = altitude_gambia@extent[3], ymax = altitude_gambia@extent[4] ) + theme_void() # extract from altitude_gambia the altitude values at malaria_village locations and add it to data frame malaria_village$alt &lt;- raster::extract(altitude_gambia, malaria_village[, c(&quot;long&quot;, &quot;lat&quot;)]) head(malaria_village) Nimble Example10_14_Nimble &lt;- nimbleCode({ # Define priors sigma ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf) sigma_sq &lt;- sigma ^ 2 tau ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf) tau_sq &lt;- tau ^ 2 phi ~ dexp(rate = 1/45.51057) # maxdist/6 Sigma[1:n, 1:n] &lt;- (sigma ^ 2) * exp(-obs_dist_mat[1:n, 1:n] / phi) + (tau ^ 2) * identityMatrix(d = n) # L[1:n,1:n] &lt;- chol(Sigma[1:n, 1:n]) S[1:n] ~ dmnorm(zeroes[1:n], cov = Sigma[1:n,1:n]) for(i in 1:n){ logit(p[i]) &lt;- b0 + b1*altitude[i] + S[i] y[i] ~ dbinom(size = N[i], prob = p[i]) } b0 ~ dnorm(0,100) b1 ~ dnorm(0,100) }) # distance specification coords_sf &lt;- sf::st_as_sf(malaria_village[,c(&quot;long&quot;,&quot;lat&quot;)], coords = c(&quot;long&quot;,&quot;lat&quot;)) |&gt; sf::st_set_crs(4326) obs_dist_mat &lt;- sf::st_distance(coords_sf) obs_dist_mat &lt;- units::set_units(obs_dist_mat, km) obs_dist_mat &lt;- units::set_units(obs_dist_mat, NULL) # Model specification n = nrow(malaria_village) altitude &lt;- malaria_village$alt # there are two missing values in the altitude that will be replaced with the mean altitude[is.na(altitude)] &lt;- mean(altitude, na.rm = TRUE) zeroes &lt;- rep(0, n) const_list &lt;- list(n = n, # number of villages zeroes = zeroes) dat_list &lt;- list(y = malaria_village$positive, # malaria prevalence N = malaria_village$total, # people sampled per village altitude = as.vector(scale(altitude)), # altitude per village obs_dist_mat = obs_dist_mat # distance matrix in km ) init_list &lt;- list(tau = 0.01, sigma = 0.01, p = rep(0.01, n)) Rmodel &lt;- nimbleModel( Example10_14_Nimble, constants = const_list, data = dat_list, inits = init_list ) Rmodel$initializeInfo() Cmodel &lt;- compileNimble(Rmodel, showCompilerOutput = FALSE) conf &lt;- configureMCMC(Rmodel, monitors = c(&quot;tau&quot;, &quot;sigma&quot;, &quot;phi&quot;, &quot;b0&quot;, &quot;b1&quot;, &quot;p&quot;, &quot;S&quot;)) Rmcmc &lt;- buildMCMC(conf) Cmcmc &lt;- compileNimble( Rmcmc, project = Cmodel, resetFunctions = TRUE, showCompilerOutput = TRUE ) niters &lt;- 60000 nburnins &lt;- 0.5 * niters nchains &lt;- 2 nthins &lt;- 14 post_samples &lt;- runMCMC( Cmcmc, niter = niters, nburnin = nburnins, thin = nthins, nchains = nchains, samplesAsCodaMCMC = TRUE, summary = TRUE ) plot(post_samples$samples[, c(&quot;b0&quot;)], bty = &quot;n&quot;, main = &quot;b0&quot;) plot(post_samples$samples[, c(&quot;b1&quot;)], bty = &quot;n&quot;, main = &quot;b1&quot;) plot(post_samples$samples[, c(&quot;tau&quot;)], bty = &quot;n&quot;, main = &quot;tau&quot;) plot(post_samples$samples[, c(&quot;sigma&quot;)], bty = &quot;n&quot;, main = &quot;sigma&quot;) plot(post_samples$samples[, c(&quot;phi&quot;)], bty = &quot;n&quot;, main = &quot;phi&quot;) plot(post_samples$samples[, c(&quot;S[1]&quot;)], bty = &quot;n&quot;, main = &quot;S[1]&quot;) plot(post_samples$samples[, c(&quot;S[13]&quot;)], bty = &quot;n&quot;, main = &quot;S[13]&quot;) plot(post_samples$samples[, c(&quot;p[1]&quot;)], bty = &quot;n&quot;, main = &quot;p[1]&quot;) plot(post_samples$samples[, c(&quot;p[13]&quot;)], bty = &quot;n&quot;, main = &quot;p[13]&quot;) # Get minimum effective size (ESS) and which variable has the min ESS min(coda::effectiveSize(post_samples$samples)) mcmc_variable_names &lt;- colnames(post_samples$samples$chain1) mcmc_variable_names[which(coda::effectiveSize(post_samples$samples) == min(coda::effectiveSize(post_samples$samples)))] # Extract samples variables &lt;- c(&quot;b0&quot;, &quot;b1&quot;,&quot;tau&quot;, &quot;sigma&quot;, &quot;phi&quot;) summary_nimble &lt;- post_samples$summary$all.chains summary_nimble[variables,] # Plot posterior summary for the spatial random effect by village post_summary &lt;- post_samples$summary$all.chains post_sum_S &lt;- as.data.frame(post_summary) |&gt; tibble::rownames_to_column() |&gt; filter(str_detect(rowname, &quot;S&quot;)) |&gt; dplyr::select(rowname, `95%CI_low`, Mean, `95%CI_upp`) |&gt; mutate(village = gsub(&quot;.*?([0-9]+).*&quot;, &quot;\\\\1&quot;, rowname)) post_sum_S$village &lt;- factor(post_sum_S$village , levels = 1:65) ggplot(data = post_sum_S, aes(x = village)) + geom_pointrange(aes(ymin = `95%CI_low`, ymax = `95%CI_upp`, y = Mean)) + geom_hline(yintercept = 0, linetype = &quot;dotted&quot;) + scale_x_discrete( breaks = post_sum_S$village[seq(1, length(post_sum_S$village), by = 5)]) + theme_clear() + ylab(&quot;&quot;) + xlab(&quot;village&quot;) + ggtitle(&quot;Posterior summary spatial random effect by village&quot;) # Plot posterior summary for the probabilities post_sum_p &lt;- as.data.frame(post_summary) |&gt; tibble::rownames_to_column() |&gt; filter(str_detect(rowname, &quot;p\\\\[&quot;)) |&gt; dplyr::select(rowname, `95%CI_low`, Mean, `95%CI_upp`) |&gt; mutate(village = gsub(&quot;.*?([0-9]+).*&quot;, &quot;\\\\1&quot;, rowname)) post_sum_p$village &lt;- factor(post_sum_p$village , levels = 1:65) ggplot(data = post_sum_p, aes(x = village)) + geom_pointrange(aes(ymin = `95%CI_low`, ymax = `95%CI_upp`, y = Mean)) + scale_x_discrete( breaks = post_sum_p$village[seq(1, length(post_sum_p$village), by = 5)]) + theme_clear() + ylab(&quot;&quot;) + xlab(&quot;village&quot;) + ggtitle(&quot;Posterior summary probabilities by village&quot;) Stan ex.data &lt;- list(y = malaria_village$positive, # malaria prevalence N = malaria_village$total, # people sampled per village X = as.vector(scale(altitude)), # altitude per village dist_matrix = obs_dist_mat, # distance matrix in km n = nrow(malaria_village) # number of villages ) Example10_14Stan &lt;- stan( file = &quot;functions/Example10_14.stan&quot;, data = ex.data, warmup = 15000, iter = 30000, chains = 2, thin = 10, pars = c(&quot;beta0&quot;, &quot;beta&quot;,&quot;sigma&quot;, &quot;tau&quot;, &quot;phi&quot;, &quot;S&quot;, &quot;p&quot;), include = TRUE ) #computing WAIC using the package loo traceplot(Example10_14Stan, pars = c(&quot;beta0&quot;,&quot;beta&quot;,&quot;sigma&quot;, &quot;tau&quot;, &quot;phi&quot;)) # Extract samples summary_stan &lt;- summary( Example10_14Stan, pars = c(&quot;beta0&quot;,&quot;beta&quot;, &quot;tau&quot;, &quot;sigma&quot;, &quot;phi&quot;), probs = c(0.025, 0.975) ) summary_stan$summary S_summary &lt;- summary(Example10_14Stan, pars = c(&quot;S&quot;))$summary S_summary_df &lt;- data.frame(S_summary) |&gt; tibble::rownames_to_column() |&gt; filter(rowname %in% paste0(&quot;S[&quot;, 1:65, &quot;]&quot;)) |&gt; mutate(village = 1:65) |&gt; dplyr::select(mean, X2.5., X97.5., village) S_summary_df$village &lt;- factor(S_summary_df$village , levels = 1:65) ggplot(S_summary_df, aes(x = village, group = 1)) + geom_pointrange(aes(ymin = X2.5., ymax = X97.5., y = mean)) + geom_hline(yintercept = 0, linetype = &quot;dotted&quot;) + scale_x_discrete( breaks = S_summary_df$village[seq(1, length(S_summary_df$village), by = 5)]) + theme_clear() + ylab(&quot;&quot;) + xlab(&quot;village&quot;) + ggtitle(&quot;Posterior summary spatial random effect by village&quot;) p_summary &lt;- summary(Example10_14Stan, pars = c(&quot;p&quot;))$summary p_summary_df &lt;- data.frame(p_summary) |&gt; tibble::rownames_to_column() |&gt; filter(rowname %in% paste0(&quot;p[&quot;, 1:65, &quot;]&quot;)) |&gt; mutate(village = 1:65) |&gt; dplyr::select(mean, X2.5., X97.5., village) p_summary_df$village &lt;- factor(p_summary_df$village , levels = 1:65) ggplot(p_summary_df, aes(x = village, group = 1)) + geom_pointrange(aes(ymin = X2.5., ymax = X97.5., y = mean)) + scale_x_discrete( breaks = p_summary_df$village[seq(1, length(p_summary_df$village), by = 5)]) + theme_clear() + ylab(&quot;&quot;) + xlab(&quot;village&quot;) + ggtitle(&quot;Posterior summary probabilities by village&quot;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
