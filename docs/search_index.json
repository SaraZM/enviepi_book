[["index.html", "Spatio-temporal methods in environmental epidemiology Introduction", " Spatio-temporal methods in environmental epidemiology Gavin Shaddick and James V Zidek 2022-11-29 Introduction This is the online companion for the book Spatio-temporal methods in environmental epidemiology published in Chapman and Hall/CRC. All the codes used for the examples in the book are presented here to ensure the material is reproducible, transparent, and accessible. Please feel free to contact us if you find any typos, or error in our code Errare humanum est. "],["preface-2nd-edition.html", "Preface (2nd edition)", " Preface (2nd edition) Lorem ipsum dolor sit amet. Id dolorem aliquam qui sunt quaerat non pariatur nemo vel modi velit. Rem fugiat quis nam voluptatem eius aut consequatur culpa sed quia quia est fugit perferendis qui voluptas reprehenderit aut molestiae adipisci. Et rerum doloribus aut quia atque id voluptas dolorum sed quaerat adipisci ut tempora repudiandae. Est odio officiis nam odit eaque hic adipisci impedit est ducimus vitae. Sit molestias quod qui repellat provident sit maxime incidunt a dolor incidunt est dolor molestiae qui libero tempora qui eligendi voluptatibus. Qui commodi possimus id autem ratione aut voluptas inventore qui totam corrupti id repudiandae fuga. Ut perferendis sequi ad saepe maiores et dolorum inventore sit quod enim ad quis consequuntur! At distinctio atque non numquam voluptatem ut fugiat fugiat est illum debitis quo saepe rerum nam labore consequatur non odio aperiam. Qui quia mollitia ea eveniet porro et labore exercitationem. Est dolorem voluptas et fugit atque vel adipisci rerum in voluptas debitis ea nemo nostrum? "],["why.html", "Chapter 1 Why spatio-temporal epidemiology?", " Chapter 1 Why spatio-temporal epidemiology? This is empty "],["health-risks.html", "Chapter 2 Modelling health risks", " Chapter 2 Modelling health risks This is still empty "],["importance.html", "Chapter 3 Importance of uncertainty", " Chapter 3 Importance of uncertainty This is empty "],["embracing.html", "Chapter 4 Embracing uncertainty: The Bayesian approach", " Chapter 4 Embracing uncertainty: The Bayesian approach This is also empty "],["Bayesian.html", "Chapter 5 The Bayesian approach in practice Example 5.2: Chronic obstructive pulmonary disease (COPD) in England Example 5.3: Fitting a Poisson regression model in Nimble", " Chapter 5 The Bayesian approach in practice Example 5.2: Chronic obstructive pulmonary disease (COPD) in England We now look at example into the hospital admission rates for chronic obstructive pulmonary disease (COPD) in England between 2001–2010. In England, there are 324 local authority administrative areas each with an observed and expected number of cases. The expected numbers were calculated using indirect standardization by applying the age–sex specific rates for the whole of England to the age–sex population profile of each of the areas. For this example, the following packages are needed ggplot2 and sf. Load the necessary packages. To create SMR maps, we need to read in the relevant shapefiles. englandlocalauthority.shp and englandlocalauthority.dbf contain the location, shape, and attributes of English local authorities. The function read_sf() from the sf package will read these shapefiles into R. copdmortalityobserved.csv contains the observed number of hospital admissions in England by local authority. copdmortalityexpected.csv contains the expected number of hospital admissions in England by local authority. # Reading in borders england &lt;- read_sf(&quot;data/englandlocalauthority.shp&quot;) # Reading in data observed &lt;- read.csv(file = &quot;data/copdmortalityobserved.csv&quot;, row.names = 1) expected &lt;- read.csv(file = &quot;data/copdmortalityexpected.csv&quot;, row.names = 1) Print summaries of the observed and expected counts. # Printing first six rows of the observed counts head(observed) ## name Y2001 Y2002 Y2003 Y2004 Y2005 Y2006 Y2007 Y2008 ## 00AA City of London LB 2 0 3 1 1 1 5 1 ## 00AB Barking and Dagenham LB 100 100 122 93 136 97 91 96 ## 00AC Barnet LB 110 102 106 89 99 97 72 84 ## 00AD Bexley LB 109 113 113 96 113 97 94 89 ## 00AE Brent LB 69 89 70 59 61 48 53 46 ## 00AF Bromley LB 120 129 135 124 128 117 120 106 ## Y2009 Y2010 ## 00AA 0 1 ## 00AB 101 78 ## 00AC 78 89 ## 00AD 93 93 ## 00AE 55 43 ## 00AF 107 113 # Printing first six rows of the expected counts head(expected) ## E2001 E2002 E2003 E2004 E2005 E2006 ## 00AA 2.648915 2.68106 2.727112 2.749562 2.808655 2.915977 ## 00AB 63.946730 63.41700 62.567863 61.444884 60.677119 59.678672 ## 00AC 121.795213 121.91534 122.451050 123.201898 124.449563 125.982868 ## 00AD 90.201336 91.24645 91.949050 92.754781 93.674540 94.598593 ## 00AE 76.876437 77.18529 78.017980 78.967493 80.422828 81.785325 ## 00AF 131.182934 132.30521 133.257442 134.520920 136.441229 137.382528 ## E2007 E2008 E2009 E2010 ## 00AA 3.021586 3.114696 3.237998 3.237998 ## 00AB 58.487583 57.701932 57.250524 57.250524 ## 00AC 127.088805 128.825149 131.374946 131.374946 ## 00AD 95.447131 96.832061 97.651369 97.651369 ## 00AE 83.651266 85.265264 87.089119 87.089119 ## 00AF 138.634021 139.508507 140.634084 140.634084 # Summarising the observed counts summary(observed) ## name Y2001 Y2002 Y2003 ## Length:324 Min. : 2.00 Min. : 0.00 Min. : 3.00 ## Class :character 1st Qu.: 35.00 1st Qu.: 38.00 1st Qu.: 38.00 ## Mode :character Median : 50.00 Median : 52.00 Median : 52.00 ## Mean : 68.01 Mean : 69.63 Mean : 73.44 ## 3rd Qu.: 83.50 3rd Qu.: 80.75 3rd Qu.: 83.25 ## Max. :445.00 Max. :438.00 Max. :480.00 ## Y2004 Y2005 Y2006 Y2007 ## Min. : 1.00 Min. : 1.00 Min. : 1.00 Min. : 5.00 ## 1st Qu.: 35.00 1st Qu.: 37.00 1st Qu.: 35.00 1st Qu.: 37.00 ## Median : 49.50 Median : 51.00 Median : 49.00 Median : 50.00 ## Mean : 66.67 Mean : 69.37 Mean : 67.07 Mean : 68.17 ## 3rd Qu.: 81.25 3rd Qu.: 80.50 3rd Qu.: 81.00 3rd Qu.: 79.00 ## Max. :428.00 Max. :395.00 Max. :428.00 Max. :456.00 ## Y2008 Y2009 Y2010 ## Min. : 1.00 Min. : 0.00 Min. : 1.00 ## 1st Qu.: 37.00 1st Qu.: 36.00 1st Qu.: 38.00 ## Median : 51.00 Median : 50.00 Median : 51.00 ## Mean : 71.40 Mean : 67.04 Mean : 68.81 ## 3rd Qu.: 84.25 3rd Qu.: 78.00 3rd Qu.: 81.25 ## Max. :463.00 Max. :394.00 Max. :441.00 # Summarising the expected counts summary(expected) ## E2001 E2002 E2003 E2004 ## Min. : 2.649 Min. : 2.681 Min. : 2.727 Min. : 2.75 ## 1st Qu.: 39.066 1st Qu.: 39.456 1st Qu.: 39.849 1st Qu.: 40.60 ## Median : 51.766 Median : 52.671 Median : 53.487 Median : 54.29 ## Mean : 62.944 Mean : 63.589 Mean : 64.139 Mean : 64.72 ## 3rd Qu.: 74.292 3rd Qu.: 74.974 3rd Qu.: 74.701 3rd Qu.: 74.02 ## Max. :370.913 Max. :371.271 Max. :369.861 Max. :368.87 ## E2005 E2006 E2007 E2008 ## Min. : 2.809 Min. : 2.916 Min. : 3.022 Min. : 3.115 ## 1st Qu.: 41.646 1st Qu.: 42.497 1st Qu.: 43.203 1st Qu.: 44.262 ## Median : 54.765 Median : 55.506 Median : 56.552 Median : 57.522 ## Mean : 65.440 Mean : 66.180 Mean : 67.022 Mean : 67.950 ## 3rd Qu.: 75.003 3rd Qu.: 75.260 3rd Qu.: 75.790 3rd Qu.: 76.935 ## Max. :368.565 Max. :367.838 Max. :368.026 Max. :368.291 ## E2009 E2010 ## Min. : 3.238 Min. : 3.238 ## 1st Qu.: 45.062 1st Qu.: 45.062 ## Median : 58.077 Median : 58.077 ## Mean : 68.901 Mean : 68.901 ## 3rd Qu.: 78.166 3rd Qu.: 78.166 ## Max. :368.940 Max. :368.940 Modelling the raw standardized mortality rates (SMRs) Calculate the raw SMRs as. \\[ \\text{SMR} = \\dfrac{observed}{expected}\\] SMR_raw &lt;- observed[, -1] / expected # Rename columns names(SMR_raw) &lt;- c( &quot;SMR2001&quot;, &quot;SMR2002&quot;, &quot;SMR2003&quot;, &quot;SMR2004&quot;, &quot;SMR2005&quot;, &quot;SMR2006&quot;, &quot;SMR2007&quot;, &quot;SMR2008&quot;, &quot;SMR2009&quot;, &quot;SMR2010&quot; ) # Printing first six rows of raw SMRs head(SMR_raw) ## SMR2001 SMR2002 SMR2003 SMR2004 SMR2005 SMR2006 SMR2007 ## 00AA 0.7550261 0.0000000 1.1000648 0.3636943 0.3560423 0.3429382 1.6547601 ## 00AB 1.5638016 1.5768644 1.9498828 1.5135516 2.2413721 1.6253713 1.5558858 ## 00AC 0.9031554 0.8366462 0.8656520 0.7223915 0.7955030 0.7699460 0.5665330 ## 00AD 1.2084078 1.2384043 1.2289415 1.0349871 1.2063043 1.0253852 0.9848384 ## 00AE 0.8975442 1.1530694 0.8972291 0.7471429 0.7584911 0.5869024 0.6335828 ## 00AF 0.9147531 0.9750183 1.0130766 0.9217897 0.9381329 0.8516367 0.8655884 ## SMR2008 SMR2009 SMR2010 ## 00AA 0.3210586 0.0000000 0.3088328 ## 00AB 1.6637225 1.7641760 1.3624329 ## 00AC 0.6520466 0.5937205 0.6774503 ## 00AD 0.9191171 0.9523676 0.9523676 ## 00AE 0.5394928 0.6315370 0.4937471 ## 00AF 0.7598103 0.7608397 0.8035037 # Summarising raw SMRs summary(SMR_raw) ## SMR2001 SMR2002 SMR2003 SMR2004 ## Min. :0.3883 Min. :0.0000 Min. :0.3616 Min. :0.2778 ## 1st Qu.:0.7900 1st Qu.:0.8272 1st Qu.:0.8519 1st Qu.:0.7636 ## Median :0.9496 Median :1.0168 Median :1.0209 Median :0.9266 ## Mean :1.0349 Mean :1.0508 Mean :1.0895 Mean :0.9812 ## 3rd Qu.:1.2526 3rd Qu.:1.2364 3rd Qu.:1.3071 3rd Qu.:1.1858 ## Max. :1.9861 Max. :2.2181 Max. :2.2483 Max. :1.9811 ## SMR2005 SMR2006 SMR2007 SMR2008 ## Min. :0.3326 Min. :0.3429 Min. :0.3509 Min. :0.3211 ## 1st Qu.:0.7592 1st Qu.:0.7415 1st Qu.:0.7533 1st Qu.:0.7695 ## Median :0.9573 Median :0.9101 Median :0.9305 Median :0.9404 ## Mean :1.0126 Mean :0.9726 Mean :0.9743 Mean :1.0069 ## 3rd Qu.:1.2083 3rd Qu.:1.1586 3rd Qu.:1.1679 3rd Qu.:1.1979 ## Max. :2.2414 Max. :2.0805 Max. :1.8528 Max. :2.0567 ## SMR2009 SMR2010 ## Min. :0.0000 Min. :0.3088 ## 1st Qu.:0.7452 1st Qu.:0.7682 ## Median :0.8777 Median :0.9337 ## Mean :0.9328 Mean :0.9639 ## 3rd Qu.:1.0934 3rd Qu.:1.1335 ## Max. :1.8507 Max. :2.3856 Attach the values of the raw SMRs to the shapefiles. The function merge() allows us to combine a data frame with a shapefile to plot later. # Convert row names to ID column SMR_raw &lt;- tibble::rownames_to_column(SMR_raw, &quot;ID&quot;) # Combine raw SMRs and shapefiles SMRspatial_raw &lt;- merge(england, SMR_raw, by = &quot;ID&quot;) Use ggplot() and geom_sf() to create a map which colours the local authorities by the raw SMR estimate. # Creating breaks for legend in plot range &lt;- seq(min(SMR_raw$SMR2010) - 0.01, max(SMR_raw$SMR2010) + 0.01, length.out = 11) # Creating map of Raw SMRs in England in 2010 ggplot() + # Choose spatial object and column for plotting geom_sf(data = SMRspatial_raw, aes(fill = SMR2010)) + # Break points for colours scale_y_continuous(breaks = range) + # Clear background and plot borders theme( axis.text.x = element_blank(), axis.text.y = element_blank(), axis.ticks = element_blank(), rect = element_blank() ) Modelling a Poisson-Gamma with an MCMC implemented in R The following code shows how to implement the MCMC using only R for the COPD example. First, the constants are defined and the necessary vectors are initialized. # observations y &lt;- observed$Y2010 # offset E &lt;- expected$E2010 # Number of MCMC iterations L &lt;- 80000 ## Initialize objects used in MCMC # Matrix for sampled values of parameter theta_i theta &lt;- matrix(ncol = length(y), nrow = L) # Matrix for fitted values fitted &lt;- theta # Vector for sampled values of hyper-parameter a a &lt;- c() # Vector for sampled values of hyper-parameter b b &lt;- c() ## Define constants # Sample size N &lt;- length(y) # Parameter of exponential prior for a lambda_a &lt;- 1 # Parameter of exponential prior for b lambda_b &lt;- 1 # standard deviation of the proposal distribution of log a u &lt;- 0.5 Then, the initial values for all the parameters are defined. theta[1, ] &lt;- y / E # Initial value sampled from the prior for a # REVIEW: In the example of the book theta ~ Ga(a,a) not Ga(a,b) a &lt;- rexp(1, lambda_a) # Initial value sampled from the prior for b b &lt;- rexp(1, lambda_b) fitted[1, ] &lt;- rpois(N, E * theta[1, ]) Once all the constants and initial values are set we can run the MCMC. The following code shows the MCMC implementation of a Poisson-Gamma model using only R. # Starting from l=2 as l=1 contains the initial values for(l in 2:L) { # Sampling from the posterior full conditional of each theta_i for (i in 1:N) theta[l, i] &lt;- rgamma(1, (y[i] + a[(l - 1)]), rate = (E[i] + b[(l - 1)])) # Sampling from the posterior full conditional of b # b[l] &lt;- b[l-1] # REVIEW: is this part of the comment? b[l] &lt;- rgamma(1, (N * a[(l - 1)] + 1), rate = (sum(theta[l, ]) + lambda_b)) # Metropolis-Hastings step to sample from the full conditional of &quot;a&quot; # the new value receives the current value in case the proposed # value is rejected a[l] &lt;- a[l - 1] # Proposal in the log-scale laprop &lt;- rnorm(1, log(a[l - 1]), u) aprop &lt;- exp(laprop) num &lt;- N * (aprop * (log(b[l])) - lgamma(aprop)) + (aprop - 1) * sum(log(theta[l, ])) - aprop * lambda_a + log(aprop) den &lt;- N * (a[l - 1] * (log(b[l])) - lgamma(a[l - 1])) + (a[(l - 1)] - 1) * sum(log(theta[l, ])) - a[(l - 1)] * lambda_a + log(a[(l - 1)]) ratio &lt;- exp(num - den) unif &lt;- runif(1) # Change the current value if the proposed value is accepted if (unif &lt; ratio) a[l] &lt;- aprop fitted[l,] &lt;- rpois(N, E * theta[l,]) } After running the MCMC, we should check if the chains have converged # Number of burn in samples burnin &lt;- 20000 thin &lt;- 30 # MCMC samples seqaux &lt;- seq(burnin, L, by = thin) # Trace-plots of the parameters xx &lt;- seq(0, 6, length = 2000) par(mfrow = c(2, 2)) # Plot for &quot;a&quot; plot(a[seqaux], type = &quot;l&quot;, bty = &quot;n&quot;) hist(a[seqaux], prob = 1, main = &quot;&quot;) lines(xx, dexp(xx, lambda_a), col = 2, lwd = 2) # COMBAK: This chains are not looking great # Plot for &quot;b&quot; plot(b[seqaux], type = &quot;l&quot;, bty = &quot;n&quot;) hist(b[seqaux], prob = 1, main = &quot;&quot;) lines(xx, dexp(xx, lambda_b), col = 2, lwd = 2) # Traceplots of theta&#39;s par(mfrow = c(3, 3)) for (i in 1:9) plot(theta[seqaux, i], type = &quot;l&quot;, bty = &quot;n&quot;) Given the convergence issues, we can also check the estimated sampled size and Rhat using the package coda. print(&quot;ESS a:&quot;) ## [1] &quot;ESS a:&quot; coda::effectiveSize(a[seqaux]) ## var1 ## 63.3439 print(&quot;ESS b:&quot;) ## [1] &quot;ESS b:&quot; coda::effectiveSize(b[seqaux]) ## var1 ## 74.59579 print(&quot;ESS theta[1]:&quot;) ## [1] &quot;ESS theta[1]:&quot; coda::effectiveSize(theta[seqaux, 1]) ## var1 ## 2001 print(&quot;ESS theta[10]:&quot;) ## [1] &quot;ESS theta[10]:&quot; coda::effectiveSize(theta[seqaux, 10]) ## var1 ## 2001 The variances for the parameters a and b is lower than the recommended minimum of 100. We will go back to this in Chapter 8. Now that we have guaranteed the convergence of the chains, we can look at the posterior summaries. # Posterior summaries of theta_i meantheta &lt;- apply(theta, 2, mean) q025theta &lt;- apply(theta, 2, function(x) quantile(x, 0.025)) q975theta &lt;- apply(theta, 2, function(x) quantile(x, 0.975)) # Plot the mean and 95% CIs for the thetas par(mfrow = c(1, 1)) plot( meantheta, pch = 19, cex = 0.8, bty = &quot;n&quot;, xlab = &quot;Borough&quot;, ylab = &quot;Posterior Summary Rate&quot;, ylim = c(min(q025theta), max(q975theta)) ) for (i in 1:N) segments(i, q025theta[i], i, q975theta[i]) abline(h = 1, lwd = 2, lty = 2) # Posterior summary of fitted values meanfit &lt;- apply(fitted, 2, mean) q025fit &lt;- apply(fitted, 2, function(x) quantile(x, 0.025)) q975fit &lt;- apply(fitted, 2, function(x) quantile(x, 0.975)) # Plot mean and 95% CIs for the fitted values par(mfrow = c(1, 1)) plot( y, meanfit, ylim = c(min(q025fit), max(q975fit)), xlab = &quot;Observed&quot;, ylab = &quot;Fitted&quot;, pch = 19, cex = 0.7, bty = &quot;n&quot; ) for (i in 1:N) segments(y[i], q025fit[i], y[i], q975fit[i]) abline(a = 0, b = 1) Example 5.3: Fitting a Poisson regression model in Nimble Load nimble package The following code is used to fit the Poisson log-linear model seen in Chapter 2 Section … using Nimble First, define the model in Nimble. Example5_3Code &lt;- nimbleCode({ for (i in 1:N) { Y[i] ~ dpois(mu[i]) log(mu[i]) &lt;- log(E[i]) + beta0 + beta1 * X1[i] + betad * X2[i] } # Priors beta0 ~ dnorm (0 , sd = 100) beta1 ~ dnorm (0 , sd = 100) betad ~ dnorm (0 , sd = 100) # Functions of interest: base &lt;- exp(beta0) RR &lt;- exp(beta1) }) Read the data and define the constants, data and initials lists for the Nimble model. # REVIEW: Is this another version of the COPD data? Is there a data dictionary for this dataset? data &lt;- read.csv(&quot;data/DataExample53.csv&quot;, sep = &quot;,&quot;) ex.const &lt;- list( N = 393, E = data$exp_lungc65pls, X1 = as.vector(scale(data$k3)), X2 = as.vector(scale(data$k2)) ) ex.data &lt;- list(Y = data$lungc65pls) inits &lt;- function() list(beta0 = rnorm(1), beta1 = rnorm(1), betad = rnorm(1)) Define the parameter monitors and run the model. # Define parameters to monitor params &lt;- c(&quot;beta0&quot;, &quot;beta1&quot;, &quot;betad&quot;, &quot;base&quot;, &quot;RR&quot;) samples &lt;- nimbleMCMC( code = Example5_3Code, data = ex.data, constants = ex.const, inits = inits, monitors = params, niter = 22000, nburnin = 2000, thin = 10, WAIC = TRUE, nchains = 2, samplesAsCodaMCMC = TRUE ) Check the WAIC. samples$WAIC ## nimbleList object of type waicList ## Field &quot;WAIC&quot;: ## [1] 3049.352 ## Field &quot;lppd&quot;: ## [1] -1514.445 ## Field &quot;pWAIC&quot;: ## [1] 10.23029 Show the trace plots and posterior summaries for each of the parameters. mvSamples &lt;- samples$samples #trace plots of beta1 plot(mvSamples[, c(&quot;beta1&quot;)]) #trace plots of base plot(mvSamples[, c(&quot;base&quot;)]) #trace plots of RR plot(mvSamples[, c(&quot;RR&quot;)]) #posterior summary of base summary(mvSamples[, c(&quot;base&quot;)]) ## ## Iterations = 1:2000 ## Thinning interval = 1 ## Number of chains = 2 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 1.1285874 0.0124476 0.0001968 0.0001960 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 1.105 1.120 1.129 1.137 1.153 #posterior summary of RR summary(mvSamples[, c(&quot;RR&quot;)]) ## ## Iterations = 1:2000 ## Thinning interval = 1 ## Number of chains = 2 ## Sample size per chain = 2000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 1.0148394 0.0176035 0.0002783 0.0004294 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 0.9819 1.0028 1.0149 1.0265 1.0502 "],["Strategies.html", "Chapter 6 Strategies for modelling", " Chapter 6 Strategies for modelling "],["RealData.html", "Chapter 7 Is ‘real’ data always quite so real?", " Chapter 7 Is ‘real’ data always quite so real? Holi "],["Spatial.html", "Chapter 8 Spatial patterns in disease Example 8.1: Empirical Bayes and Bayes smoothing of COPD mortality for 2010 Example 8.3: Fitting a conditional spatial model in nimble and stan Example 8.4: Fitting a conditional spatial model using CARBayes Example 8.5: Fitting a conditional model using INLA", " Chapter 8 Spatial patterns in disease Example 8.1: Empirical Bayes and Bayes smoothing of COPD mortality for 2010 Following Example-5.2 we look back at the hospital admission rates for COPD, in England for 2010. We can implement the same model we used on Example-5.2 in nimble. Nimble The following is the code for the Poisson-Gamma model implemented in Nimble. Example8_1Code &lt;- nimbleCode({ for (i in 1:N) { Y[i] ~ dpois(mu[i]) # REVIEW: There is an intercept in the book, # but then we wouldn&#39;t be able to compare it to example 5.2 mu[i] &lt;- E[i] * theta[i] # REVIEW: Same as before, the example in the book has theta[i] ~ Ga(a,a) theta[i] ~ dgamma(a, b) Y.fit[i] ~ dpois(mu[i]) } # Priors a ~ dexp(lambda_a) b ~ dexp(lambda_b) }) Define the constants, data and initials lists for the Nimble model. # observations y &lt;- observed$Y2010 # offset E &lt;- expected$E2010 N &lt;- length(y) # Parameter of exponential prior for a lambda_a &lt;- 1 # Parameter of exponential prior for b lambda_b &lt;- 1 constants &lt;- list( N = N, E = E, lambda_a = lambda_a, lambda_b = lambda_b ) ex.data &lt;- list(Y = y) # Function to generate initial values inits &lt;- function() list( theta = rgamma(N, 1, 1), a = rexp(1, lambda_a), b = rexp(1, lambda_b), Y.fit = rpois(N, E) ) Define the parameter monitors and run the model. # parameters to monitor params &lt;- c(&quot;theta&quot;, &quot;a&quot;, &quot;b&quot;, &quot;Y.fit&quot;) mcmc.out &lt;- nimbleMCMC( code = Example8_1Code, constants = constants, data = ex.data, # provide the combined data &amp; constants as constants inits = inits, monitors = params, niter = 50000, nburnin = 20000, thin = 30, WAIC = TRUE, nchains = 2, summary = TRUE, samplesAsCodaMCMC = TRUE ) Check the WAIC and ESS. mcmc.out$WAIC ## nimbleList object of type waicList ## Field &quot;WAIC&quot;: ## [1] 2417.405 ## Field &quot;lppd&quot;: ## [1] -1060.275 ## Field &quot;pWAIC&quot;: ## [1] 148.4276 min(coda::effectiveSize(mcmc.out$samples)) ## [1] 227.2731 Show the trace plots and posterior summaries for each of the parameters. mvSamples &lt;- mcmc.out$samples #trace plots of a plot(mvSamples[, c(&quot;a&quot;)]) #trace plots of b plot(mvSamples[, c(&quot;b&quot;)]) summary(mvSamples[, c(&quot;a&quot;, &quot;b&quot;)]) ## ## Iterations = 1:1000 ## Thinning interval = 1 ## Number of chains = 2 ## Sample size per chain = 1000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## a 11.82 1.049 0.02346 0.06863 ## b 12.15 1.101 0.02461 0.07146 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## a 9.887 11.10 11.76 12.50 13.96 ## b 10.105 11.39 12.10 12.87 14.44 #trace plots of theta&#39;s for (i in 1:3) plot(mvSamples[, c(paste(&quot;theta[&quot;, i, &quot;]&quot;, sep = &quot;&quot;))]) Now that we have checked the convergence of the chains we can plot the posterior mean and 95% CIs for each of the parameters. # Posterior summaries of theta_i post_summary &lt;- mcmc.out$summary$all.chains %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column(&quot;variable&quot;) # Plot the mean and 95% CIs for the thetas post_theta &lt;- post_summary[grepl(&quot;theta\\\\[&quot;, post_summary$variable), ] par(mfrow = c(1, 1)) plot( post_theta$Mean, pch = 19, cex = 0.8, bty = &quot;n&quot;, xlab = &quot;Borough&quot;, ylab = &quot;Posterior Summary Rate&quot;, ylim = c(min(post_theta$`95%CI_low`), max(post_theta$`95%CI_upp`)) ) for (i in 1:N) segments(i, post_theta$`95%CI_low`[i], i, post_theta$`95%CI_upp`[i]) abline(h = 1, lwd = 2, lty = 2) # Posterior summary of fitted values post_fitted &lt;- post_summary[grepl(&quot;Y.fit\\\\[&quot;, post_summary$variable), ] # Plot mean and 95% CIs for the fitted values par(mfrow = c(1, 1)) plot( y, post_fitted$Mean, ylim = c(min(post_fitted$`95%CI_low`), max(post_fitted$`95%CI_upp`)), xlab = &quot;Observed&quot;, ylab = &quot;Fitted&quot;, pch = 19, cex = 0.7, bty = &quot;n&quot; ) for (i in 1:N) segments(y[i], post_fitted$`95%CI_low`[i], y[i], post_fitted$`95%CI_upp`[i]) abline(a = 0, b = 1) Stan Load stan with options Write the stan model. This model is in a separate file called Example8_1.stan that will be called later. data { int&lt;lower=0&gt; N; real&lt;lower=0&gt; E[N]; // need to indicate that variable is strictly positive int&lt;lower=0&gt; Y[N]; real&lt;lower=0&gt;lambda_a; real&lt;lower=0&gt;lambda_b; } parameters { real&lt;lower=0&gt; theta[N]; real&lt;lower=0&gt; a; real&lt;lower=0&gt; b; } transformed parameters{ real &lt;lower=0&gt; mu[N]; for(i in 1:N){ mu[i]=E[i]*theta[i]; } } model { // likelihood function and prior for theta for(i in 1:N){ Y[i] ~ poisson(mu[i]); theta[i]~gamma(a,b); } a~exponential(lambda_a); b~exponential(lambda_b); } generated quantities { vector [N] log_lik; int&lt;lower=0&gt; yfit [N]; //computing the log_likelihood for each value of the mean mu and the fitted values for(i in 1:N){ log_lik[i]=poisson_lpmf(Y[i] |mu[i]); yfit[i]=poisson_rng(mu[i]); } } Define the data for the model, similar to nimble. # observations y &lt;- observed$Y2010 # offset E &lt;- expected$E2010 N &lt;- length(y) # Define the data list ex.data &lt;- list( N = length(y), Y = y, E = E, lambda_a = 1, lambda_b = 1 ) # Run the model in Stan mod0 &lt;- stan( file = &quot;functions/Example8_1.stan&quot;, data = ex.data, chains = 3, iter = 10000, warmup = 3000, thin = 14, control = list(adapt_delta = 0.8, max_treedepth = 15), init = &quot;random&quot;, pars = c(&quot;a&quot;, &quot;b&quot;, &quot;theta&quot;, &quot;log_lik&quot;, &quot;yfit&quot;), include = TRUE ) Compute the WAIC. #computing WAIC using the package loo loglik0 &lt;- extract_log_lik(mod0) waic0 &lt;- waic(loglik0) waic0 ## ## Computed from 1500 by 324 log-likelihood matrix ## ## Estimate SE ## elpd_waic -1207.0 7.5 ## p_waic 146.9 3.3 ## waic 2414.1 15.0 ## ## 174 (53.7%) p_waic estimates greater than 0.4. We recommend trying loo instead. Show the trace plots and posterior summaries of the parameters. #traceplots of the vector of coefficients beta traceplot(mod0,pars=c(&quot;a&quot;,&quot;b&quot;)) traceplot(mod0,pars=c(&quot;theta[1]&quot;, &quot;theta[2]&quot;, &quot;theta[3]&quot;)) summary_theta &lt;- summary(mod0, pars = c(&quot;theta&quot;), probs = c(0.05, 0.95))$summary %&gt;% as.data.frame() par(mfrow = c(1, 1)) plot( summary_theta$mean, pch = 19, cex = 0.8, bty = &quot;n&quot;, xlab = &quot;Borough&quot;, ylab = &quot;Posterior Summary Rate&quot;, ylim = c(min(summary_theta$`5%`), max(summary_theta$`95%`)) ) for (i in 1:N) segments(i, summary_theta$`5%`[i], i, summary_theta$`95%`[i]) abline(h = 1, lwd = 2, lty = 2) # Posterior summary of fitted values summary_fit &lt;- summary(mod0, pars = c(&quot;yfit&quot;), probs = c(0.05, 0.95))$summary %&gt;% as.data.frame() # Plot mean and 95% CIs for the fitted values par(mfrow = c(1, 1)) plot( y, summary_fit$mean, ylim = c(min(summary_fit$`5%`), max(summary_fit$`95%`)), xlab = &quot;Observed&quot;, ylab = &quot;Fitted&quot;, pch = 19, cex = 0.7, bty = &quot;n&quot; ) for (i in 1:N) segments(y[i], summary_fit$`5%`[i], y[i], summary_fit$`95%`[i]) abline(a = 0, b = 1) Example 8.3: Fitting a conditional spatial model in nimble and stan Nimble Stan Here, we implement the CAR model using stan. We will need two function to structure the matrix of neighbors that will be needed in stan. adjlist = function(W, N) { adj = 0 for (i in 1:N) { for (j in 1:N) { if (W[i, j] == 1) { adj = append(adj, j) } } } adj = adj[-1] return(adj) } mungeCARdata4stan = function(adjBUGS, numBUGS) { N = length(numBUGS) nn = numBUGS N_edges = length(adjBUGS) / 2 node1 = vector(mode = &quot;numeric&quot;, length = N_edges) node2 = vector(mode = &quot;numeric&quot;, length = N_edges) iAdj = 0 iEdge = 0 for (i in 1:N) { for (j in 1:nn[i]) { iAdj = iAdj + 1 if (i &lt; adjBUGS[iAdj]) { iEdge = iEdge + 1 node1[iEdge] = i node2[iEdge] = adjBUGS[iAdj] } } } return (list( &quot;N&quot; = N, &quot;N_edges&quot; = N_edges, &quot;node1&quot; = node1, &quot;node2&quot; = node2 )) } Define the adjacency matrix and indexes for stan using the nb2mat and adjlist # Create the neighborhood W.nb &lt;- poly2nb(england, row.names = rownames(england)) # Creates a matrix for following function call W.mat &lt;- nb2mat(W.nb, style = &quot;B&quot;) # Define the spatial structure to use in stan N &lt;- length(unique(england$ID)) neigh = adjlist(W.mat, N) numneigh = apply(W.mat, 2, sum) nbs = mungeCARdata4stan(neigh, numneigh) N = nbs$N node1 = nbs$node1 node2 = nbs$node2 N_edges = nbs$N_edges Stan model for CAR effects. This model is in a separate file called Example8_3.stan that will be called later. data { int&lt;lower=1&gt; N; int&lt;lower=1&gt; N_edges; int&lt;lower=1, upper=N&gt; node1[N_edges]; // node1[i] adjacent to node2[i] int&lt;lower=1, upper=N&gt; node2[N_edges]; // and node1[i] &lt; node2[i] int&lt;lower=0&gt; y[N]; // count outcomes vector&lt;lower=0&gt;[N] E; // exposure } transformed data { vector[N] log_E = log(E); } parameters { real beta0; // intercept vector[N] s; // spatial effects real&lt;lower=0&gt; sigma_s; // marginal standard deviation of spatial effects } transformed parameters { vector[N] b; // latent effect b = sigma_s*s; } model { y ~ poisson_log(log_E + beta0 + b); // This is the prior for s! (up to proportionality) target += -0.5 * dot_self(s[node1] - s[node2]); sum(s) ~ normal(0, 0.001 * N); beta0 ~ normal(0.0, 10.0); sigma_s ~ normal(0.0,1.0); } generated quantities { vector[N] mu=exp(log_E + beta0 + b); vector[N] lik; for(i in 1:N){ lik[i] = exp(poisson_lpmf(y[i] | mu[i] )); } } N_edges = N_edges node1 = node1 node2 = node2 N = N y = observed$Y2010 E = expected$E2010 COPD_fitCAR = stan( &quot;functions/Example8_3.stan&quot;, data = list( N = N, y = y, E = E, N_edges = N_edges, node1 = node1, node2 = node2 ), warmup = 10000, iter = 20000, chains = 2, thin = 10 ) Show traceplots. traceplot(COPD_fitCAR, pars = c(&quot;beta0&quot;,&quot;sigma_s&quot; )) Show the posterior summary for the parameters if interest. Keep in mind that in the stan model the we are sampling the standard deviation of the random effect unlike CARBayes where the variance is obtained. # Extract samples summary_CAR &lt;- summary( COPD_fitCAR, pars = c(&quot;beta0&quot;, &quot;sigma_s&quot;), probs = c(0.025, 0.975) ) print(summary_CAR$summary) mean se_mean sd 2.5% 97.5% n_eff beta0 -0.06462819 0.0001741830 0.007607012 -0.07984097 -0.05033877 1907.290 sigma_s 0.41040730 0.0006004027 0.025342817 0.36345122 0.46141905 1781.659 Rhat beta0 1.0004465 sigma_s 0.9998871 Example 8.4: Fitting a conditional spatial model using CARBayes Load the necessary libraries rm(list=ls()) library(CARBayes) library(ggplot2) library(sf) library(spdep) Load the COPD data. As in example 5.2 englandlocalauthority.shp and it’s related files contain the location, shape, and attributes of English local authorities. # Reading in borders england &lt;- read_sf(&quot;data/englandlocalauthority.shp&quot;) # Reading in data observed &lt;- read.csv(file = &quot;data/copdmortalityobserved.csv&quot;, row.names = 1) expected &lt;- read.csv(file = &quot;data/copdmortalityexpected.csv&quot;, row.names = 1) To calculate the smoother SMRs, we first need to create a neighborhood structure. The functions poly2nb() and nb2mat() from the spdep package can be used to create this # Create the neighborhood W.nb &lt;- poly2nb(england, row.names = rownames(england)) # Creates a matrix for following function call W.mat &lt;- nb2mat(W.nb, style = &quot;B&quot;) Here, we use first neighbors to define the structure, so any local authority sharing a border are considered neighbors. The function S.CARleroux() allows us to use the neighborhood structure and performs a Bayesian analysis to create a smoothed set of observed values. # Running smoothing model model &lt;- S.CARleroux( # Model Formula formula = observed$Y2010 ~ offset(log(expected$E2010)), # Choosing Poisson Regression family = &quot;poisson&quot;, # Neighborhood matrix W = W.mat, # Number of burn in samples burnin = 20000, # Number of MCMC samples n.sample = 100000, thin = 10, rho = 1 ) We can extract the new smoother values from the model output and divide them by the expected values in order to compare both methods. # Creating a dataset with smoothed SMRs in 2010 SMR2010 &lt;- model$fitted.values / expected$E2010 SMR_smooth &lt;- as.data.frame(SMR2010, row.names = rownames(observed)) Check that there are no errors and summarize the results # Printing first six rows of smoothed SMRs head(SMR_smooth) ## SMR2010 ## 00AA 1.0142368 ## 00AB 1.2645745 ## 00AC 0.6878243 ## 00AD 0.9726070 ## 00AE 0.6005188 ## 00AF 0.8597476 # Summarizing smoothed SMRs summary(SMR_smooth) ## SMR2010 ## Min. :0.5498 ## 1st Qu.:0.8003 ## Median :0.9281 ## Mean :0.9691 ## 3rd Qu.:1.0837 ## Max. :1.7312 Show the summary of the parameters under the CAR model. Mean 2.5% 97.5% n.sample % accept n.effective Geweke.diag (Intercept) -0.0644 -0.0818 -0.0468 8000 34.9 6878.1 -2.2 tau2 0.1654 0.1303 0.2079 8000 100.0 6140.1 1.4 rho 1.0000 1.0000 1.0000 NA NA NA NA Use ggplot() and geom_sf() to plot the map of smoothed SMRs. SMR_smooth &lt;- tibble::rownames_to_column(SMR_smooth, &quot;ID&quot;) # Combining smoothed SMRs and the shapefile SMRspatial_smooth &lt;- merge(england, SMR_smooth, by = &quot;ID&quot;) # Creating breaks for legend in plot range &lt;- seq(min(SMR_smooth$SMR2010) - 0.01, max(SMR_smooth$SMR2010) + 0.01, length.out = 11) # Creating map of smoothed SMRs in England in 2010 ggplot() + # Choose spatial object and column for plotting geom_sf(data = SMRspatial_smooth, aes(fill = SMR2010)) + # Break points for colours scale_y_continuous(breaks = range) + # Clear background and plot borders theme( axis.text.x = element_blank(), axis.text.y = element_blank(), axis.ticks = element_blank(), rect = element_blank() ) Example 8.5: Fitting a conditional model using INLA # Reading in borders england &lt;- read_sf(&quot;data/englandlocalauthority.shp&quot;) # Reading in data observed &lt;- read.csv(file = &quot;data/copdmortalityobserved.csv&quot;, row.names = 1) expected &lt;- read.csv(file = &quot;data/copdmortalityexpected.csv&quot;, row.names = 1) # Create the neighborhood matrix W.nb &lt;- poly2nb (england , row.names = england$ID) W.list &lt;- nb2listw (W.nb , style = &quot;B&quot;) W.mat &lt;- nb2mat (W.nb , style = &quot;B&quot;) # Convert the adjacency matrix into a file in the INLA format nb2INLA(&quot;UK.adj&quot;, W.nb) # Create areas IDs to match the values in UK.adj data = as.data.frame(cbind(y = observed$Y2010, E = expected$E2010)) data$ID &lt;- 1:324 # run the INLA model m1 &lt;- inla( y ~ f(ID , model = &quot;besag&quot;, graph = &quot;UK.adj&quot;), family = &quot;poisson&quot;, E = E, data = data, control.predictor = list(compute = TRUE) ) "],["PointsFields.html", "Chapter 9 From points to fields: modelling environmental hazards over space", " Chapter 9 From points to fields: modelling environmental hazards over space This is also empty "],["references.html", "References", " References print(sessionInfo()) ## R version 4.2.2 (2022-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19044) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_Canada.utf8 LC_CTYPE=English_Canada.utf8 ## [3] LC_MONETARY=English_Canada.utf8 LC_NUMERIC=C ## [5] LC_TIME=English_Canada.utf8 ## ## attached base packages: ## [1] parallel stats graphics grDevices utils datasets methods ## [8] base ## ## other attached packages: ## [1] INLA_22.05.07 foreach_1.5.2 Matrix_1.5-1 ## [4] CARBayes_5.3 Rcpp_1.0.9 MASS_7.3-58.1 ## [7] spdep_1.2-7 spData_2.2.1 sp_1.5-1 ## [10] loo_2.5.1 rstan_2.26.13 StanHeaders_2.26.13 ## [13] nimble_0.12.2 sf_1.0-9 ggplot2_3.4.0 ## ## loaded via a namespace (and not attached): ## [1] mcmc_0.9-7 matrixStats_0.62.0 RColorBrewer_1.1-3 CARBayesdata_3.0 ## [5] tools_4.2.2 backports_1.4.1 bslib_0.4.1 utf8_1.2.2 ## [9] R6_2.5.1 KernSmooth_2.23-20 DBI_1.1.3 colorspace_2.0-3 ## [13] withr_2.5.0 tidyselect_1.2.0 gridExtra_2.3 prettyunits_1.1.1 ## [17] GGally_2.1.2 processx_3.8.0 leaflet_2.1.1 curl_4.3.3 ## [21] compiler_4.2.2 quantreg_5.94 cli_3.4.1 SparseM_1.81 ## [25] labeling_0.4.2 bookdown_0.30 sass_0.4.2 scales_1.2.1 ## [29] checkmate_2.1.0 classInt_0.4-8 callr_3.7.3 proxy_0.4-27 ## [33] stringr_1.4.1 digest_0.6.30 rmarkdown_2.18 MCMCpack_1.6-3 ## [37] pkgconfig_2.0.3 htmltools_0.5.3 fastmap_1.1.0 highr_0.9 ## [41] htmlwidgets_1.5.4 rlang_1.0.6 rstudioapi_0.14 jquerylib_0.1.4 ## [45] farver_2.1.1 generics_0.1.3 jsonlite_1.8.3 crosstalk_1.2.0 ## [49] dplyr_1.0.10 inline_0.3.19 magrittr_2.0.3 s2_1.1.0 ## [53] dotCall64_1.0-2 munsell_0.5.0 fansi_1.0.3 lifecycle_1.0.3 ## [57] stringi_1.7.8 yaml_2.3.6 pkgbuild_1.3.1 plyr_1.8.8 ## [61] grid_4.2.2 crayon_1.5.2 deldir_1.0-6 lattice_0.20-45 ## [65] splines_4.2.2 knitr_1.40 ps_1.7.2 pillar_1.8.1 ## [69] igraph_1.3.5 boot_1.3-28 codetools_0.2-18 stats4_4.2.2 ## [73] wk_0.7.0 glue_1.6.2 evaluate_0.18 V8_4.2.2 ## [77] RcppParallel_5.1.5 vctrs_0.5.0 spam_2.9-1 MatrixModels_0.5-1 ## [81] gtable_0.3.1 reshape_0.8.9 assertthat_0.2.1 cachem_1.0.6 ## [85] xfun_0.34 e1071_1.7-12 coda_0.19-4 survival_3.4-0 ## [89] class_7.3-20 truncnorm_1.0-8 tibble_3.1.8 iterators_1.0.14 ## [93] units_0.8-0 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
