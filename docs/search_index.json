[["Time.html", "Chapter 11 Time-why it also matters Example 11.1 Ground level ozone concentrations Example 11.2 Low-pass filtering of carbon monoxide levels using the moving average Example 11.13 Forecasting ozone levels Example 11.14 Forecasting volcanic ash Example 11.16 implementation of a dynamic linear model", " Chapter 11 Time-why it also matters The chapter contains the theory required for handling time series data. From this chapter, the reader will have gained an understanding of the following topics: That a temporal process consists of both low and high frequency components, the former playing a key role in determining long-term trends while the latter may be associated with shorter-term changes. Techniques for the exploratory analysis of the data generated by the temporal process, including the ACF (correlogram) and PACF (periodogram). Models for irregular (high frequency) components after the regular components (trend) have been removed. Methods for forecasting, including exponential smoothing and ARIMA modelling. The state space modelling approach, which sits naturally within a Bayesian setting and which provides a general framework for most of the classical time series models and many more besides. Implementing time series processes within a Bayesian hierarchical framework. Example 11.1 Ground level ozone concentrations Load the daily and hourly data for one site. library(ggplot2) # Load data for one site site_daily &lt;- read.csv(&quot;data/LA_ozone_daily.csv&quot;, header = TRUE) # change the format of the date column site_daily$date &lt;- as.Date(site_daily$date, &quot;%m/%d/%Y&quot;) # load hourly data from that same site site_hourly &lt;- read.csv(&quot;data/LA_ozone_hourly.csv&quot;, header = TRUE) # Add a theme to clear axes and background in ggplot (optional) theme_clear &lt;- function(){ theme( panel.grid.major = element_blank(), # remove background grid panel.grid.minor = element_blank(), panel.background = element_blank(), # remove grey background axis.line = element_line(colour = &quot;black&quot;) # keep axis line ) } Plot the daily and hourly time series. # Plot daily data ggplot(data = site_daily) + geom_line(aes(x = date, y = max.ozone, group = 1)) + # draw a line at the first data geom_vline(xintercept = as.Date(&quot;2013-01-01&quot;), color = &quot;grey&quot;) + # 8 hour regulatory standard of 0.075 (ppm) geom_hline(yintercept = 0.075, color = &quot;grey&quot;) + xlab(&quot;Day in 2013 at Los Angeles Site 060379033&quot;) + ylab(&quot;Max Daily 8hr Ozone Level (ppm)&quot;) + theme_clear() # Plot hourly data ggplot(data = site_hourly,) + geom_line(aes(x = time, y = ozone, group = 1)) + geom_vline(xintercept = 1, color = &quot;grey&quot;) + # 8 hour regulatory standard of 0.075 (ppm). geom_hline(yintercept = 0.075, color = &quot;grey&quot;) + xlab(&quot;Hour in 2013&#39;s ozone season&quot;) + ylab(&quot;Hourly Ozone Concentration (ppm)&quot;) + theme_clear() Example 11.2 Low-pass filtering of carbon monoxide levels using the moving average For this example we will use the TTR package (Technical Trading Rules). This allow us to manipulate objects like time series for forecasting. library(TTR) # Load daily data site_daily &lt;- read.csv(&quot;data/LA_ozone_daily.csv&quot;, header = TRUE) # add an identifier column for each day in the sample site_daily$day &lt;- 1:nrow(site_daily) # add a theme to clear axes and background in ggplot theme_clear &lt;- function(){ theme( panel.grid.major = element_blank(), # remove background grid panel.grid.minor = element_blank(), panel.background = element_blank(), # remove grey background axis.line = element_line(colour = &quot;black&quot;), # keep axis line ) } # Add loess smooth # Single day ozone.loess &lt;- loess(max.ozone ~ day, span = 0.75, data = site_daily[,c(&quot;max.ozone&quot;, &quot;day&quot;)]) ozone.predict &lt;- predict(ozone.loess, data.frame(day = 1:nrow(site_daily))) ozone.predict_df &lt;- data.frame(day = 1:nrow(site_daily), ozone.prediction = ozone.predict) ggplot(data = site_daily) + geom_line(aes(x = day, y = max.ozone, group = 1)) + geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) + xlab(&quot;Day in 2013 at Los Angeles Site 060379033&quot;) + ylab(&quot;Max Daily 8hr Ozone Level (ppm)&quot;) + ggtitle(&quot;Single day&quot;) + theme_clear() # Three days ozone_SMA3 &lt;- data.frame(sma = SMA(site_daily$max.ozone, n = 3), day = 1:nrow(site_daily)) ggplot(data = ozone_SMA3) + geom_line(aes(x = day, y = sma, group = 1)) + geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) + xlab(&quot;Day in 2013 at Los Angeles Site 060379033&quot;) + ylab(&quot;Max Daily 8hr Ozone Level (ppm)&quot;) + ggtitle(&quot;Three days&quot;) + theme_clear() # Six days ozone_SMA6 &lt;- data.frame(sma = SMA(site_daily$max.ozone, n = 6), day = 1:nrow(site_daily)) ggplot(data = ozone_SMA6) + geom_line(aes(x = day, y = sma, group = 1)) + geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) + xlab(&quot;Day in 2013 at Los Angeles Site 060379033&quot;) + ylab(&quot;Max Daily 8hr Ozone Level (ppm)&quot;) + ggtitle(&quot;Six days&quot;) + theme_clear() # Twelve days ozone_SMA12 &lt;- data.frame(sma = SMA(site_daily$max.ozone, n = 12), day = 1:nrow(site_daily)) ggplot(data = ozone_SMA12) + geom_line(aes(x = day, y = sma, group = 1)) + geom_line(data = ozone.predict_df, aes(x = day, y = ozone.predict)) + xlab(&quot;Day in 2013 at Los Angeles Site 060379033&quot;) + ylab(&quot;Max Daily 8hr Ozone Level (ppm)&quot;) + ggtitle(&quot;Twelve days&quot;) + theme_clear() Example 11.13 Forecasting ozone levels library(TTR) library(forecast) # Load hourly data for site 060379033 site_hourly &lt;- read.csv(&quot;data/LA_ozone_hourly.csv&quot;, header = TRUE) # one night hour per day missing for instrument calibration - imputed for simplicity imputeNA &lt;- mean(site_hourly$ozone, na.rm = TRUE) site_hourly$ozone[is.na(site_hourly$ozone)] &lt;- imputeNA # Select the first seven days in july # days_pattern contains the dates for the first seven days days_pattern &lt;- paste0(&quot;^2013070&quot;, 1:7, collapse=&quot;|&quot;) # select all the rows that follow that pattern using grepl july_seven_days &lt;- site_hourly[grepl(days_pattern, site_hourly$datetime),] july_seven_days$hours &lt;- 1:nrow(july_seven_days) # Holt-Winters model fitting # Turn this into a time series object to use Holt-Winters forecast level_ts &lt;- ts(july_seven_days$ozone, frequency = 24, start = c(1)) ozone_forecast &lt;- HoltWinters(level_ts) # Plot using the default function plot( ozone_forecast, xlab = &quot;Hours - First Week -July 2013&quot;, ylab = &quot;O3 (ppm)&quot;, col.predicted = 1, col = &quot;black&quot;, bty = &quot;n&quot;, lty = 2 ) # Holt- Winters 24 ahead forast on Day 8 # no need to specify Holt-Winters forecast as the object is already HoltWinters class ozoneforecast_day8 &lt;- forecast(ozone_forecast, h=24) # Plot using default function plot(ozoneforecast_day8, bty = &quot;n&quot;) Example 11.14 Forecasting volcanic ash The data in this example consists of atmospheric levels of volcanic ash from 1500AD to 2000AD. library(ggplot2) library(forecast) library(TTR) # Load volcano dust data ## REVIEW: Data source: Hyn�d�man, R.J. Time Series Data Library, http://data.is/TSDLdemo # Data cover the period from 1500AD to 2000AD volcano_dust &lt;- scan(&quot;https://robjhyndman.com/tsdldata/annual/dvi.dat&quot;, skip = 1) # Add a theme to clear axes and background in ggplot theme_clear &lt;- function(){ theme( panel.grid.major = element_blank(), # remove background grid panel.grid.minor = element_blank(), panel.background = element_blank(), # remove grey background axis.line = element_line(colour = &quot;black&quot;), # keep axis line ) } The following figure shows the plot of the original time series. # Turn data into data frame to plot it in ggplot volcano_dust_df &lt;- data.frame(year = 1500:(1500+length(volcano_dust)-1), dust = volcano_dust) ggplot(data = volcano_dust_df) + geom_line(aes(x = year, y = dust, group = 1)) + xlab(&quot;Year&quot;) + ylab(&quot;Atmospheric levels of volcanic ash&quot;) + theme_clear() We can also plot the autocorrelogram (ACF) and partial autocorrelogram (PACF) to identify any autocorrelation in the time series. # convert data into a time series object volcano_dust_series &lt;- ts(volcano_dust, start = c(1500)) # Compute autocorrelogram with max lag 20 acf( volcano_dust_series, lag.max = 20, bty = &quot;n&quot;, main = &quot;Autocorrelogram volcano dust&quot; ) # Compute the partial autocorrelogram with max lag 20 pacf( volcano_dust_series, lag.max = 20, bty = &quot;n&quot;, main = &quot;Partial autocorrelogram volcano dust&quot; ) # Finding an ARIMA model auto.arima(volcano_dust_series, ic = &quot;aic&quot;) ## Series: volcano_dust_series ## ARIMA(1,0,2) with non-zero mean ## ## Coefficients: ## ar1 ma1 ma2 mean ## 0.4723 0.2694 0.1279 57.5178 ## s.e. 0.0936 0.0969 0.0752 8.4883 ## ## sigma^2 = 4897: log likelihood = -2661.84 ## AIC=5333.68 AICc=5333.81 BIC=5354.45 # fitting the ARIMA(2,0,0) model volcano_dust_arima &lt;- arima(volcano_dust_series, order = c(2, 0, 0)) # forecast 31 years with the ARIMA(2,0,0) model volcano_dust_forecast &lt;- forecast(volcano_dust_arima, h = 31) plot(volcano_dust_forecast, bty = &quot;n&quot;) Example 11.16 implementation of a dynamic linear model NOTE The code for the implementation of DLMs in Stan and Nimble was developed by Paritosh Kumar Roy. This code and other more complex DLM structures are available through his github. Nile river data Measurements of the annual flow of the river Nile at Aswan (formerly Assuan), 1871–1970, in \\(10^8\\) \\(m^3\\), “with apparent change point near 1898” (\\(\\ref{Cobb1978}\\), Table 1, p.249). Stan library(coda) library(ggplot2) library(rstan) library(tidyverse) options(mc.cores = parallel::detectCores()) rstan_options(auto_write = TRUE) # Load data for RW case data(&quot;Nile&quot;, package = &quot;datasets&quot;) # Add a theme to clear axes and background in ggplot (optional) theme_clear &lt;- function(){ theme( panel.grid.major = element_blank(), # remove background grid panel.grid.minor = element_blank(), panel.background = element_blank(), # remove grey background axis.line = element_line(colour = &quot;black&quot;) # keep axis line ) } J &lt;- length(Nile) y &lt;- as.vector(Nile) Ft &lt;- rep(1, J) Gt &lt;- 1 m0 &lt;- mean(y) C0 &lt;- 100 stan_data &lt;- list( T = J, y = y, F = Ft, G = Gt, m0 = m0, C0 = C0 ) functions { real uous_dlm_ldensity(array[] real y, array[] real F, real G, real V, real W, real m0, real C0, int T){ array[T+1] real a; array[T+1] real R; array[T] real lldata; a[1] = m0; R[1] = C0; for (i in 1:T) { real u; real Q; real A; real L; u = y[i] - F[i] * a[i]; Q = F[i] * R[i] * F[i] + V; A = G * R[i] * F[i] * inv(Q); L = G - A * F[i]; lldata[i] = normal_lpdf(u | 0, sqrt(Q)); a[i+1] = G * a[i] + A * u; R[i+1] = G * R[i] * L + W; } return sum(lldata); } array[] real uous_ffbs_rng(array[] real y, array[] real F, real G, real V, real W, real m0, real C0, int T){ array[T] real theta; array[T] real a; array[T] real R; array[T] real m; array[T] real C; // Kalman filtering real mt = m0; real Ct = C0; for(i in 1:T){ real ft; real Qt; real at; real Rt; real At; at = G * mt; Rt = G * Ct * G + W; ft = F[i] * at; Qt = F[i] * Rt * F[i] + V; At = Rt * F[i] * inv(Qt); mt = at + At * (y[i] - ft); Ct = Rt - At * Qt * At; //store for backward sampling a[i] = at; R[i] = Rt; m[i] = mt; C[i] = Ct; } // backward sampling array[T-1] int ind = sort_indices_desc(linspaced_int_array(T-1,1,T-1)); theta[T] = normal_rng(m[T], sqrt(C[T])); for(i in ind) { real Bt; real ht; real Ht; Bt = C[i] * G * inv(R[i+1]); ht = m[i] + Bt * (theta[i+1] - a[i+1]); Ht = C[i] - Bt * G * C[i]; theta[i] = normal_rng(ht, sqrt(Ht)); } return theta; } } data{ int T; array[T] real y; array[T] real F; real G; real m0; real&lt;lower=0&gt; C0; } parameters{ real&lt;lower=0&gt; tau; real&lt;lower=0&gt; sqrt_W; } model { real V = square(tau); real W = square(sqrt_W); tau ~ std_normal(); sqrt_W ~ std_normal(); target += uous_dlm_ldensity(y, F, G, V, W, m0, C0, T); } generated quantities{ array[T] real theta; real V = square(tau); real W = square(sqrt_W); theta = uous_ffbs_rng(y, F, G, V, W, m0, C0, T); } Example11_16_Nile_Stan &lt;- stan( file = &quot;functions/Example11_16_Nile.stan&quot;, data = stan_data, warmup = 5000, iter = 10000, chains = 3, include = TRUE ) rstan::traceplot(Example11_16_Nile_Stan, pars = c(&quot;tau&quot;,&quot;sqrt_W&quot;)) rstan::traceplot(Example11_16_Nile_Stan, pars = paste0(&quot;theta[&quot;, sample.int(J, size = 4, replace = FALSE), &quot;]&quot;)) stanfit_summary &lt;- summary(Example11_16_Nile_Stan, pars = c(&quot;tau&quot;,&quot;sqrt_W&quot;,&quot;theta&quot;)) head(stanfit_summary$summary) ## mean se_mean sd 2.5% 25% 50% ## tau 30.65683 0.007731462 0.6367664 29.4166 30.21944 30.65556 ## sqrt_W 17.19988 0.010446301 0.8589537 15.5064 16.63028 17.18717 ## theta[1] 1016.78418 0.121861780 14.3782257 988.4504 1007.15746 1016.80199 ## theta[2] 1056.96245 0.134523937 15.7147870 1026.5595 1046.31618 1056.88108 ## theta[3] 1064.71884 0.132299552 15.7023906 1034.2012 1054.28355 1064.69565 ## theta[4] 1104.73603 0.136416551 16.2744198 1072.6856 1093.78977 1104.71020 ## 75% 97.5% n_eff Rhat ## tau 31.09780 31.89589 6783.239 1.0002581 ## sqrt_W 17.76715 18.92548 6761.056 1.0005901 ## theta[1] 1026.53111 1044.66956 13921.164 1.0003126 ## theta[2] 1067.60348 1087.81237 13646.393 1.0003196 ## theta[3] 1075.22411 1095.56754 14086.880 0.9999034 ## theta[4] 1115.67504 1136.51547 14232.359 1.0003366 stan_fit_df &lt;- data.frame(stanfit_summary$summary) |&gt; rownames_to_column() |&gt; filter(str_detect(rowname, &quot;theta&quot;)) |&gt; mutate(date = zoo::as.yearmon(time(Nile))) ggplot(data = stan_fit_df, aes(x = date)) + geom_path(aes(y = mean), col = &quot;blue&quot;, size = 0.6) + geom_ribbon(aes(ymin = X2.5., ymax = X97.5.), alpha = 0.25, col = &quot;gray99&quot;) + theme_clear() + xlab(&quot;year&quot;) ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. # TODO: I am still missing the plots for the fitted values here Nimble library(coda) library(ggplot2) library(nimble) library(tidybayes) library(tidyverse) source(&quot;functions/FFBS_functions_nimble.R&quot;) # load necessary functions for ffbs # Load data for one site data(&quot;Nile&quot;, package = &quot;datasets&quot;) # Add a theme to clear axes and background in ggplot (optional) theme_clear &lt;- function(){ theme( panel.grid.major = element_blank(), # remove background grid panel.grid.minor = element_blank(), panel.background = element_blank(), # remove grey background axis.line = element_line(colour = &quot;black&quot;) # keep axis line ) } Example11_16_Nile_Nimble &lt;- nimbleCode({ tau ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf) Vt &lt;- tau^2 sqrt_Wt_diag ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf) Wt &lt;- sqrt_Wt_diag^2 theta_mean[1] &lt;- m0 theta[1] ~ dnorm(theta_mean[1], var = C0) for(t in 1:J) { theta_mean[t+1] &lt;- Gt * theta[t] theta[t+1] ~ dnorm(theta_mean[t+1], var = Wt) yt_mean[t] &lt;- Ft[t] * theta[t+1] yt[t] ~ dnorm(yt_mean[t], var = Vt) } }) # Model specification J &lt;- length(Nile) yt &lt;- as.vector(Nile) Ft &lt;- rep(1, J) Gt &lt;- 1 m0 &lt;- mean(yt) C0 &lt;- 100 const_list &lt;- list(J = J) dat_list &lt;- list(yt = yt, Ft = Ft, Gt = Gt, m0 = m0, C0 = C0) init_list &lt;- list(tau = 0.01, sqrt_Wt_diag = 0.1, theta = rep(0, J+1)) Rmodel &lt;- nimbleModel(Example11_16_Nile_Nimble, constants=const_list, data=dat_list, inits=init_list) Rmodel$initializeInfo() Cmodel &lt;- compileNimble(Rmodel, showCompilerOutput = FALSE) conf &lt;- configureMCMC(Rmodel, monitors = c(&quot;tau&quot;,&quot;sqrt_Wt_diag&quot;,&quot;theta&quot;)) conf$removeSampler(target = &quot;theta[]&quot;) conf$addSampler(target = &quot;theta&quot;, type = &quot;ffbs_uous&quot;, control = list(ytName = &quot;yt&quot;, FtName = &quot;Ft&quot;, VtName = &quot;Vt&quot;, GtName = &quot;Gt&quot;, WtName = &quot;Wt&quot;, m0Name = &quot;m0&quot;, C0Name = &quot;C0&quot;)) conf$printSamplers(byType = TRUE) conf$removeSampler(target = &quot;sqrt_Wt_diag&quot;) conf$addSampler(target = &quot;sqrt_Wt_diag&quot;, type = &quot;RW&quot;, control = list(log = TRUE)) conf$removeSampler(target = &quot;tau&quot;) conf$addSampler(target = &quot;tau&quot;, type = &quot;RW&quot;, control = list(log = TRUE)) conf$printSamplers(byType = TRUE) conf$printSamplers(executionOrder = TRUE) Rmcmc &lt;- buildMCMC(conf) Cmcmc &lt;- compileNimble(Rmcmc, project = Cmodel, resetFunctions = TRUE, showCompilerOutput = TRUE) niters &lt;- 40000 nburnins &lt;- 0.5*niters nchains &lt;- 2 nthins &lt;- 14 post_samples &lt;- runMCMC( Cmcmc, niter = niters, nburnin = nburnins, thin = nthins, nchains = nchains, samplesAsCodaMCMC = TRUE ) post_summary &lt;- nimSummary(post_samples) tidy_post_samples &lt;- post_samples |&gt; tidy_draws() # Traceplots tidy_post_samples |&gt; select(.chain, .iteration, .draw, &#39;tau&#39;) |&gt; gather(vars, value, -.chain, -.iteration, -.draw) |&gt; ggplot(aes(x = .iteration, y = value)) + geom_path(aes(color = factor(.chain)), size = 0.25, show.legend = FALSE) + facet_wrap( ~ vars, scales = &quot;free_y&quot;, nrow = 1) + theme_bw() + theme(panel.grid = element_blank(), strip.background = element_blank()) tidy_post_samples |&gt; select(.chain, .iteration, .draw, &#39;sqrt_Wt_diag&#39;) |&gt; gather(vars, value, -.chain, -.iteration, -.draw) |&gt; ggplot(aes(x = .iteration, y = value)) + geom_path(aes(color = factor(.chain)), size = 0.25, show.legend = FALSE) + facet_wrap( ~ vars, scales = &quot;free_y&quot;, nrow = 1) + theme_bw() + theme(panel.grid = element_blank(), strip.background = element_blank()) tidy_post_samples |&gt; select(.chain, .iteration, .draw, paste0(&#39;theta[&#39;, sample.int(J, size = 4, replace = FALSE),&quot;]&quot;)) |&gt; gather(vars, value, -.chain, -.iteration, -.draw) |&gt; ggplot(aes(x = .iteration, y = value)) + geom_path(aes(color = factor(.chain)), linewidth = 0.25, show.legend = FALSE) + facet_wrap( ~ vars, scales = &quot;free_y&quot;, nrow = 2) + theme_bw() + theme(panel.grid = element_blank(), strip.background = element_blank()) head(post_summary) ## post.mean post.sd q2.5 q50 q97.5 f0 n.eff Rhat ## sqrt_Wt_diag 92.787 60.191 24.035 59.043 187.184 1 192.979 1.943 ## tau 76.848 58.281 0.375 110.341 144.701 1 482.610 1.979 ## theta[1] 921.510 10.041 901.999 921.399 941.385 1 2651.944 1.010 ## theta[2] 1034.637 74.801 915.142 1019.089 1124.311 1 793.983 1.613 ## theta[3] 1074.438 78.441 935.455 1067.160 1164.746 1 565.741 1.472 ## theta[4] 1010.156 55.726 945.134 992.844 1134.635 1 599.376 1.356 post_sum_theta &lt;- as.data.frame(post_summary) |&gt; rownames_to_column() |&gt; filter(str_detect(rowname, &quot;theta&quot;)) |&gt; mutate(time = as.numeric(gsub(&quot;.*?([0-9]+).*&quot;, &quot;\\\\1&quot;, rowname))) |&gt; select(time, post.mean, post.sd, q2.5, q50, q97.5) ggplot(data = post_sum_theta, aes(x = time)) + geom_ribbon(aes(ymin = q2.5, ymax = q97.5), fill = &quot;lightgray&quot;, alpha = 0.7) + geom_path(aes(y = q50), col = &quot;blue&quot;, linewidth = 0.6) + ylab(&quot;&quot;) + xlab(&quot;Time&quot;) + theme_clear() # REVIEW: it is not giving the same results as Stan and the credible intervals # are wider Cnim_postfit_uous &lt;- compileNimble(nim_postfit_uous, showCompilerOutput = FALSE) ## Compiling ## [Note] This may take a minute. ## [Note] Use &#39;showCompilerOutput = TRUE&#39; to see C++ compilation details. post_tau &lt;- tidy_post_samples$tau post_sqrt_Wt_diag &lt;- tidy_post_samples$sqrt_Wt_diag post_ft_list &lt;- lapply(1:length(post_tau), function(i) { post_Vt &lt;- post_tau[i] ^ 2 post_Wt &lt;- post_sqrt_Wt_diag[i] ^ 2 post_ft &lt;- Cnim_postfit_uous( yt = dat_list$yt, Ft = dat_list$Ft, Vt = post_Vt, Gt = dat_list$Gt, Wt = post_Wt, m0 = dat_list$m0, C0 = dat_list$C0 ) post_ft &lt;- data.frame(ft = post_ft) %&gt;% mutate(time = row_number()) return(post_ft) }) tidy_post_ft &lt;- do.call(&quot;rbind&quot;, post_ft_list) ## posterior summaries of ft post_sum_ft &lt;- tidy_post_ft |&gt; group_by(time) |&gt; summarise( post.mean = mean(ft), post.sd = sd(ft), q2.5 = quantile(ft, prob = 0.025), q50 = quantile(ft, prob = 0.50), q97.5 = quantile(ft, prob = 0.975) ) |&gt; ungroup() ggplot(data = post_sum_ft, aes(x = time)) + geom_ribbon(aes(ymin = q2.5, ymax = q97.5), fill = &quot;lightblue&quot;) + geom_path(aes(y = post.mean), col = &quot;red&quot;, linewidth = 0.25) + geom_point(aes(y = yt), size = 0.25) + ylab(&quot;&quot;) + xlab(&quot;Time&quot;) + theme_clear() 11.0.1 UK ozone data 11.0.1.1 Stan library(coda) library(ggplot2) library(gridExtra) library(rstan) library(tidyverse) options(mc.cores = parallel::detectCores()) rstan_options(auto_write = TRUE) # Load data for RW case UK_ozone &lt;- read.csv(&quot;data/uk_ozone_one_site.csv&quot;) # Add a theme to clear axes and background in ggplot (optional) theme_clear &lt;- function(){ theme( panel.grid.major = element_blank(), # remove background grid panel.grid.minor = element_blank(), panel.background = element_blank(), # remove grey background axis.line = element_line(colour = &quot;black&quot;) # keep axis line ) } y &lt;- UK_ozone$ozone temp &lt;- UK_ozone$temp wind &lt;- UK_ozone$wind J &lt;- length(y) p &lt;- 3 # (intercept, wind, temp) Ft &lt;- array(0, dim = c(J, p)) Ft[, 1] &lt;- 1 Ft[, 2] &lt;- (wind[1:J] - mean(wind[1:J])) / sd(wind[1:J]) Ft[, 3] &lt;- (temp[1:J] - mean(temp[1:J])) / sd(temp[1:J]) Gt &lt;- diag(x = 1, nrow = p, ncol = p) m0 &lt;- c(mean(y), 0, 0) C0 &lt;- diag(x = 1, nrow = p, ncol = p) stan_data &lt;- list(T = J, p = p, y = y, F = Ft, G = Gt, m0= m0, C0 = C0) functions { // FFBS for DLM with univariate observation equation and univariate system equation array[] vector uoms_ffbs_rng(array[] real y, array[] vector F, matrix G, real V, matrix W, vector m0, matrix C0, int T, int p){ array[T] vector[p] theta; array[T] vector[p] a; array[T] matrix[p,p] R; array[T] vector[p] m; array[T] matrix[p,p] C; // Kalman filtering vector[p] mt = m0; matrix[p,p] Ct = C0; for(i in 1:T){ real ft; real Qt; vector[p] at; matrix[p,p] Rt; vector[p] At; at = G * mt; Rt = G * Ct * G&#39; + W; ft = F[i]&#39; * at; Qt = quad_form(Rt, F[i]) + V; //F[i]&#39; * Rt * F[i] + V; At = Rt * F[i] * inv(Qt); mt = at + At * (y[i] - ft); Ct = Rt - At * Qt * At&#39;; //store for backward sampling a[i] = at; R[i] = Rt; m[i] = mt; C[i] = Ct; } // backward sampling array[T-1] int ind = sort_indices_desc(linspaced_int_array(T-1,1,T-1)); theta[T] = multi_normal_rng(m[T], C[T]); for(i in ind) { matrix[p,p] Bt; vector[p] ht; matrix[p,p] Ht; Bt = C[i] * G&#39; * inverse(R[i+1]); ht = m[i] + Bt * (theta[i+1] - a[i+1]); Ht = C[i] - Bt * R[i+1] * Bt&#39;; theta[i] = multi_normal_rng(ht, Ht); } return theta; } real uoms_dlm_ldensity(array[] real y, array[] vector F, matrix G, real V, matrix W, vector m0, matrix C0, int T, int p){ array[T+1] vector[p] a; array[T+1] matrix[p, p] R; array[T] real lldata; a[1] = m0; R[1] = C0; for (i in 1:T) { real u; real Q; real Qinv; vector[p] A; matrix[p, p] L; u = y[i] - F[i]&#39; * a[i]; Q = quad_form(R[i],F[i]) + V; //F[i]&#39; * R[i] * F[i] + V; Qinv = inv(Q); // A = G * R[i] * F[i] * Qinv; L = G - A * F[i]&#39;; //lldata[i] = -0.5 * (log(2 * pi()) + log(Q) + Qinv*square(u)); lldata[i] = normal_lpdf(u | 0, sqrt(Q)); // univariate a[i+1] = G * a[i] + A * u; R[i+1] = G * R[i] * L&#39; + W; } return sum(lldata); } array[] real uoms_dlm_one_step_ahead_rng(array[] real y, array[] vector F, matrix G, real V, matrix W, vector m0, matrix C0, int T, int p){ array[T] real yfit; array[T+1] vector[p] a; array[T+1] matrix[p, p] R; array[T] real lldata; a[1] = m0; R[1] = C0; for (i in 1:T) { real u; real Q; real Qinv; vector[p] A; matrix[p, p] L; u = y[i] - F[i]&#39; * a[i]; Q = quad_form(R[i],F[i]) + V; //F[i]&#39; * R[i] * F[i] + V; Qinv = inv(Q); // A = G * R[i] * F[i] * Qinv; L = G - A * F[i]&#39;; yfit[i] = normal_rng(F[i]&#39; * a[i], sqrt(Q)); // univariate a[i+1] = G * a[i] + A * u; R[i+1] = G * R[i] * L&#39; + W; } return yfit; } } data{ int T; int p; array[T] real y; array[T] vector[p] F; matrix[p, p] G; vector[p] m0; cov_matrix[p] C0; } parameters{ real&lt;lower=0&gt; tau; vector&lt;lower=0&gt;[p] sqrt_W_diag; } model { real V = square(tau); matrix[p, p] W = diag_matrix(square(sqrt_W_diag)); tau ~ std_normal(); sqrt_W_diag ~ std_normal(); target += uoms_dlm_ldensity(y, F, G, V, W, m0, C0, T, p); } generated quantities{ array[T] vector[p] theta; array[T] real yfit; real V = square(tau); matrix[p, p] W = diag_matrix(square(sqrt_W_diag)); theta = uoms_ffbs_rng(y, F, G, V, W, m0, C0, T, p); yfit = uoms_dlm_one_step_ahead_rng(y, F, G, V, W, m0, C0, T, p); } Example11_16_UK_Stan &lt;- stan( file = &quot;functions/Example11_16_UK.stan&quot;, data = stan_data, warmup = 5000, iter = 10000, chains = 3, include = TRUE ) ## Warning: There were 5 divergent transitions after warmup. See ## https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup ## to find out why this is a problem and how to eliminate them. ## Warning: Examine the pairs() plot to diagnose sampling problems rstan::traceplot(Example11_16_UK_Stan, pars = c(&quot;tau&quot;, &quot;sqrt_W_diag&quot;, &quot;theta[1,1]&quot;)) rstan::traceplot(Example11_16_UK_Stan, pars = paste0(&quot;theta[&quot;, sample.int(J, size = 4, replace = FALSE), &quot;,1]&quot;)) rstan::traceplot(Example11_16_UK_Stan, pars = paste0(&quot;theta[&quot;, sample.int(J, size = 4, replace = FALSE), &quot;,2]&quot;)) rstan::traceplot(Example11_16_UK_Stan, pars = paste0(&quot;theta[&quot;, sample.int(J, size = 4, replace = FALSE), &quot;,3]&quot;)) fixedpars_summary &lt;- summary(Example11_16_UK_Stan, pars = c(&quot;tau&quot;, &quot;sqrt_W_diag&quot;))$summary fixedpars_summary ## mean se_mean sd 2.5% 25% 50% ## tau 7.3610275 0.004851020 0.4008981 6.57719600 7.0908376 7.3629348 ## sqrt_W_diag[1] 2.6439045 0.007754856 0.6125134 1.46888530 2.2241253 2.6420340 ## sqrt_W_diag[2] 0.2479908 0.001223029 0.1181039 0.08087677 0.1662709 0.2264369 ## sqrt_W_diag[3] 0.6024224 0.005817935 0.5380677 0.01871538 0.1804329 0.4444740 ## 75% 97.5% n_eff Rhat ## tau 7.6317345 8.1446432 6829.705 0.9999462 ## sqrt_W_diag[1] 3.0521496 3.8662784 6238.551 1.0002905 ## sqrt_W_diag[2] 0.3046127 0.5368648 9325.146 1.0001561 ## sqrt_W_diag[3] 0.8731195 1.9720697 8553.346 0.9998983 theta_summary &lt;- summary(Example11_16_UK_Stan, pars = c(&quot;theta&quot;))$summary p1 &lt;- data.frame(theta_summary) |&gt; rownames_to_column() |&gt; filter(rowname %in% paste0(&quot;theta[&quot;, 1:J, &quot;,1]&quot;)) |&gt; mutate(date = as.Date(UK_ozone$date[1:J])) |&gt; ggplot(aes(x = date, group = 1)) + geom_path(aes(y = mean), color = &quot;blue&quot;, linewidth = 0.6) + geom_ribbon(aes(ymin = X2.5., ymax = X97.5.), alpha = 0.25, col = &quot;lightgray&quot;) + ggtitle(&quot;Intercept&quot;) + theme_clear() + theme(plot.title = element_text(hjust = 0.5)) p2 &lt;- data.frame(theta_summary) |&gt; rownames_to_column() |&gt; filter(rowname %in% paste0(&quot;theta[&quot;, 1:J, &quot;,2]&quot;)) |&gt; mutate(date = as.Date(UK_ozone$date[1:J])) |&gt; ggplot(aes(x = date)) + geom_path(aes(y = mean), color = &quot;blue&quot;, linewidth = 0.6) + geom_ribbon(aes(ymin = X2.5., ymax = X97.5.), alpha = 0.25, col = &quot;lightgray&quot;) + ggtitle(&quot;Wind&quot;) + theme_clear() + theme(plot.title = element_text(hjust = 0.5)) p3 &lt;- data.frame(theta_summary) |&gt; rownames_to_column() |&gt; filter(rowname %in% paste0(&quot;theta[&quot;, 1:J, &quot;,3]&quot;)) |&gt; mutate(date = as.Date(UK_ozone$date[1:J])) |&gt; ggplot(aes(x = date)) + geom_path(aes(y = mean), color = &quot;blue&quot;, linewidth = 0.6) + geom_ribbon(aes(ymin = X2.5., ymax = X97.5.), alpha = 0.25, col = &quot;lightgray&quot;) + ggtitle(&quot;Temperature&quot;) + theme_clear() + theme(plot.title = element_text(hjust = 0.5)) grid.arrange(p1,p2,p3, ncol = 2) # TODO: I am still missing the plots for the fitted values here 11.0.1.2 Nimble library(coda) library(dplyr) #library(sf) library(ggplot2) library(nimble, warn.conflicts = FALSE) library(nleqslv) library(tidybayes) source(&quot;functions/FFBS_functions_nimble.R&quot;) UK_ozone &lt;- read.csv(&quot;data/uk_ozone_one_site.csv&quot;) # Add a theme to clear axes and background in ggplot (optional) theme_clear &lt;- function(){ theme( panel.grid.major = element_blank(), # remove background grid panel.grid.minor = element_blank(), panel.background = element_blank(), # remove grey background axis.line = element_line(colour = &quot;black&quot;) # keep axis line ) } Example11_16_O3_Nimble &lt;- nimbleCode({ tau ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf) for (t in 1:Tt) { Vt[t] &lt;- tau ^ 2 } for (j in 1:p) { sqrt_Wt_diag[j] ~ T(dt(mu = 0, sigma = 1, df = 1), 0, Inf) } Wt[1:p, 1:p] &lt;- nim_diag(x = sqrt_Wt_diag[1:p] ^ 2) mt[1:p, 1] &lt;- m0[1:p] Ct[1:p, 1:p, 1] &lt;- C0[1:p, 1:p] for (t in 1:Tt) { at[1:p, t] &lt;- (Gt[1:p, 1:p] %*% mt[1:p, t])[1:p, 1] Rt[1:p, 1:p, t] &lt;- Gt[1:p, 1:p] %*% Ct[1:p, 1:p, t] %*% t(Gt[1:p, 1:p]) + Wt[1:p, 1:p] ft[t] &lt;- (t(Ft[1:p, t]) %*% at[1:p, t])[1, 1] Qt[t] &lt;- (t(Ft[1:p, t]) %*% Rt[1:p, 1:p, t] %*% Ft[1:p, t] + Vt[t])[1, 1] yt[t] ~ dnorm(mean = ft[t], var = Qt[t]) At[1:p, t] &lt;- (Rt[1:p, 1:p, t] %*% Ft[1:p, t])[1:p, 1] / Qt[t] mt[1:p, t + 1] &lt;- at[1:p, t] + (At[1:p, t] * (yt[t] - ft[t])) Ct[1:p, 1:p, t + 1] &lt;- Rt[1:p, 1:p, t] - (At[1:p, t] %*% t(At[1:p, t])) * Qt[t] } theta[1:p, 1:(Tt + 1)] &lt;- nim_bsample( mt = mt[1:p, 1:(Tt + 1)], Ct = Ct[1:p, 1:p, 1:(Tt + 1)], at = at[1:p, 1:Tt], Gt = Gt[1:p, 1:p], Rt = Rt[1:p, 1:p, 1:Tt] ) }) # Model specification yt &lt;- UK_ozone$ozone temp &lt;- UK_ozone$temp wind &lt;- UK_ozone$wind Tt &lt;- length(yt) p &lt;- 3 # (intercept, wind, temp) Ft &lt;- array(0, dim = c( p, Tt)) Ft[ 1,] &lt;- 1 Ft[ 2,] &lt;- (wind[1:Tt] - mean(wind[1:Tt])) / sd(wind[1:Tt]) Ft[ 3,] &lt;- (temp[1:Tt] - mean(temp[1:Tt])) / sd(temp[1:Tt]) Gt &lt;- diag(x = 1, nrow = p, ncol = p) m0 &lt;- c(mean(yt), 0, 0) C0 &lt;- diag(x = 1, nrow = p, ncol = p) const_list &lt;- list(Tt = Tt, p = p, m0 = m0, C0 = C0) dat_list &lt;- list(yt = yt, Ft = Ft, Gt = Gt) init_list &lt;- list(tau = 0.01, sqrt_Wt_diag = sqrt(rep(0.1, p))) Rmodel &lt;- nimbleModel( Example11_16_O3_Nimble, constants = const_list, data = dat_list, inits = init_list ) Rmodel$initializeInfo() Rmodel$calculate() Cmodel &lt;- compileNimble(Rmodel, showCompilerOutput = FALSE) conf &lt;- configureMCMC(Rmodel, monitors = c(&quot;tau&quot;, &quot;sqrt_Wt_diag&quot;, &quot;theta&quot;, &quot;ft&quot;)) Rmcmc &lt;- buildMCMC(conf) Cmcmc &lt;- compileNimble( Rmcmc, project = Cmodel, resetFunctions = TRUE, showCompilerOutput = FALSE ) niter &lt;- 10000 nburnin &lt;- 0.5 * niter nthin &lt;- 1 start_time &lt;- Sys.time() post_samples &lt;- runMCMC( Cmcmc, niter = niter, nburnin = nburnin, thin = nthin, nchains = 2, samplesAsCodaMCMC = TRUE ) end_time &lt;- Sys.time() run_time &lt;- end_time - start_time run_time post_summary &lt;- nimSummary(post_samples) tidy_post_samples &lt;- post_samples |&gt; tidy_draws() tidy_post_samples |&gt; select( .chain, .iteration, .draw, &#39;tau&#39;, &#39;sqrt_Wt_diag[1]&#39;, &#39;sqrt_Wt_diag[2]&#39;, &#39;sqrt_Wt_diag[3]&#39; ) |&gt; gather(vars, value, -.chain, -.iteration, -.draw) |&gt; ggplot(aes(x = .iteration, y = value)) + geom_path(aes(color = factor(.chain)), linewidth = 0.25, show.legend = FALSE) + facet_wrap( ~ vars, scales = &quot;free&quot;, nrow = 2) + theme_clear() + theme(panel.grid = element_blank(), strip.background = element_blank()) post_summary[c(&#39;tau&#39;,&#39;sqrt_Wt_diag[1]&#39;,&#39;sqrt_Wt_diag[2]&#39;,&#39;sqrt_Wt_diag[3]&#39;),] ## post.mean post.sd q2.5 q50 q97.5 f0 n.eff Rhat ## tau 8.545 0.546 7.498 8.544 9.588 1 950.683 1.006 ## sqrt_Wt_diag[1] 2.206 0.729 1.029 2.144 3.782 1 825.333 1.009 ## sqrt_Wt_diag[2] 0.247 0.116 0.074 0.230 0.542 1 1762.821 1.001 ## sqrt_Wt_diag[3] 0.442 0.431 0.016 0.316 1.632 1 723.406 1.024 post_sum_theta &lt;- as.data.frame(post_summary) |&gt; rownames_to_column() |&gt; filter(str_detect(rowname, &quot;theta&quot;)) |&gt; select(rowname, q2.5, q50, q97.5) |&gt; separate(rowname, into = c(&quot;x1&quot;, &quot;x2&quot;), sep = &quot;,&quot;) |&gt; mutate(component = as.numeric(gsub(&quot;.*?([0-9]+).*&quot;, &quot;\\\\1&quot;, x1))) |&gt; mutate(time = as.numeric(gsub(&quot;.*?([0-9]+).*&quot;, &quot;\\\\1&quot;, x2))) |&gt; select(component, time, q2.5, q50, q97.5) ggplot(data = post_sum_theta, aes(x = time)) + geom_ribbon(aes(ymin = q2.5, ymax = q97.5), fill = &quot;lightgray&quot;, alpha = 0.7) + geom_path(aes(y = q50), col = &quot;blue&quot;, linewidth = 0.4) + facet_wrap( ~ component, nrow = 2, scales = &quot;free&quot;, labeller = label_bquote(theta[.(component)]) ) + ylab(&quot;&quot;) + xlab(&quot;Time&quot;) + theme_clear() + theme(panel.grid = element_blank(), strip.background = element_blank()) # TODO: I am missing the fitted values here "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
